{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test preparation\" : \"0\" \"Calendar\":\"1\" \"Comics, graphics & novels\" :\"2\" \"Romance\" :\"3\"\"Computer\" \"&\" \"technology \":\"4\"\")\n",
      "\"Cookbooks, food & wine\":5\"Children books\" :6\"Science fiction and fantasy\":7\n",
      "\"Mystery, thriller & suspense \":8\"Travel \":9\"Law\" :10\"Reference\" :11\n",
      "\"Parenting and relationship \":12\"Engineering & transportation \":13\"Medical books \":14\n",
      "\"Crafts ,hobbies & home \":15\"Religion and spirituality \":16\"Sports and outdoors \":18\"Self  help \":19\n",
      "\"Science & math \":20\"Biography & memoirs\" :21\"Business & money \":22\n",
      "\"Health fitness & dieting \":23\"History \":24\"Teen & young Adults \":2 \"Arts & photography\":26\"Literature & Fiction\":27\n",
      "\"Humor & Entertainment \":28\"Christian books & Bible \":29 \"Political & social sciences\":30\n"
     ]
    }
   ],
   "source": [
    "pnumber_of_crossvalidation_run=7\n",
    "cwd=os.getcwd()\n",
    "visual_m_path = os.path.join(cwd,'data/cover-images_mean_feature_vectors.pkl')\n",
    "textual_m_path = os.path.join(cwd,'data/text_extracted_features.pkl')\n",
    "models_folder_name = os.path.join(cwd,'models','artificial_net_textual_modality')\n",
    "path_to_save_test_results=os.path.join(models_folder_name, 'test_results.pkl')\n",
    "model_checkpoint_path = os.path.join(cwd,models_folder_name,'gmu.ckpt')\n",
    "models_folder_name_test = os.path.join(cwd,os.pardir,'text_feature_extraction','models','test',str(number_of_crossvalidation_run))\n",
    "path_to_preprocessed_texts_test=os.path.join(models_folder_name_test,'book-cover_test_dataset.pkl')\n",
    "summaries_folder_name=os.path.join(cwd,'summaries','artificial_net_textual_modality')\n",
    "\n",
    "\n",
    "df_visual_m = pd.read_pickle(visual_m_path)\n",
    "df_textual_m = pd.read_pickle(textual_m_path)\n",
    "\n",
    "number_of_recipes=len(df_visual_m)\n",
    "unique_labels=sorted(set(df_visual_m.mean_vector_labels.values))\n",
    "number_of_classes=len(unique_labels)\n",
    "possible_class_indices=list(range(0,number_of_classes))\n",
    "labels2class_indices=dict(zip(unique_labels,possible_class_indices))\n",
    "print(labels2class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value: visual features  0.5558735478366387\n",
      "Max value in visual feature vectors after subraction of mean value:  22.56199106092801\n",
      "Mean value: textual features  0.013499930763029529\n",
      "Max value in textual feature vectors after subraction of mean value:  3.519134565925813\n",
      "doc_embeddings\tlabels\ttext_names\n",
      "0\t[-0.11329869829923188, -0.6441225998849662, -0...\tTest preparation\t1.txt\n",
      "1\t[-0.07474968697600654, -0.28306451085312634, 0...\tTest preparation\t10.txt\n",
      "2\t[-0.10599670561622081, -0.5485997736729018, 0....\tTest preparation\t11.txt\n",
      "3\t[-0.5233624146389693, -0.32503846481726917, 0....\tTest preparation\t12.txt\n",
      "4\t[-0.07889076414967888, -0.2116037304174958, 0....\tTest preparation\t13.txt\n",
      "5\t[-0.07946860561194324, -0.2566648633469014, -0...\tTest preparation\t14.txt\n",
      "6\t[-0.1800028915393702, -0.6000170525947526, 0.1...\tTest preparation\t15.txt\n",
      "7\t[-0.28211158437034184, -0.503643364081505, 0.2...\tTest preparation\t2.txt\n",
      "8\t[-0.41500734646954496, -0.40415873356834714, 0...\tTest preparation\t3.txt\n",
      "9\t[-0.38648066177147605, -0.48593944596184546, 0...\tTest preparation\t4.txt\n",
      "10\t[-0.11808992227722907, -0.13458911551453934, 0...\tTest preparation\t5.txt\n",
      "11\t[-0.22233212234939284, -0.1979024863085554, -0...\tCalendar\t6.txt\n",
      "12\t[-0.08471857641348418, -0.559017298364654, -0....\tCalendar\t7.txt\n",
      "13\t[-0.027834884908365817, -0.4463838338459294, 0...\tCalendar\t8.txt\n",
      "14\t[-0.011526498846268104, -0.4014876533002968, 0...\tCalendar\t9.txt\n",
      "15\t[0.07568393993445587, 0.18173006428900282, -0....\tComics, graphics & novels\t1.txt\n",
      "16\t[0.11993878107278198, 0.13665470402595217, -0....\tComics, graphics & novels\t10.txt\n",
      "17\t[0.36336042299016497, -0.26849277411003303, -0...\tComics, graphics & novels\t11.txt\n",
      "18\t[0.41915961905088583, 0.30774946810341, 0.0777...\tComics, graphics & novels\t2.txt\n",
      "19\t[-0.03108438250694706, 0.24778843820546667, -0...\tComics, graphics & novels\t3.txt\n",
      "20\t[0.0018196716644160666, -0.09403709886171152, ...\tComics, graphics & novels\t4.txt\n",
      "21\t[0.226157589689446, -0.21843183432901234, -0.3...\tComics, graphics & novels\t5.txt\n",
      "22\t[-0.37221488045095963, 0.15941117175552535, -0...\tChildren books\t6.txt\n",
      "23\t[-0.3998149931080913, 0.36037593488667613, -0....\tChildren books\t7.txt\n",
      "24\t[-0.1703639576813445, -0.09615897017645816, -0...\tChildren books\t8.txt\n",
      "25\t[-0.4037997305160365, -0.012025206058038617, -...\tChildren books\t9.txt\n",
      "26\t[-0.24562844964158864, -0.22083867574920935, 0...\tChildren books\t1.txt\n",
      "27\t[0.05659051096808063, -0.28589183773174304, -0...\tChildren books\t2.txt\n",
      "28\t[-0.47327678027169323, -0.011298772057821004, ...\tChildren books\t3.txt\n",
      "29\t[-0.25067830622049087, -0.24191728353487582, 0...\tChildren books\t4.txt\n",
      "...\t...\t...\t...\n",
      "286\t[0.4708458284532324, 0.7217121344166731, -0.70...\tBusiness & money\t1.txt\n",
      "287\t[0.12419525208469703, 0.18482393348853915, 0.3...\tBusiness & money\t10.txt\n",
      "288\t[-0.05141209618191453, 0.55971178687658, 0.236...\tBusiness & money\t2.txt\n",
      "289\t[0.10458004412553981, 0.5648145217121964, -0.1...\tBusiness & money\t3.txt\n",
      "290\t[0.3630706935028643, 0.565899796272484, -0.326...\tBusiness & money\t4.txt\n",
      "291\t[0.34942447868798676, 0.14594550857952454, -0....\tBusiness & money\t5.txt\n",
      "292\t[-0.35736008751753723, 0.5371146822211336, -0....\tBusiness & money\t6.txt\n",
      "293\t[0.7463816534651476, 0.2869543568779235, -0.10...\tBusiness & money\t7.txt\n",
      "294\t[-0.21550115603384534, 0.45582593070031935, -0...\tBusiness & money\t8.txt\n",
      "295\t[-0.0025939224634417357, 0.37468226410808103, ...\tBusiness & money\t9.txt\n",
      "296\t[0.3207366863736894, 0.5524853514976054, -0.48...\tTravel\t1.txt\n",
      "297\t[0.4244060160817136, 0.45012659634051966, -0.5...\tTravel\t10.txt\n",
      "298\t[0.2937218252484289, 0.52740398501471, -0.5844...\tTravel\t2.txt\n",
      "299\t[-0.0139463671688339, 0.6422751719935768, -0.6...\tTravel\t3.txt\n",
      "300\t[0.09960700667966998, 0.3342375113885559, -0.2...\tTravel\t4.txt\n",
      "301\t[-0.04262138664029187, 0.5035471854634082, -0....\tPolitical & social sciences\t5.txt\n",
      "302\t[0.3768222583359232, 0.4499174545359371, -0.67...\tPolitical & social sciences\t6.txt\n",
      "303\t[0.43418761283413504, 0.45749500018450967, -0....\tPolitical & social sciences\t7.txt\n",
      "304\t[0.2918933418782059, 0.6923211730742701, -0.20...\tHumor & Entertainment\t8.txt\n",
      "305\t[0.33254293432761617, 0.08518671482203785, -0....\tHumor & Entertainment\t9.txt\n",
      "306\t[-0.4934857931002106, 0.11483502153039708, -0....\tTeen & young Adults\t1.txt\n",
      "307\t[-0.09611500094057411, -0.20871532762801706, -...\tTeen & young Adults\t10.txt\n",
      "308\t[0.003307216144157723, 0.005713223931523985, -...\tTeen & young Adults\t2.txt\n",
      "309\t[0.27163321227237797, -0.28940085713958213, -0...\tSelf  help\t3.txt\n",
      "310\t[0.29004043491855896, -0.0040635356498566234, ...\tSelf  help\t4.txt\n",
      "311\t[0.013618091409093954, -0.12388211539501581, -...\tMedical books\t5.txt\n",
      "312\t[-0.47174940825568706, -0.13215411582983644, 0...\tMedical books\t6.txt\n",
      "313\t[-0.5636584578472996, -0.3188487955657733, -0....\tMedical books\t7.txt\n",
      "314\t[-0.09456783768722951, 0.02148465835402908, 0....\tReligion and spirituality\t8.txt\n",
      "315\t[0.053729910759766616, 0.13244119448045463, 0....\tReligion and spirituality\t9.txt\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "816 rows Ã— 3 columns\n"
     ]
    }
   ],
   "source": [
    "df_textual_m_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples:  [0, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 130, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 165, 166, 167, 168, 170, 171, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 234, 235, 237, 239, 240, 241, 242, 244, 245, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 263, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 287, 288, 289, 290, 291, 293, 294, 295, 297, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311, 312, 313, 314]\n",
      "test samples:  [1, 2, 10, 21, 23, 26, 36, 43, 48, 57, 60, 65, 75, 79, 92, 93, 106, 114, 120, 128, 129, 131, 140, 149, 159, 163, 169, 172, 173, 182, 192, 198, 205, 211, 220, 228, 236, 238, 243, 246, 261, 262, 264, 265, 270, 280, 286, 292, 296, 298, 309, 315]\n"
     ]
    }
   ],
   "source": [
    "df_preprocessed_texts_test = pd.read_pickle(path_to_preprocessed_texts_test)\n",
    "test_samples=df_preprocessed_texts_test.index.values.tolist()\n",
    "\n",
    "all_samples=set(range(0,number_of_recipes))\n",
    "train_samples=list(all_samples.difference(test_samples))\n",
    "print(\"train samples: \", train_samples)\n",
    "print(\"test samples: \", test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 2, 3, 3, 3, 4, 4, 5, 6, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 13, 13, 14, 14, 15, 15, 15, 16, 17, 17, 18, 19, 20, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 25, 25, 26, 26]\n",
      "(264, 202)\n",
      "(264, 27)\n"
     ]
    }
   ],
   "source": [
    "df_visual_m_train=df_visual_m.iloc[train_samples]\n",
    "df_visual_m_test=df_visual_m.iloc[test_samples]\n",
    "df_textual_m_train=df_textual_m.iloc[train_samples]\n",
    "df_textual_m_test=df_textual_m.iloc[test_samples]\n",
    "\n",
    "visual_m_train_inputs=list(df_visual_m_train.mean_feature_vectors.values)\n",
    "visual_m_test_inputs=list(df_visual_m_test.mean_feature_vectors.values)\n",
    "\n",
    "textual_m_train_inputs=list(df_textual_m_train.doc_embeddings.values)\n",
    "textual_m_test_inputs=list(df_textual_m_test.doc_embeddings.values)\n",
    "\n",
    "train_correct_class_ids=[labels2class_indices[l] for l in df_visual_m_train.mean_vector_labels]\n",
    "test_correct_class_ids=[labels2class_indices[l] for l in df_visual_m_test.mean_vector_labels]\n",
    "\n",
    "number_of_training_samples=len(visual_m_train_inputs)\n",
    "number_of_test_samples=len(visual_m_test_inputs)\n",
    "len_of_visual_features_vec=len(visual_m_train_inputs[0])\n",
    "len_of_textual_features_vec=len(textual_m_train_inputs[0])\n",
    "\n",
    "print(test_correct_class_ids)\n",
    "print(np.shape(visual_m_train_inputs))\n",
    "print(np.shape(textual_m_train_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "learning_rate=0.001\n",
    "hidden_state_dim = 27\n",
    "number_of_training_iterations=50000\n",
    "print_valid_every=20\n",
    "num_repeat_training=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 17  0 14]\n",
      "(4, 202)\n",
      "(4, 27)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "def remove_directory_content(path):\n",
    "    files = glob.glob(path+\"/*\")\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "def create_training_batch():\n",
    "    inputs_visual=[]\n",
    "    inputs_textual=[]\n",
    "    correct_classes=[]\n",
    "    for i in range(batch_size):\n",
    "        train_sample_index=np.random.choice(range(0,number_of_training_samples),1)[0]\n",
    "        inputs_visual.append(visual_m_train_inputs[train_sample_index])\n",
    "        inputs_textual.append(textual_m_train_inputs[train_sample_index])\n",
    "        correct_classes.append(train_correct_class_ids[train_sample_index])\n",
    "    return np.array(inputs_visual),np.array(inputs_textual),np.array(correct_classes)\n",
    "\n",
    "inputs_visual,inputs_textual,correct_classes=create_training_batch()\n",
    "print(np.array(correct_classes))\n",
    "print(np.shape(inputs_visual))\n",
    "print(np.shape(inputs_textual))\n",
    "print(np.shape(correct_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "textual = tf.placeholder(tf.float32, shape=[None,len_of_textual_features_vec], name=\"input_textual_modality\")\n",
    "target = tf.placeholder(tf.int32, shape=[None],name=\"input_correct_labels\")\n",
    "\n",
    "h_t = tf.layers.dense(textual, hidden_state_dim, activation=tf.nn.tanh, name=\"h_t\")\n",
    "\n",
    "logits = tf.layers.dense(h_t, number_of_classes, name=\"h\")\n",
    "scores = tf.nn.sigmoid(logits)\n",
    "\n",
    "multi_class_labels=tf.one_hot(target, depth=number_of_classes)\n",
    "loss = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(multi_class_labels=multi_class_labels,\n",
    "                                       logits=logits))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "correct_prediction=tf.equal(tf.argmax(logits, axis=1), tf.argmax(multi_class_labels,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"performance\"):\n",
    "    loss_ph = tf.placeholder(tf.float32,shape=None,name='loss_summary')\n",
    "    loss_summary = tf.summary.scalar('loss', loss_ph)\n",
    "    accuracy_ph = tf.placeholder(tf.float32,shape=None,name='accuracy_summary')\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy_ph)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy=0\n",
    "\n",
    "def show_validation_result(session,accuracy_res, loss_res, scores_res):\n",
    "    print(\"Validation: Loss: \", loss_res,\" Accuracy: \", accuracy_res)\n",
    "    global best_accuracy\n",
    "    if accuracy_res > best_accuracy:\n",
    "        best_accuracy=accuracy_res\n",
    "        df_performance=pd.DataFrame(data={'Accuracy':[accuracy_res], 'Loss':[loss_res]})\n",
    "        class_scores=list(np.around(scores_res,4))\n",
    "        predicted_labels = [np.argmax(one_recipe_class_scores) for one_recipe_class_scores in class_scores]\n",
    "        df_scores=pd.DataFrame(data={'Class scores':class_scores,\n",
    "                               'Predicted labels':predicted_labels,\n",
    "                               'Correct labels':test_correct_class_ids,\n",
    "                               })\n",
    "        df_res=pd.concat([df_scores, df_performance], axis=1)\n",
    "        df_res.to_pickle(path_to_save_test_results)\n",
    "        saver.save(session, model_checkpoint_path)\n",
    "        display(df_res)\n",
    "        \n",
    "    \n",
    "\n",
    "def train():\n",
    "        session=tf.InteractiveSession()\n",
    "        summ_writer = tf.summary.FileWriter(summaries_folder_name, session.graph)\n",
    "        session.run(tf.global_variables_initializer())\n",
    "    \n",
    "        print(\"Start model training\")\n",
    "    \n",
    "        for train_iter in range(number_of_training_iterations):           \n",
    "            inputs_visual,inputs_textual,correct_classes=create_training_batch()\n",
    "            _, l = session.run([train_op, loss], {textual: inputs_textual,target: correct_classes})\n",
    "            print(train_iter, \": Training: loss: \", l)\n",
    "            summ_loss = session.run(loss_summary, feed_dict={loss_ph:l})\n",
    "            summ_writer.add_summary(summ_loss, train_iter)\n",
    "        \n",
    "            if (train_iter)%print_valid_every==0:                        \n",
    "                accuracy_res, loss_res, scores_res = session.run([accuracy, loss, scores],\n",
    "                                                                          {textual: textual_m_test_inputs,\n",
    "                                                                           target: test_correct_class_ids})        \n",
    "                \n",
    "                show_validation_result(session,accuracy_res, loss_res, scores_res)\n",
    "                summ_accuracy = session.run(accuracy_summary, feed_dict={accuracy_ph:accuracy_res})\n",
    "                summ_writer.add_summary(summ_accuracy, train_iter)\n",
    "                \n",
    "                if accuracy_res==1.0:\n",
    "                    return 0\n",
    "                \n",
    "        session.close()\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n",
      "0 : Training: loss:  0.6739862\n",
      "Validation: Loss:  0.7004497  Accuracy:  0.09615385\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5773, 0.4286, 0.5809, 0.3986, 0.3182, 0.547...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.70045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.5475, 0.3959, 0.5859, 0.4025, 0.3352, 0.440...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.5055, 0.568, 0.6421, 0.4399, 0.509, 0.5851,...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.5237, 0.4336, 0.5391, 0.5193, 0.4283, 0.460...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.4734, 0.4583, 0.5588, 0.5682, 0.4996, 0.393...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.4462, 0.5193, 0.4865, 0.5024, 0.5403, 0.453...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.5835, 0.4735, 0.5664, 0.4125, 0.5393, 0.502...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.6118, 0.5023, 0.5633, 0.4653, 0.5154, 0.610...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.5649, 0.5391, 0.6213, 0.4288, 0.5845, 0.666...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.3802, 0.5371, 0.5429, 0.5477, 0.5922, 0.330...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.4648, 0.5111, 0.5768, 0.4861, 0.6109, 0.456...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.5097, 0.602, 0.6168, 0.4733, 0.5224, 0.5935...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.4591, 0.6169, 0.438, 0.6105, 0.5242, 0.5095...</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.5488, 0.4586, 0.5807, 0.4255, 0.4817, 0.488...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.4855, 0.4807, 0.4829, 0.5071, 0.4038, 0.410...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.4823, 0.5535, 0.5559, 0.5341, 0.4302, 0.493...</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.6323, 0.3341, 0.6332, 0.5777, 0.4487, 0.402...</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.5529, 0.4815, 0.6289, 0.5939, 0.518, 0.5061...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.4608, 0.4229, 0.4046, 0.5345, 0.4741, 0.453...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.472, 0.4617, 0.4155, 0.5336, 0.542, 0.4264,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.4764, 0.4624, 0.5353, 0.4584, 0.3506, 0.470...</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.5054, 0.429, 0.6257, 0.3874, 0.4572, 0.4764...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.3582, 0.6501, 0.4879, 0.5519, 0.4726, 0.509...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.3995, 0.6321, 0.4274, 0.5655, 0.6821, 0.475...</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.4554, 0.5455, 0.4244, 0.5479, 0.5268, 0.561...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.4624, 0.5121, 0.5056, 0.5169, 0.5325, 0.453...</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.4549, 0.4792, 0.4485, 0.5721, 0.473, 0.361,...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.4616, 0.5452, 0.5331, 0.5999, 0.5786, 0.423...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.4153, 0.5923, 0.4786, 0.7099, 0.6227, 0.457...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.4112, 0.586, 0.5534, 0.6242, 0.5622, 0.4223...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.5437, 0.5391, 0.4838, 0.3889, 0.5093, 0.558...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.4426, 0.5387, 0.5789, 0.5814, 0.4819, 0.505...</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.4027, 0.5252, 0.5541, 0.4926, 0.5257, 0.476...</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.4634, 0.4844, 0.4603, 0.5275, 0.5158, 0.429...</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.5339, 0.4383, 0.4571, 0.5232, 0.4585, 0.356...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.4412, 0.4936, 0.4246, 0.5025, 0.5683, 0.415...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.5839, 0.4851, 0.45, 0.5939, 0.4582, 0.4625,...</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.5687, 0.5723, 0.4513, 0.4638, 0.5514, 0.616...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.5096, 0.5948, 0.3444, 0.5007, 0.5555, 0.584...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.5156, 0.4349, 0.4964, 0.4861, 0.4031, 0.449...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.5684, 0.3884, 0.4396, 0.6301, 0.5133, 0.353...</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.5025, 0.4805, 0.4107, 0.5588, 0.4967, 0.457...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.6171, 0.3692, 0.3521, 0.5558, 0.4461, 0.451...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.4557, 0.4662, 0.3368, 0.4128, 0.3905, 0.510...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.5202, 0.4606, 0.5143, 0.4222, 0.4033, 0.563...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.4913, 0.5562, 0.5125, 0.4152, 0.5682, 0.587...</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.4433, 0.5723, 0.3624, 0.482, 0.6237, 0.4384...</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.4645, 0.5976, 0.462, 0.4014, 0.5901, 0.4548...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.5017, 0.6093, 0.5393, 0.5115, 0.4305, 0.579...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.5206, 0.6248, 0.5123, 0.5822, 0.4848, 0.561...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.5437, 0.3967, 0.5081, 0.4158, 0.4309, 0.545...</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.4057, 0.4437, 0.5066, 0.5419, 0.4823, 0.291...</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.5773, 0.4286, 0.5809, 0.3986, 0.3182, 0.547...               0   \n",
       "1   [0.5475, 0.3959, 0.5859, 0.4025, 0.3352, 0.440...               0   \n",
       "2   [0.5055, 0.568, 0.6421, 0.4399, 0.509, 0.5851,...               0   \n",
       "3   [0.5237, 0.4336, 0.5391, 0.5193, 0.4283, 0.460...               1   \n",
       "4   [0.4734, 0.4583, 0.5588, 0.5682, 0.4996, 0.393...               1   \n",
       "5   [0.4462, 0.5193, 0.4865, 0.5024, 0.5403, 0.453...               2   \n",
       "6   [0.5835, 0.4735, 0.5664, 0.4125, 0.5393, 0.502...               3   \n",
       "7   [0.6118, 0.5023, 0.5633, 0.4653, 0.5154, 0.610...               3   \n",
       "8   [0.5649, 0.5391, 0.6213, 0.4288, 0.5845, 0.666...               3   \n",
       "9   [0.3802, 0.5371, 0.5429, 0.5477, 0.5922, 0.330...               4   \n",
       "10  [0.4648, 0.5111, 0.5768, 0.4861, 0.6109, 0.456...               4   \n",
       "11  [0.5097, 0.602, 0.6168, 0.4733, 0.5224, 0.5935...               5   \n",
       "12  [0.4591, 0.6169, 0.438, 0.6105, 0.5242, 0.5095...               6   \n",
       "13  [0.5488, 0.4586, 0.5807, 0.4255, 0.4817, 0.488...               7   \n",
       "14  [0.4855, 0.4807, 0.4829, 0.5071, 0.4038, 0.410...               8   \n",
       "15  [0.4823, 0.5535, 0.5559, 0.5341, 0.4302, 0.493...               8   \n",
       "16  [0.6323, 0.3341, 0.6332, 0.5777, 0.4487, 0.402...               9   \n",
       "17  [0.5529, 0.4815, 0.6289, 0.5939, 0.518, 0.5061...               9   \n",
       "18  [0.4608, 0.4229, 0.4046, 0.5345, 0.4741, 0.453...              10   \n",
       "19  [0.472, 0.4617, 0.4155, 0.5336, 0.542, 0.4264,...              10   \n",
       "20  [0.4764, 0.4624, 0.5353, 0.4584, 0.3506, 0.470...              11   \n",
       "21  [0.5054, 0.429, 0.6257, 0.3874, 0.4572, 0.4764...              11   \n",
       "22  [0.3582, 0.6501, 0.4879, 0.5519, 0.4726, 0.509...              12   \n",
       "23  [0.3995, 0.6321, 0.4274, 0.5655, 0.6821, 0.475...              13   \n",
       "24  [0.4554, 0.5455, 0.4244, 0.5479, 0.5268, 0.561...              13   \n",
       "25  [0.4624, 0.5121, 0.5056, 0.5169, 0.5325, 0.453...              14   \n",
       "26  [0.4549, 0.4792, 0.4485, 0.5721, 0.473, 0.361,...              14   \n",
       "27  [0.4616, 0.5452, 0.5331, 0.5999, 0.5786, 0.423...              15   \n",
       "28  [0.4153, 0.5923, 0.4786, 0.7099, 0.6227, 0.457...              15   \n",
       "29  [0.4112, 0.586, 0.5534, 0.6242, 0.5622, 0.4223...              15   \n",
       "30  [0.5437, 0.5391, 0.4838, 0.3889, 0.5093, 0.558...              16   \n",
       "31  [0.4426, 0.5387, 0.5789, 0.5814, 0.4819, 0.505...              17   \n",
       "32  [0.4027, 0.5252, 0.5541, 0.4926, 0.5257, 0.476...              17   \n",
       "33  [0.4634, 0.4844, 0.4603, 0.5275, 0.5158, 0.429...              18   \n",
       "34  [0.5339, 0.4383, 0.4571, 0.5232, 0.4585, 0.356...              19   \n",
       "35  [0.4412, 0.4936, 0.4246, 0.5025, 0.5683, 0.415...              20   \n",
       "36  [0.5839, 0.4851, 0.45, 0.5939, 0.4582, 0.4625,...              21   \n",
       "37  [0.5687, 0.5723, 0.4513, 0.4638, 0.5514, 0.616...              21   \n",
       "38  [0.5096, 0.5948, 0.3444, 0.5007, 0.5555, 0.584...              22   \n",
       "39  [0.5156, 0.4349, 0.4964, 0.4861, 0.4031, 0.449...              22   \n",
       "40  [0.5684, 0.3884, 0.4396, 0.6301, 0.5133, 0.353...              22   \n",
       "41  [0.5025, 0.4805, 0.4107, 0.5588, 0.4967, 0.457...              22   \n",
       "42  [0.6171, 0.3692, 0.3521, 0.5558, 0.4461, 0.451...              23   \n",
       "43  [0.4557, 0.4662, 0.3368, 0.4128, 0.3905, 0.510...              23   \n",
       "44  [0.5202, 0.4606, 0.5143, 0.4222, 0.4033, 0.563...              23   \n",
       "45  [0.4913, 0.5562, 0.5125, 0.4152, 0.5682, 0.587...              23   \n",
       "46  [0.4433, 0.5723, 0.3624, 0.482, 0.6237, 0.4384...              24   \n",
       "47  [0.4645, 0.5976, 0.462, 0.4014, 0.5901, 0.4548...              24   \n",
       "48  [0.5017, 0.6093, 0.5393, 0.5115, 0.4305, 0.579...              25   \n",
       "49  [0.5206, 0.6248, 0.5123, 0.5822, 0.4848, 0.561...              25   \n",
       "50  [0.5437, 0.3967, 0.5081, 0.4158, 0.4309, 0.545...              26   \n",
       "51  [0.4057, 0.4437, 0.5066, 0.5419, 0.4823, 0.291...              26   \n",
       "\n",
       "    Predicted labels  Accuracy     Loss  \n",
       "0                  2  0.096154  0.70045  \n",
       "1                 26       NaN      NaN  \n",
       "2                  8       NaN      NaN  \n",
       "3                 25       NaN      NaN  \n",
       "4                 10       NaN      NaN  \n",
       "5                 10       NaN      NaN  \n",
       "6                  9       NaN      NaN  \n",
       "7                 16       NaN      NaN  \n",
       "8                 22       NaN      NaN  \n",
       "9                 12       NaN      NaN  \n",
       "10                 4       NaN      NaN  \n",
       "11                 2       NaN      NaN  \n",
       "12                15       NaN      NaN  \n",
       "13                10       NaN      NaN  \n",
       "14                12       NaN      NaN  \n",
       "15                24       NaN      NaN  \n",
       "16                26       NaN      NaN  \n",
       "17                 2       NaN      NaN  \n",
       "18                12       NaN      NaN  \n",
       "19                10       NaN      NaN  \n",
       "20                21       NaN      NaN  \n",
       "21                 2       NaN      NaN  \n",
       "22                 1       NaN      NaN  \n",
       "23                 4       NaN      NaN  \n",
       "24                13       NaN      NaN  \n",
       "25                12       NaN      NaN  \n",
       "26                15       NaN      NaN  \n",
       "27                17       NaN      NaN  \n",
       "28                 3       NaN      NaN  \n",
       "29                 3       NaN      NaN  \n",
       "30                17       NaN      NaN  \n",
       "31                14       NaN      NaN  \n",
       "32                15       NaN      NaN  \n",
       "33                10       NaN      NaN  \n",
       "34                12       NaN      NaN  \n",
       "35                10       NaN      NaN  \n",
       "36                 7       NaN      NaN  \n",
       "37                22       NaN      NaN  \n",
       "38                22       NaN      NaN  \n",
       "39                 7       NaN      NaN  \n",
       "40                11       NaN      NaN  \n",
       "41                 7       NaN      NaN  \n",
       "42                16       NaN      NaN  \n",
       "43                 8       NaN      NaN  \n",
       "44                16       NaN      NaN  \n",
       "45                 9       NaN      NaN  \n",
       "46                15       NaN      NaN  \n",
       "47                22       NaN      NaN  \n",
       "48                 1       NaN      NaN  \n",
       "49                25       NaN      NaN  \n",
       "50                16       NaN      NaN  \n",
       "51                12       NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Training: loss:  0.67612404\n",
      "2 : Training: loss:  0.6831408\n",
      "3 : Training: loss:  0.6744434\n",
      "4 : Training: loss:  0.69870806\n",
      "5 : Training: loss:  0.71235013\n",
      "6 : Training: loss:  0.6852699\n",
      "7 : Training: loss:  0.6756886\n",
      "8 : Training: loss:  0.728265\n",
      "9 : Training: loss:  0.67974\n",
      "10 : Training: loss:  0.6878726\n",
      "11 : Training: loss:  0.71393424\n",
      "12 : Training: loss:  0.68292415\n",
      "13 : Training: loss:  0.7075807\n",
      "14 : Training: loss:  0.71384877\n",
      "15 : Training: loss:  0.6776031\n",
      "16 : Training: loss:  0.6996258\n",
      "17 : Training: loss:  0.68505996\n",
      "18 : Training: loss:  0.6895129\n",
      "19 : Training: loss:  0.7150982\n",
      "20 : Training: loss:  0.67453295\n",
      "Validation: Loss:  0.6802102  Accuracy:  0.13461539\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5783, 0.4163, 0.5753, 0.3916, 0.311, 0.547,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.68021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.549, 0.385, 0.5785, 0.3964, 0.3314, 0.4391,...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.511, 0.5652, 0.6367, 0.4415, 0.5075, 0.5916...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.5201, 0.4146, 0.5294, 0.496, 0.4138, 0.4577...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.4638, 0.438, 0.5472, 0.5425, 0.4808, 0.3867...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.4376, 0.4955, 0.4834, 0.4798, 0.5232, 0.441...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.5801, 0.4609, 0.5587, 0.4087, 0.5343, 0.498...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.6042, 0.4906, 0.5608, 0.4598, 0.5027, 0.602...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.5649, 0.54, 0.623, 0.4373, 0.583, 0.6655, 0...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.3812, 0.5121, 0.5274, 0.5275, 0.5791, 0.329...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.4608, 0.4916, 0.5657, 0.469, 0.5991, 0.4533...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.5086, 0.5884, 0.609, 0.465, 0.515, 0.5896, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.4588, 0.5963, 0.4336, 0.5942, 0.5103, 0.504...</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.5436, 0.4408, 0.573, 0.4081, 0.4642, 0.4866...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.4735, 0.4511, 0.4681, 0.4812, 0.3879, 0.398...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.4801, 0.5293, 0.5456, 0.5231, 0.4221, 0.485...</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.6228, 0.3182, 0.6267, 0.555, 0.4284, 0.3942...</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.5466, 0.4615, 0.6256, 0.5745, 0.4975, 0.500...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.4528, 0.3987, 0.3986, 0.5078, 0.4534, 0.442...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.465, 0.4356, 0.4092, 0.5055, 0.52, 0.4174, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.4735, 0.4451, 0.5263, 0.4432, 0.3401, 0.467...</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.5014, 0.4096, 0.6185, 0.3742, 0.4476, 0.471...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.3599, 0.633, 0.4822, 0.5458, 0.4677, 0.5041...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.4006, 0.6219, 0.4248, 0.5592, 0.6756, 0.475...</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.4509, 0.5279, 0.4205, 0.5395, 0.5171, 0.551...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.4605, 0.4886, 0.5003, 0.502, 0.5198, 0.4471...</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.451, 0.4566, 0.4399, 0.5557, 0.4603, 0.353,...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.4563, 0.5164, 0.522, 0.5743, 0.5588, 0.4193...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.4077, 0.5653, 0.471, 0.6873, 0.602, 0.4466,...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.4076, 0.5571, 0.5427, 0.6038, 0.5457, 0.415...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.5445, 0.5175, 0.4776, 0.376, 0.4982, 0.5561...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.443, 0.5203, 0.5734, 0.5721, 0.4725, 0.5018...</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.4044, 0.5084, 0.5487, 0.4839, 0.5187, 0.474...</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.4615, 0.4613, 0.4542, 0.5083, 0.5027, 0.425...</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.5213, 0.4102, 0.4422, 0.4959, 0.4377, 0.346...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.4385, 0.4712, 0.4197, 0.478, 0.5485, 0.4117...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.5776, 0.4646, 0.4404, 0.5782, 0.4449, 0.452...</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.5663, 0.5557, 0.4482, 0.4593, 0.5446, 0.609...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.5065, 0.5806, 0.3422, 0.49, 0.5414, 0.5761,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.5102, 0.4114, 0.4871, 0.4668, 0.3867, 0.440...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.56, 0.3675, 0.4308, 0.6053, 0.4872, 0.3467,...</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.4995, 0.4607, 0.4034, 0.5426, 0.4815, 0.451...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.6074, 0.3564, 0.347, 0.5388, 0.4318, 0.4419...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.45, 0.4487, 0.3316, 0.4036, 0.3871, 0.4995,...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.5134, 0.4413, 0.51, 0.4089, 0.3926, 0.5513,...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.4977, 0.5542, 0.5135, 0.4256, 0.5766, 0.589...</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.436, 0.5511, 0.3533, 0.4646, 0.607, 0.43, 0...</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.4601, 0.5809, 0.4533, 0.393, 0.5813, 0.4491...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.5014, 0.5796, 0.5295, 0.4936, 0.4163, 0.569...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.5153, 0.5948, 0.5003, 0.5606, 0.4642, 0.548...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.543, 0.3893, 0.5063, 0.4105, 0.4231, 0.5446...</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.3998, 0.4115, 0.4941, 0.5156, 0.4656, 0.284...</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.5783, 0.4163, 0.5753, 0.3916, 0.311, 0.547,...               0   \n",
       "1   [0.549, 0.385, 0.5785, 0.3964, 0.3314, 0.4391,...               0   \n",
       "2   [0.511, 0.5652, 0.6367, 0.4415, 0.5075, 0.5916...               0   \n",
       "3   [0.5201, 0.4146, 0.5294, 0.496, 0.4138, 0.4577...               1   \n",
       "4   [0.4638, 0.438, 0.5472, 0.5425, 0.4808, 0.3867...               1   \n",
       "5   [0.4376, 0.4955, 0.4834, 0.4798, 0.5232, 0.441...               2   \n",
       "6   [0.5801, 0.4609, 0.5587, 0.4087, 0.5343, 0.498...               3   \n",
       "7   [0.6042, 0.4906, 0.5608, 0.4598, 0.5027, 0.602...               3   \n",
       "8   [0.5649, 0.54, 0.623, 0.4373, 0.583, 0.6655, 0...               3   \n",
       "9   [0.3812, 0.5121, 0.5274, 0.5275, 0.5791, 0.329...               4   \n",
       "10  [0.4608, 0.4916, 0.5657, 0.469, 0.5991, 0.4533...               4   \n",
       "11  [0.5086, 0.5884, 0.609, 0.465, 0.515, 0.5896, ...               5   \n",
       "12  [0.4588, 0.5963, 0.4336, 0.5942, 0.5103, 0.504...               6   \n",
       "13  [0.5436, 0.4408, 0.573, 0.4081, 0.4642, 0.4866...               7   \n",
       "14  [0.4735, 0.4511, 0.4681, 0.4812, 0.3879, 0.398...               8   \n",
       "15  [0.4801, 0.5293, 0.5456, 0.5231, 0.4221, 0.485...               8   \n",
       "16  [0.6228, 0.3182, 0.6267, 0.555, 0.4284, 0.3942...               9   \n",
       "17  [0.5466, 0.4615, 0.6256, 0.5745, 0.4975, 0.500...               9   \n",
       "18  [0.4528, 0.3987, 0.3986, 0.5078, 0.4534, 0.442...              10   \n",
       "19  [0.465, 0.4356, 0.4092, 0.5055, 0.52, 0.4174, ...              10   \n",
       "20  [0.4735, 0.4451, 0.5263, 0.4432, 0.3401, 0.467...              11   \n",
       "21  [0.5014, 0.4096, 0.6185, 0.3742, 0.4476, 0.471...              11   \n",
       "22  [0.3599, 0.633, 0.4822, 0.5458, 0.4677, 0.5041...              12   \n",
       "23  [0.4006, 0.6219, 0.4248, 0.5592, 0.6756, 0.475...              13   \n",
       "24  [0.4509, 0.5279, 0.4205, 0.5395, 0.5171, 0.551...              13   \n",
       "25  [0.4605, 0.4886, 0.5003, 0.502, 0.5198, 0.4471...              14   \n",
       "26  [0.451, 0.4566, 0.4399, 0.5557, 0.4603, 0.353,...              14   \n",
       "27  [0.4563, 0.5164, 0.522, 0.5743, 0.5588, 0.4193...              15   \n",
       "28  [0.4077, 0.5653, 0.471, 0.6873, 0.602, 0.4466,...              15   \n",
       "29  [0.4076, 0.5571, 0.5427, 0.6038, 0.5457, 0.415...              15   \n",
       "30  [0.5445, 0.5175, 0.4776, 0.376, 0.4982, 0.5561...              16   \n",
       "31  [0.443, 0.5203, 0.5734, 0.5721, 0.4725, 0.5018...              17   \n",
       "32  [0.4044, 0.5084, 0.5487, 0.4839, 0.5187, 0.474...              17   \n",
       "33  [0.4615, 0.4613, 0.4542, 0.5083, 0.5027, 0.425...              18   \n",
       "34  [0.5213, 0.4102, 0.4422, 0.4959, 0.4377, 0.346...              19   \n",
       "35  [0.4385, 0.4712, 0.4197, 0.478, 0.5485, 0.4117...              20   \n",
       "36  [0.5776, 0.4646, 0.4404, 0.5782, 0.4449, 0.452...              21   \n",
       "37  [0.5663, 0.5557, 0.4482, 0.4593, 0.5446, 0.609...              21   \n",
       "38  [0.5065, 0.5806, 0.3422, 0.49, 0.5414, 0.5761,...              22   \n",
       "39  [0.5102, 0.4114, 0.4871, 0.4668, 0.3867, 0.440...              22   \n",
       "40  [0.56, 0.3675, 0.4308, 0.6053, 0.4872, 0.3467,...              22   \n",
       "41  [0.4995, 0.4607, 0.4034, 0.5426, 0.4815, 0.451...              22   \n",
       "42  [0.6074, 0.3564, 0.347, 0.5388, 0.4318, 0.4419...              23   \n",
       "43  [0.45, 0.4487, 0.3316, 0.4036, 0.3871, 0.4995,...              23   \n",
       "44  [0.5134, 0.4413, 0.51, 0.4089, 0.3926, 0.5513,...              23   \n",
       "45  [0.4977, 0.5542, 0.5135, 0.4256, 0.5766, 0.589...              23   \n",
       "46  [0.436, 0.5511, 0.3533, 0.4646, 0.607, 0.43, 0...              24   \n",
       "47  [0.4601, 0.5809, 0.4533, 0.393, 0.5813, 0.4491...              24   \n",
       "48  [0.5014, 0.5796, 0.5295, 0.4936, 0.4163, 0.569...              25   \n",
       "49  [0.5153, 0.5948, 0.5003, 0.5606, 0.4642, 0.548...              25   \n",
       "50  [0.543, 0.3893, 0.5063, 0.4105, 0.4231, 0.5446...              26   \n",
       "51  [0.3998, 0.4115, 0.4941, 0.5156, 0.4656, 0.284...              26   \n",
       "\n",
       "    Predicted labels  Accuracy     Loss  \n",
       "0                  0  0.134615  0.68021  \n",
       "1                 26       NaN      NaN  \n",
       "2                  8       NaN      NaN  \n",
       "3                 25       NaN      NaN  \n",
       "4                 10       NaN      NaN  \n",
       "5                 10       NaN      NaN  \n",
       "6                 16       NaN      NaN  \n",
       "7                 16       NaN      NaN  \n",
       "8                 22       NaN      NaN  \n",
       "9                 12       NaN      NaN  \n",
       "10                 4       NaN      NaN  \n",
       "11                26       NaN      NaN  \n",
       "12                15       NaN      NaN  \n",
       "13                10       NaN      NaN  \n",
       "14                12       NaN      NaN  \n",
       "15                24       NaN      NaN  \n",
       "16                26       NaN      NaN  \n",
       "17                 2       NaN      NaN  \n",
       "18                10       NaN      NaN  \n",
       "19                10       NaN      NaN  \n",
       "20                21       NaN      NaN  \n",
       "21                 2       NaN      NaN  \n",
       "22                 1       NaN      NaN  \n",
       "23                 4       NaN      NaN  \n",
       "24                13       NaN      NaN  \n",
       "25                12       NaN      NaN  \n",
       "26                15       NaN      NaN  \n",
       "27                17       NaN      NaN  \n",
       "28                 3       NaN      NaN  \n",
       "29                 3       NaN      NaN  \n",
       "30                17       NaN      NaN  \n",
       "31                14       NaN      NaN  \n",
       "32                15       NaN      NaN  \n",
       "33                10       NaN      NaN  \n",
       "34                12       NaN      NaN  \n",
       "35                10       NaN      NaN  \n",
       "36                 7       NaN      NaN  \n",
       "37                22       NaN      NaN  \n",
       "38                22       NaN      NaN  \n",
       "39                 7       NaN      NaN  \n",
       "40                11       NaN      NaN  \n",
       "41                 7       NaN      NaN  \n",
       "42                16       NaN      NaN  \n",
       "43                 8       NaN      NaN  \n",
       "44                16       NaN      NaN  \n",
       "45                 9       NaN      NaN  \n",
       "46                15       NaN      NaN  \n",
       "47                22       NaN      NaN  \n",
       "48                 1       NaN      NaN  \n",
       "49                25       NaN      NaN  \n",
       "50                16       NaN      NaN  \n",
       "51                12       NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 : Training: loss:  0.70796126\n",
      "22 : Training: loss:  0.68469197\n",
      "23 : Training: loss:  0.6830398\n",
      "24 : Training: loss:  0.6757053\n",
      "25 : Training: loss:  0.6668065\n",
      "26 : Training: loss:  0.66289115\n",
      "27 : Training: loss:  0.67156476\n",
      "28 : Training: loss:  0.6964206\n",
      "29 : Training: loss:  0.6584073\n",
      "30 : Training: loss:  0.68664366\n",
      "31 : Training: loss:  0.65477854\n",
      "32 : Training: loss:  0.64978904\n",
      "33 : Training: loss:  0.645622\n",
      "34 : Training: loss:  0.68069196\n",
      "35 : Training: loss:  0.6468587\n",
      "36 : Training: loss:  0.6681946\n",
      "37 : Training: loss:  0.650808\n",
      "38 : Training: loss:  0.66384685\n",
      "39 : Training: loss:  0.6597024\n",
      "40 : Training: loss:  0.67060024\n",
      "Validation: Loss:  0.6598941  Accuracy:  0.13461539\n",
      "41 : Training: loss:  0.6422047\n",
      "42 : Training: loss:  0.6511383\n",
      "43 : Training: loss:  0.67141837\n",
      "44 : Training: loss:  0.6550969\n",
      "45 : Training: loss:  0.6611154\n",
      "46 : Training: loss:  0.65435475\n",
      "47 : Training: loss:  0.6422294\n",
      "48 : Training: loss:  0.67487186\n",
      "49 : Training: loss:  0.6582981\n",
      "50 : Training: loss:  0.6546\n",
      "51 : Training: loss:  0.6615012\n",
      "52 : Training: loss:  0.6563286\n",
      "53 : Training: loss:  0.65013087\n",
      "54 : Training: loss:  0.6426739\n",
      "55 : Training: loss:  0.67352945\n",
      "56 : Training: loss:  0.6806697\n",
      "57 : Training: loss:  0.6441312\n",
      "58 : Training: loss:  0.64383596\n",
      "59 : Training: loss:  0.654445\n",
      "60 : Training: loss:  0.66598725\n",
      "Validation: Loss:  0.63705677  Accuracy:  0.15384616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5798, 0.375, 0.5491, 0.3737, 0.2912, 0.5293...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.637057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.5527, 0.3487, 0.5516, 0.379, 0.3144, 0.4203...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.5195, 0.5274, 0.6114, 0.4242, 0.4785, 0.586...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.5114, 0.3918, 0.5054, 0.4552, 0.3866, 0.451...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.4439, 0.4096, 0.52, 0.4849, 0.4336, 0.3801,...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.4174, 0.4567, 0.4687, 0.4397, 0.4907, 0.421...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.5671, 0.4252, 0.5344, 0.4029, 0.5126, 0.479...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.5758, 0.4374, 0.5294, 0.447, 0.4661, 0.5661...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.5565, 0.5018, 0.6022, 0.4439, 0.5659, 0.638...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.38, 0.4725, 0.4976, 0.4882, 0.5458, 0.3326,...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.4471, 0.4619, 0.5399, 0.426, 0.5606, 0.4496...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.498, 0.5471, 0.5767, 0.4395, 0.4824, 0.5806...</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.4549, 0.5692, 0.4263, 0.5565, 0.4815, 0.504...</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.5302, 0.3919, 0.5399, 0.3661, 0.4178, 0.470...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.4486, 0.4096, 0.4359, 0.4308, 0.3527, 0.384...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.4709, 0.4721, 0.5104, 0.498, 0.3984, 0.4615...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.6018, 0.2848, 0.5979, 0.5194, 0.3925, 0.369...</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.5283, 0.4189, 0.6002, 0.5307, 0.4541, 0.482...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.4359, 0.3632, 0.3821, 0.46, 0.423, 0.4275, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.448, 0.3983, 0.3919, 0.4555, 0.4846, 0.407,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.4694, 0.4091, 0.5065, 0.4122, 0.3197, 0.455...</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.487, 0.3905, 0.5994, 0.3583, 0.4308, 0.4602...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.3626, 0.5815, 0.4634, 0.516, 0.4428, 0.4863...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.4, 0.5864, 0.4127, 0.5395, 0.6547, 0.4724, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.4362, 0.4938, 0.407, 0.5244, 0.4978, 0.537,...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.4497, 0.4506, 0.484, 0.4711, 0.4917, 0.4361...</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.4441, 0.4244, 0.4286, 0.5343, 0.4463, 0.343...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.4427, 0.474, 0.4967, 0.5283, 0.5243, 0.4145...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.3872, 0.5208, 0.4497, 0.6415, 0.558, 0.431,...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.394, 0.5131, 0.517, 0.5608, 0.5101, 0.4064,...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.5405, 0.4812, 0.4572, 0.3509, 0.474, 0.5502...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.443, 0.4789, 0.5577, 0.5512, 0.4518, 0.487,...</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.4048, 0.4642, 0.53, 0.4626, 0.4965, 0.4551,...</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.4568, 0.4173, 0.4395, 0.4639, 0.4754, 0.417...</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.4961, 0.3869, 0.4226, 0.4601, 0.4089, 0.345...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.4297, 0.4187, 0.3963, 0.4238, 0.5062, 0.393...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.5622, 0.4336, 0.4179, 0.5479, 0.4174, 0.437...</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.5535, 0.5013, 0.4231, 0.437, 0.5214, 0.5785...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.493, 0.5456, 0.3298, 0.4657, 0.5124, 0.5592...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.4951, 0.3742, 0.4608, 0.4335, 0.3593, 0.422...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.5368, 0.3387, 0.4034, 0.5649, 0.4417, 0.332...</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.4905, 0.4269, 0.3867, 0.5117, 0.4566, 0.435...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.5913, 0.343, 0.3404, 0.5102, 0.4135, 0.4319...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.4413, 0.4297, 0.3274, 0.3807, 0.384, 0.4877...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.4912, 0.4043, 0.4854, 0.38, 0.3664, 0.5216,...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.5098, 0.5417, 0.5139, 0.4398, 0.5826, 0.587...</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.4167, 0.5137, 0.3366, 0.4305, 0.5695, 0.418...</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.4472, 0.543, 0.4333, 0.3748, 0.5537, 0.4378...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.4869, 0.522, 0.4954, 0.4556, 0.3811, 0.5498...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.4928, 0.5369, 0.4634, 0.513, 0.4164, 0.5265...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.5422, 0.3544, 0.4858, 0.3881, 0.3995, 0.525...</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.3886, 0.3638, 0.4668, 0.4717, 0.4365, 0.272...</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.5798, 0.375, 0.5491, 0.3737, 0.2912, 0.5293...               0   \n",
       "1   [0.5527, 0.3487, 0.5516, 0.379, 0.3144, 0.4203...               0   \n",
       "2   [0.5195, 0.5274, 0.6114, 0.4242, 0.4785, 0.586...               0   \n",
       "3   [0.5114, 0.3918, 0.5054, 0.4552, 0.3866, 0.451...               1   \n",
       "4   [0.4439, 0.4096, 0.52, 0.4849, 0.4336, 0.3801,...               1   \n",
       "5   [0.4174, 0.4567, 0.4687, 0.4397, 0.4907, 0.421...               2   \n",
       "6   [0.5671, 0.4252, 0.5344, 0.4029, 0.5126, 0.479...               3   \n",
       "7   [0.5758, 0.4374, 0.5294, 0.447, 0.4661, 0.5661...               3   \n",
       "8   [0.5565, 0.5018, 0.6022, 0.4439, 0.5659, 0.638...               3   \n",
       "9   [0.38, 0.4725, 0.4976, 0.4882, 0.5458, 0.3326,...               4   \n",
       "10  [0.4471, 0.4619, 0.5399, 0.426, 0.5606, 0.4496...               4   \n",
       "11  [0.498, 0.5471, 0.5767, 0.4395, 0.4824, 0.5806...               5   \n",
       "12  [0.4549, 0.5692, 0.4263, 0.5565, 0.4815, 0.504...               6   \n",
       "13  [0.5302, 0.3919, 0.5399, 0.3661, 0.4178, 0.470...               7   \n",
       "14  [0.4486, 0.4096, 0.4359, 0.4308, 0.3527, 0.384...               8   \n",
       "15  [0.4709, 0.4721, 0.5104, 0.498, 0.3984, 0.4615...               8   \n",
       "16  [0.6018, 0.2848, 0.5979, 0.5194, 0.3925, 0.369...               9   \n",
       "17  [0.5283, 0.4189, 0.6002, 0.5307, 0.4541, 0.482...               9   \n",
       "18  [0.4359, 0.3632, 0.3821, 0.46, 0.423, 0.4275, ...              10   \n",
       "19  [0.448, 0.3983, 0.3919, 0.4555, 0.4846, 0.407,...              10   \n",
       "20  [0.4694, 0.4091, 0.5065, 0.4122, 0.3197, 0.455...              11   \n",
       "21  [0.487, 0.3905, 0.5994, 0.3583, 0.4308, 0.4602...              11   \n",
       "22  [0.3626, 0.5815, 0.4634, 0.516, 0.4428, 0.4863...              12   \n",
       "23  [0.4, 0.5864, 0.4127, 0.5395, 0.6547, 0.4724, ...              13   \n",
       "24  [0.4362, 0.4938, 0.407, 0.5244, 0.4978, 0.537,...              13   \n",
       "25  [0.4497, 0.4506, 0.484, 0.4711, 0.4917, 0.4361...              14   \n",
       "26  [0.4441, 0.4244, 0.4286, 0.5343, 0.4463, 0.343...              14   \n",
       "27  [0.4427, 0.474, 0.4967, 0.5283, 0.5243, 0.4145...              15   \n",
       "28  [0.3872, 0.5208, 0.4497, 0.6415, 0.558, 0.431,...              15   \n",
       "29  [0.394, 0.5131, 0.517, 0.5608, 0.5101, 0.4064,...              15   \n",
       "30  [0.5405, 0.4812, 0.4572, 0.3509, 0.474, 0.5502...              16   \n",
       "31  [0.443, 0.4789, 0.5577, 0.5512, 0.4518, 0.487,...              17   \n",
       "32  [0.4048, 0.4642, 0.53, 0.4626, 0.4965, 0.4551,...              17   \n",
       "33  [0.4568, 0.4173, 0.4395, 0.4639, 0.4754, 0.417...              18   \n",
       "34  [0.4961, 0.3869, 0.4226, 0.4601, 0.4089, 0.345...              19   \n",
       "35  [0.4297, 0.4187, 0.3963, 0.4238, 0.5062, 0.393...              20   \n",
       "36  [0.5622, 0.4336, 0.4179, 0.5479, 0.4174, 0.437...              21   \n",
       "37  [0.5535, 0.5013, 0.4231, 0.437, 0.5214, 0.5785...              21   \n",
       "38  [0.493, 0.5456, 0.3298, 0.4657, 0.5124, 0.5592...              22   \n",
       "39  [0.4951, 0.3742, 0.4608, 0.4335, 0.3593, 0.422...              22   \n",
       "40  [0.5368, 0.3387, 0.4034, 0.5649, 0.4417, 0.332...              22   \n",
       "41  [0.4905, 0.4269, 0.3867, 0.5117, 0.4566, 0.435...              22   \n",
       "42  [0.5913, 0.343, 0.3404, 0.5102, 0.4135, 0.4319...              23   \n",
       "43  [0.4413, 0.4297, 0.3274, 0.3807, 0.384, 0.4877...              23   \n",
       "44  [0.4912, 0.4043, 0.4854, 0.38, 0.3664, 0.5216,...              23   \n",
       "45  [0.5098, 0.5417, 0.5139, 0.4398, 0.5826, 0.587...              23   \n",
       "46  [0.4167, 0.5137, 0.3366, 0.4305, 0.5695, 0.418...              24   \n",
       "47  [0.4472, 0.543, 0.4333, 0.3748, 0.5537, 0.4378...              24   \n",
       "48  [0.4869, 0.522, 0.4954, 0.4556, 0.3811, 0.5498...              25   \n",
       "49  [0.4928, 0.5369, 0.4634, 0.513, 0.4164, 0.5265...              25   \n",
       "50  [0.5422, 0.3544, 0.4858, 0.3881, 0.3995, 0.525...              26   \n",
       "51  [0.3886, 0.3638, 0.4668, 0.4717, 0.4365, 0.272...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.153846  0.637057  \n",
       "1                 26       NaN       NaN  \n",
       "2                  8       NaN       NaN  \n",
       "3                 25       NaN       NaN  \n",
       "4                 10       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                 16       NaN       NaN  \n",
       "7                 16       NaN       NaN  \n",
       "8                  5       NaN       NaN  \n",
       "9                 12       NaN       NaN  \n",
       "10                 8       NaN       NaN  \n",
       "11                26       NaN       NaN  \n",
       "12                17       NaN       NaN  \n",
       "13                20       NaN       NaN  \n",
       "14                12       NaN       NaN  \n",
       "15                12       NaN       NaN  \n",
       "16                26       NaN       NaN  \n",
       "17                 2       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                21       NaN       NaN  \n",
       "21                 2       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                 4       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                12       NaN       NaN  \n",
       "26                15       NaN       NaN  \n",
       "27                17       NaN       NaN  \n",
       "28                 3       NaN       NaN  \n",
       "29                11       NaN       NaN  \n",
       "30                17       NaN       NaN  \n",
       "31                14       NaN       NaN  \n",
       "32                15       NaN       NaN  \n",
       "33                10       NaN       NaN  \n",
       "34                12       NaN       NaN  \n",
       "35                10       NaN       NaN  \n",
       "36                 7       NaN       NaN  \n",
       "37                 8       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                 7       NaN       NaN  \n",
       "40                16       NaN       NaN  \n",
       "41                21       NaN       NaN  \n",
       "42                16       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                16       NaN       NaN  \n",
       "45                 9       NaN       NaN  \n",
       "46                15       NaN       NaN  \n",
       "47                12       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                16       NaN       NaN  \n",
       "51                12       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 : Training: loss:  0.60999006\n",
      "62 : Training: loss:  0.6260998\n",
      "63 : Training: loss:  0.6087924\n",
      "64 : Training: loss:  0.67291045\n",
      "65 : Training: loss:  0.63432664\n",
      "66 : Training: loss:  0.6406574\n",
      "67 : Training: loss:  0.62870294\n",
      "68 : Training: loss:  0.63043237\n",
      "69 : Training: loss:  0.63307464\n",
      "70 : Training: loss:  0.618263\n",
      "71 : Training: loss:  0.62605923\n",
      "72 : Training: loss:  0.63740575\n",
      "73 : Training: loss:  0.61788523\n",
      "74 : Training: loss:  0.6356586\n",
      "75 : Training: loss:  0.62981635\n",
      "76 : Training: loss:  0.64847\n",
      "77 : Training: loss:  0.6002993\n",
      "78 : Training: loss:  0.6163963\n",
      "79 : Training: loss:  0.6431071\n",
      "80 : Training: loss:  0.6223437\n",
      "Validation: Loss:  0.6118843  Accuracy:  0.13461539\n",
      "81 : Training: loss:  0.6131932\n",
      "82 : Training: loss:  0.62318027\n",
      "83 : Training: loss:  0.6244878\n",
      "84 : Training: loss:  0.619375\n",
      "85 : Training: loss:  0.6016473\n",
      "86 : Training: loss:  0.61276436\n",
      "87 : Training: loss:  0.5997396\n",
      "88 : Training: loss:  0.6167815\n",
      "89 : Training: loss:  0.62704664\n",
      "90 : Training: loss:  0.60388875\n",
      "91 : Training: loss:  0.5793298\n",
      "92 : Training: loss:  0.5797093\n",
      "93 : Training: loss:  0.6265198\n",
      "94 : Training: loss:  0.5923767\n",
      "95 : Training: loss:  0.6211265\n",
      "96 : Training: loss:  0.56589335\n",
      "97 : Training: loss:  0.57594657\n",
      "98 : Training: loss:  0.5814281\n",
      "99 : Training: loss:  0.57758117\n",
      "100 : Training: loss:  0.5350478\n",
      "Validation: Loss:  0.5815519  Accuracy:  0.13461539\n",
      "101 : Training: loss:  0.58330625\n",
      "102 : Training: loss:  0.57762766\n",
      "103 : Training: loss:  0.56877697\n",
      "104 : Training: loss:  0.5596482\n",
      "105 : Training: loss:  0.5748247\n",
      "106 : Training: loss:  0.55905765\n",
      "107 : Training: loss:  0.5812251\n",
      "108 : Training: loss:  0.58551\n",
      "109 : Training: loss:  0.5306475\n",
      "110 : Training: loss:  0.5753084\n",
      "111 : Training: loss:  0.56660295\n",
      "112 : Training: loss:  0.57943743\n",
      "113 : Training: loss:  0.50474536\n",
      "114 : Training: loss:  0.57363975\n",
      "115 : Training: loss:  0.52753514\n",
      "116 : Training: loss:  0.59952307\n",
      "117 : Training: loss:  0.56499183\n",
      "118 : Training: loss:  0.514423\n",
      "119 : Training: loss:  0.5254249\n",
      "120 : Training: loss:  0.55342954\n",
      "Validation: Loss:  0.54465294  Accuracy:  0.13461539\n",
      "121 : Training: loss:  0.55473113\n",
      "122 : Training: loss:  0.558325\n",
      "123 : Training: loss:  0.5503655\n",
      "124 : Training: loss:  0.5170468\n",
      "125 : Training: loss:  0.5414789\n",
      "126 : Training: loss:  0.53493893\n",
      "127 : Training: loss:  0.5315932\n",
      "128 : Training: loss:  0.5445825\n",
      "129 : Training: loss:  0.56354946\n",
      "130 : Training: loss:  0.5368367\n",
      "131 : Training: loss:  0.5775997\n",
      "132 : Training: loss:  0.50683856\n",
      "133 : Training: loss:  0.5373235\n",
      "134 : Training: loss:  0.5135134\n",
      "135 : Training: loss:  0.527735\n",
      "136 : Training: loss:  0.47398046\n",
      "137 : Training: loss:  0.4611468\n",
      "138 : Training: loss:  0.53605264\n",
      "139 : Training: loss:  0.5092064\n",
      "140 : Training: loss:  0.47134593\n",
      "Validation: Loss:  0.5031109  Accuracy:  0.115384616\n",
      "141 : Training: loss:  0.5191078\n",
      "142 : Training: loss:  0.4772478\n",
      "143 : Training: loss:  0.50051683\n",
      "144 : Training: loss:  0.4766271\n",
      "145 : Training: loss:  0.51285654\n",
      "146 : Training: loss:  0.45576194\n",
      "147 : Training: loss:  0.46166947\n",
      "148 : Training: loss:  0.48685136\n",
      "149 : Training: loss:  0.5166389\n",
      "150 : Training: loss:  0.44299966\n",
      "151 : Training: loss:  0.50478554\n",
      "152 : Training: loss:  0.47956434\n",
      "153 : Training: loss:  0.43854368\n",
      "154 : Training: loss:  0.4919358\n",
      "155 : Training: loss:  0.5314776\n",
      "156 : Training: loss:  0.4916767\n",
      "157 : Training: loss:  0.42326367\n",
      "158 : Training: loss:  0.4397945\n",
      "159 : Training: loss:  0.4826769\n",
      "160 : Training: loss:  0.42486882\n",
      "Validation: Loss:  0.45742512  Accuracy:  0.13461539\n",
      "161 : Training: loss:  0.44004413\n",
      "162 : Training: loss:  0.4293953\n",
      "163 : Training: loss:  0.3900578\n",
      "164 : Training: loss:  0.43760163\n",
      "165 : Training: loss:  0.44107994\n",
      "166 : Training: loss:  0.43935066\n",
      "167 : Training: loss:  0.41359594\n",
      "168 : Training: loss:  0.4481666\n",
      "169 : Training: loss:  0.46169722\n",
      "170 : Training: loss:  0.43662798\n",
      "171 : Training: loss:  0.41336572\n",
      "172 : Training: loss:  0.45384288\n",
      "173 : Training: loss:  0.41974542\n",
      "174 : Training: loss:  0.41042545\n",
      "175 : Training: loss:  0.4194201\n",
      "176 : Training: loss:  0.37646195\n",
      "177 : Training: loss:  0.3797962\n",
      "178 : Training: loss:  0.40573713\n",
      "179 : Training: loss:  0.430574\n",
      "180 : Training: loss:  0.48015907\n",
      "Validation: Loss:  0.40936476  Accuracy:  0.15384616\n",
      "181 : Training: loss:  0.46521857\n",
      "182 : Training: loss:  0.35677642\n",
      "183 : Training: loss:  0.42713812\n",
      "184 : Training: loss:  0.40222183\n",
      "185 : Training: loss:  0.39249253\n",
      "186 : Training: loss:  0.37122884\n",
      "187 : Training: loss:  0.44719526\n",
      "188 : Training: loss:  0.38716424\n",
      "189 : Training: loss:  0.35535315\n",
      "190 : Training: loss:  0.3895543\n",
      "191 : Training: loss:  0.4262289\n",
      "192 : Training: loss:  0.34615856\n",
      "193 : Training: loss:  0.37938964\n",
      "194 : Training: loss:  0.3958704\n",
      "195 : Training: loss:  0.3752737\n",
      "196 : Training: loss:  0.3721759\n",
      "197 : Training: loss:  0.37649003\n",
      "198 : Training: loss:  0.33611542\n",
      "199 : Training: loss:  0.38677654\n",
      "200 : Training: loss:  0.33997628\n",
      "Validation: Loss:  0.36272326  Accuracy:  0.15384616\n",
      "201 : Training: loss:  0.35511956\n",
      "202 : Training: loss:  0.36862266\n",
      "203 : Training: loss:  0.39869067\n",
      "204 : Training: loss:  0.41186497\n",
      "205 : Training: loss:  0.340524\n",
      "206 : Training: loss:  0.3419051\n",
      "207 : Training: loss:  0.33710036\n",
      "208 : Training: loss:  0.35727143\n",
      "209 : Training: loss:  0.30098957\n",
      "210 : Training: loss:  0.3392798\n",
      "211 : Training: loss:  0.3783785\n",
      "212 : Training: loss:  0.33207244\n",
      "213 : Training: loss:  0.3528283\n",
      "214 : Training: loss:  0.33148652\n",
      "215 : Training: loss:  0.3078276\n",
      "216 : Training: loss:  0.32563278\n",
      "217 : Training: loss:  0.3359079\n",
      "218 : Training: loss:  0.32930037\n",
      "219 : Training: loss:  0.30350587\n",
      "220 : Training: loss:  0.29133698\n",
      "Validation: Loss:  0.32027987  Accuracy:  0.13461539\n",
      "221 : Training: loss:  0.29715952\n",
      "222 : Training: loss:  0.32364446\n",
      "223 : Training: loss:  0.31311333\n",
      "224 : Training: loss:  0.32613638\n",
      "225 : Training: loss:  0.3481166\n",
      "226 : Training: loss:  0.3086801\n",
      "227 : Training: loss:  0.29779288\n",
      "228 : Training: loss:  0.2872583\n",
      "229 : Training: loss:  0.30876794\n",
      "230 : Training: loss:  0.308033\n",
      "231 : Training: loss:  0.33029494\n",
      "232 : Training: loss:  0.26443717\n",
      "233 : Training: loss:  0.28965124\n",
      "234 : Training: loss:  0.28086576\n",
      "235 : Training: loss:  0.29684886\n",
      "236 : Training: loss:  0.29374206\n",
      "237 : Training: loss:  0.29408625\n",
      "238 : Training: loss:  0.26408306\n",
      "239 : Training: loss:  0.30187467\n",
      "240 : Training: loss:  0.2638743\n",
      "Validation: Loss:  0.2843449  Accuracy:  0.115384616\n",
      "241 : Training: loss:  0.28066286\n",
      "242 : Training: loss:  0.27667457\n",
      "243 : Training: loss:  0.2443652\n",
      "244 : Training: loss:  0.2463746\n",
      "245 : Training: loss:  0.24105275\n",
      "246 : Training: loss:  0.3166336\n",
      "247 : Training: loss:  0.27453372\n",
      "248 : Training: loss:  0.21717049\n",
      "249 : Training: loss:  0.3301882\n",
      "250 : Training: loss:  0.31256282\n",
      "251 : Training: loss:  0.256226\n",
      "252 : Training: loss:  0.24957263\n",
      "253 : Training: loss:  0.24683934\n",
      "254 : Training: loss:  0.30936515\n",
      "255 : Training: loss:  0.24675506\n",
      "256 : Training: loss:  0.2449099\n",
      "257 : Training: loss:  0.23288994\n",
      "258 : Training: loss:  0.24831593\n",
      "259 : Training: loss:  0.24653502\n",
      "260 : Training: loss:  0.251548\n",
      "Validation: Loss:  0.2554038  Accuracy:  0.115384616\n",
      "261 : Training: loss:  0.25873476\n",
      "262 : Training: loss:  0.28179777\n",
      "263 : Training: loss:  0.24719805\n",
      "264 : Training: loss:  0.24196227\n",
      "265 : Training: loss:  0.22178823\n",
      "266 : Training: loss:  0.21261765\n",
      "267 : Training: loss:  0.23197573\n",
      "268 : Training: loss:  0.24022302\n",
      "269 : Training: loss:  0.2767574\n",
      "270 : Training: loss:  0.23048027\n",
      "271 : Training: loss:  0.23816903\n",
      "272 : Training: loss:  0.28281036\n",
      "273 : Training: loss:  0.21371838\n",
      "274 : Training: loss:  0.214059\n",
      "275 : Training: loss:  0.30251464\n",
      "276 : Training: loss:  0.25933087\n",
      "277 : Training: loss:  0.19305636\n",
      "278 : Training: loss:  0.23241268\n",
      "279 : Training: loss:  0.20203473\n",
      "280 : Training: loss:  0.24176829\n",
      "Validation: Loss:  0.23255485  Accuracy:  0.13461539\n",
      "281 : Training: loss:  0.20986176\n",
      "282 : Training: loss:  0.2677183\n",
      "283 : Training: loss:  0.20792748\n",
      "284 : Training: loss:  0.20572689\n",
      "285 : Training: loss:  0.2585634\n",
      "286 : Training: loss:  0.18782844\n",
      "287 : Training: loss:  0.23531\n",
      "288 : Training: loss:  0.21342105\n",
      "289 : Training: loss:  0.24193819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 : Training: loss:  0.20381689\n",
      "291 : Training: loss:  0.22971952\n",
      "292 : Training: loss:  0.1815652\n",
      "293 : Training: loss:  0.23507865\n",
      "294 : Training: loss:  0.19209684\n",
      "295 : Training: loss:  0.21130997\n",
      "296 : Training: loss:  0.20241673\n",
      "297 : Training: loss:  0.2724573\n",
      "298 : Training: loss:  0.25433087\n",
      "299 : Training: loss:  0.21122855\n",
      "300 : Training: loss:  0.18327107\n",
      "Validation: Loss:  0.21500085  Accuracy:  0.13461539\n",
      "301 : Training: loss:  0.19251527\n",
      "302 : Training: loss:  0.19853233\n",
      "303 : Training: loss:  0.19629195\n",
      "304 : Training: loss:  0.23554927\n",
      "305 : Training: loss:  0.19203284\n",
      "306 : Training: loss:  0.20502943\n",
      "307 : Training: loss:  0.18113224\n",
      "308 : Training: loss:  0.21314782\n",
      "309 : Training: loss:  0.18156706\n",
      "310 : Training: loss:  0.18174708\n",
      "311 : Training: loss:  0.20303336\n",
      "312 : Training: loss:  0.20644392\n",
      "313 : Training: loss:  0.19365726\n",
      "314 : Training: loss:  0.19078378\n",
      "315 : Training: loss:  0.17069766\n",
      "316 : Training: loss:  0.24901962\n",
      "317 : Training: loss:  0.20660965\n",
      "318 : Training: loss:  0.21621643\n",
      "319 : Training: loss:  0.19829358\n",
      "320 : Training: loss:  0.20978366\n",
      "Validation: Loss:  0.20136341  Accuracy:  0.13461539\n",
      "321 : Training: loss:  0.18887289\n",
      "322 : Training: loss:  0.21838696\n",
      "323 : Training: loss:  0.2362435\n",
      "324 : Training: loss:  0.2016427\n",
      "325 : Training: loss:  0.19695026\n",
      "326 : Training: loss:  0.19733636\n",
      "327 : Training: loss:  0.2163812\n",
      "328 : Training: loss:  0.19139433\n",
      "329 : Training: loss:  0.18860957\n",
      "330 : Training: loss:  0.21835537\n",
      "331 : Training: loss:  0.22356437\n",
      "332 : Training: loss:  0.18531926\n",
      "333 : Training: loss:  0.2002816\n",
      "334 : Training: loss:  0.20338038\n",
      "335 : Training: loss:  0.18344906\n",
      "336 : Training: loss:  0.19010371\n",
      "337 : Training: loss:  0.19697635\n",
      "338 : Training: loss:  0.18320301\n",
      "339 : Training: loss:  0.1989046\n",
      "340 : Training: loss:  0.19126679\n",
      "Validation: Loss:  0.18976977  Accuracy:  0.1923077\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1757, 0.0517, 0.1053, 0.0635, 0.0402, 0.111...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.18977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1847, 0.0562, 0.1214, 0.0765, 0.0554, 0.086...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.16, 0.0974, 0.1319, 0.0842, 0.0792, 0.1652,...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1517, 0.0796, 0.1123, 0.0875, 0.0768, 0.110...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0826, 0.0712, 0.0947, 0.0672, 0.056, 0.0735...</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0671, 0.0626, 0.0777, 0.0553, 0.0626, 0.071...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.1764, 0.086, 0.1288, 0.1044, 0.1178, 0.1287...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.1493, 0.0859, 0.1275, 0.1167, 0.0896, 0.139...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.2837, 0.1917, 0.2785, 0.2196, 0.2313, 0.308...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.1171, 0.1033, 0.1175, 0.1108, 0.1309, 0.099...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.1212, 0.1139, 0.1325, 0.087, 0.129, 0.1276,...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.1838, 0.1662, 0.1861, 0.1248, 0.1349, 0.228...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0975, 0.0803, 0.0697, 0.0689, 0.0588, 0.106...</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0949, 0.042, 0.0723, 0.0424, 0.0404, 0.0711...</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0835, 0.0621, 0.0665, 0.059, 0.0485, 0.0684...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.1183, 0.0743, 0.0957, 0.1013, 0.0693, 0.095...</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.137, 0.0412, 0.1173, 0.0888, 0.0525, 0.0613...</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0977, 0.0532, 0.1019, 0.0717, 0.0504, 0.083...</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.1359, 0.1006, 0.1204, 0.1201, 0.1196, 0.130...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.1449, 0.1083, 0.1219, 0.1136, 0.1396, 0.130...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.114, 0.0593, 0.092, 0.061, 0.0456, 0.0933, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.1572, 0.0993, 0.1864, 0.0901, 0.1122, 0.140...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0658, 0.0604, 0.0603, 0.0574, 0.0461, 0.076...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.1594, 0.18, 0.1296, 0.1883, 0.2349, 0.1967,...</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.133, 0.125, 0.1138, 0.1514, 0.1312, 0.1862,...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.1208, 0.0902, 0.1189, 0.1038, 0.1026, 0.114...</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.1452, 0.0885, 0.1158, 0.14, 0.1106, 0.0998,...</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0896, 0.067, 0.0805, 0.0758, 0.0815, 0.0848...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0716, 0.0923, 0.085, 0.1172, 0.0868, 0.0898...</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0768, 0.0781, 0.0903, 0.0895, 0.0781, 0.078...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1818, 0.0978, 0.1043, 0.075, 0.1082, 0.1559...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.1085, 0.0631, 0.1088, 0.095, 0.0657, 0.1056...</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0858, 0.0574, 0.087, 0.0721, 0.0682, 0.083,...</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.1094, 0.0634, 0.0851, 0.0763, 0.0869, 0.089...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.1395, 0.0968, 0.1082, 0.1068, 0.0909, 0.109...</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0757, 0.0494, 0.0547, 0.0505, 0.0632, 0.058...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.1543, 0.0763, 0.0785, 0.1057, 0.0704, 0.100...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.1404, 0.0793, 0.0702, 0.0806, 0.1018, 0.120...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.1273, 0.1047, 0.0643, 0.0887, 0.0923, 0.140...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.1115, 0.0571, 0.0822, 0.0676, 0.0531, 0.081...</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.1106, 0.0529, 0.066, 0.1006, 0.0549, 0.0586...</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.1279, 0.0737, 0.0741, 0.0985, 0.0803, 0.096...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.2516, 0.12, 0.1186, 0.1726, 0.1376, 0.1616,...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.2091, 0.1829, 0.1367, 0.1425, 0.1791, 0.216...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0997, 0.0668, 0.0934, 0.0632, 0.0593, 0.090...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.3233, 0.2399, 0.2573, 0.2314, 0.3123, 0.339...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0819, 0.0804, 0.0544, 0.0683, 0.0891, 0.082...</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.1112, 0.0957, 0.0841, 0.0658, 0.1027, 0.108...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0794, 0.0515, 0.0594, 0.0494, 0.0395, 0.077...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0725, 0.0529, 0.0523, 0.0523, 0.0383, 0.069...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.2263, 0.0797, 0.1406, 0.1068, 0.0972, 0.158...</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0774, 0.0457, 0.0774, 0.0656, 0.0642, 0.048...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1757, 0.0517, 0.1053, 0.0635, 0.0402, 0.111...               0   \n",
       "1   [0.1847, 0.0562, 0.1214, 0.0765, 0.0554, 0.086...               0   \n",
       "2   [0.16, 0.0974, 0.1319, 0.0842, 0.0792, 0.1652,...               0   \n",
       "3   [0.1517, 0.0796, 0.1123, 0.0875, 0.0768, 0.110...               1   \n",
       "4   [0.0826, 0.0712, 0.0947, 0.0672, 0.056, 0.0735...               1   \n",
       "5   [0.0671, 0.0626, 0.0777, 0.0553, 0.0626, 0.071...               2   \n",
       "6   [0.1764, 0.086, 0.1288, 0.1044, 0.1178, 0.1287...               3   \n",
       "7   [0.1493, 0.0859, 0.1275, 0.1167, 0.0896, 0.139...               3   \n",
       "8   [0.2837, 0.1917, 0.2785, 0.2196, 0.2313, 0.308...               3   \n",
       "9   [0.1171, 0.1033, 0.1175, 0.1108, 0.1309, 0.099...               4   \n",
       "10  [0.1212, 0.1139, 0.1325, 0.087, 0.129, 0.1276,...               4   \n",
       "11  [0.1838, 0.1662, 0.1861, 0.1248, 0.1349, 0.228...               5   \n",
       "12  [0.0975, 0.0803, 0.0697, 0.0689, 0.0588, 0.106...               6   \n",
       "13  [0.0949, 0.042, 0.0723, 0.0424, 0.0404, 0.0711...               7   \n",
       "14  [0.0835, 0.0621, 0.0665, 0.059, 0.0485, 0.0684...               8   \n",
       "15  [0.1183, 0.0743, 0.0957, 0.1013, 0.0693, 0.095...               8   \n",
       "16  [0.137, 0.0412, 0.1173, 0.0888, 0.0525, 0.0613...               9   \n",
       "17  [0.0977, 0.0532, 0.1019, 0.0717, 0.0504, 0.083...               9   \n",
       "18  [0.1359, 0.1006, 0.1204, 0.1201, 0.1196, 0.130...              10   \n",
       "19  [0.1449, 0.1083, 0.1219, 0.1136, 0.1396, 0.130...              10   \n",
       "20  [0.114, 0.0593, 0.092, 0.061, 0.0456, 0.0933, ...              11   \n",
       "21  [0.1572, 0.0993, 0.1864, 0.0901, 0.1122, 0.140...              11   \n",
       "22  [0.0658, 0.0604, 0.0603, 0.0574, 0.0461, 0.076...              12   \n",
       "23  [0.1594, 0.18, 0.1296, 0.1883, 0.2349, 0.1967,...              13   \n",
       "24  [0.133, 0.125, 0.1138, 0.1514, 0.1312, 0.1862,...              13   \n",
       "25  [0.1208, 0.0902, 0.1189, 0.1038, 0.1026, 0.114...              14   \n",
       "26  [0.1452, 0.0885, 0.1158, 0.14, 0.1106, 0.0998,...              14   \n",
       "27  [0.0896, 0.067, 0.0805, 0.0758, 0.0815, 0.0848...              15   \n",
       "28  [0.0716, 0.0923, 0.085, 0.1172, 0.0868, 0.0898...              15   \n",
       "29  [0.0768, 0.0781, 0.0903, 0.0895, 0.0781, 0.078...              15   \n",
       "30  [0.1818, 0.0978, 0.1043, 0.075, 0.1082, 0.1559...              16   \n",
       "31  [0.1085, 0.0631, 0.1088, 0.095, 0.0657, 0.1056...              17   \n",
       "32  [0.0858, 0.0574, 0.087, 0.0721, 0.0682, 0.083,...              17   \n",
       "33  [0.1094, 0.0634, 0.0851, 0.0763, 0.0869, 0.089...              18   \n",
       "34  [0.1395, 0.0968, 0.1082, 0.1068, 0.0909, 0.109...              19   \n",
       "35  [0.0757, 0.0494, 0.0547, 0.0505, 0.0632, 0.058...              20   \n",
       "36  [0.1543, 0.0763, 0.0785, 0.1057, 0.0704, 0.100...              21   \n",
       "37  [0.1404, 0.0793, 0.0702, 0.0806, 0.1018, 0.120...              21   \n",
       "38  [0.1273, 0.1047, 0.0643, 0.0887, 0.0923, 0.140...              22   \n",
       "39  [0.1115, 0.0571, 0.0822, 0.0676, 0.0531, 0.081...              22   \n",
       "40  [0.1106, 0.0529, 0.066, 0.1006, 0.0549, 0.0586...              22   \n",
       "41  [0.1279, 0.0737, 0.0741, 0.0985, 0.0803, 0.096...              22   \n",
       "42  [0.2516, 0.12, 0.1186, 0.1726, 0.1376, 0.1616,...              23   \n",
       "43  [0.2091, 0.1829, 0.1367, 0.1425, 0.1791, 0.216...              23   \n",
       "44  [0.0997, 0.0668, 0.0934, 0.0632, 0.0593, 0.090...              23   \n",
       "45  [0.3233, 0.2399, 0.2573, 0.2314, 0.3123, 0.339...              23   \n",
       "46  [0.0819, 0.0804, 0.0544, 0.0683, 0.0891, 0.082...              24   \n",
       "47  [0.1112, 0.0957, 0.0841, 0.0658, 0.1027, 0.108...              24   \n",
       "48  [0.0794, 0.0515, 0.0594, 0.0494, 0.0395, 0.077...              25   \n",
       "49  [0.0725, 0.0529, 0.0523, 0.0523, 0.0383, 0.069...              25   \n",
       "50  [0.2263, 0.0797, 0.1406, 0.1068, 0.0972, 0.158...              26   \n",
       "51  [0.0774, 0.0457, 0.0774, 0.0656, 0.0642, 0.048...              26   \n",
       "\n",
       "    Predicted labels  Accuracy     Loss  \n",
       "0                  0  0.192308  0.18977  \n",
       "1                 16       NaN      NaN  \n",
       "2                  8       NaN      NaN  \n",
       "3                  0       NaN      NaN  \n",
       "4                 26       NaN      NaN  \n",
       "5                 10       NaN      NaN  \n",
       "6                 16       NaN      NaN  \n",
       "7                 16       NaN      NaN  \n",
       "8                  5       NaN      NaN  \n",
       "9                 12       NaN      NaN  \n",
       "10                 8       NaN      NaN  \n",
       "11                 5       NaN      NaN  \n",
       "12                21       NaN      NaN  \n",
       "13                16       NaN      NaN  \n",
       "14                12       NaN      NaN  \n",
       "15                16       NaN      NaN  \n",
       "16                16       NaN      NaN  \n",
       "17                16       NaN      NaN  \n",
       "18                10       NaN      NaN  \n",
       "19                10       NaN      NaN  \n",
       "20                21       NaN      NaN  \n",
       "21                 2       NaN      NaN  \n",
       "22                12       NaN      NaN  \n",
       "23                23       NaN      NaN  \n",
       "24                13       NaN      NaN  \n",
       "25                16       NaN      NaN  \n",
       "26                21       NaN      NaN  \n",
       "27                16       NaN      NaN  \n",
       "28                25       NaN      NaN  \n",
       "29                11       NaN      NaN  \n",
       "30                16       NaN      NaN  \n",
       "31                21       NaN      NaN  \n",
       "32                21       NaN      NaN  \n",
       "33                 8       NaN      NaN  \n",
       "34                16       NaN      NaN  \n",
       "35                10       NaN      NaN  \n",
       "36                16       NaN      NaN  \n",
       "37                 8       NaN      NaN  \n",
       "38                 7       NaN      NaN  \n",
       "39                16       NaN      NaN  \n",
       "40                16       NaN      NaN  \n",
       "41                21       NaN      NaN  \n",
       "42                16       NaN      NaN  \n",
       "43                 8       NaN      NaN  \n",
       "44                23       NaN      NaN  \n",
       "45                16       NaN      NaN  \n",
       "46                11       NaN      NaN  \n",
       "47                12       NaN      NaN  \n",
       "48                25       NaN      NaN  \n",
       "49                25       NaN      NaN  \n",
       "50                16       NaN      NaN  \n",
       "51                23       NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 : Training: loss:  0.17421283\n",
      "342 : Training: loss:  0.1591711\n",
      "343 : Training: loss:  0.19792499\n",
      "344 : Training: loss:  0.19244254\n",
      "345 : Training: loss:  0.2212442\n",
      "346 : Training: loss:  0.16748808\n",
      "347 : Training: loss:  0.15427573\n",
      "348 : Training: loss:  0.16725853\n",
      "349 : Training: loss:  0.17320754\n",
      "350 : Training: loss:  0.16520846\n",
      "351 : Training: loss:  0.1717043\n",
      "352 : Training: loss:  0.17026924\n",
      "353 : Training: loss:  0.1847696\n",
      "354 : Training: loss:  0.18576704\n",
      "355 : Training: loss:  0.17087823\n",
      "356 : Training: loss:  0.17834656\n",
      "357 : Training: loss:  0.16989845\n",
      "358 : Training: loss:  0.17353128\n",
      "359 : Training: loss:  0.16281262\n",
      "360 : Training: loss:  0.16403347\n",
      "Validation: Loss:  0.18126258  Accuracy:  0.23076923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1585, 0.0457, 0.0924, 0.0568, 0.0361, 0.097...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.181263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1684, 0.05, 0.1074, 0.0691, 0.0503, 0.0759,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1441, 0.0859, 0.1148, 0.0753, 0.0711, 0.145...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1338, 0.0688, 0.0962, 0.0761, 0.068, 0.0949...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0733, 0.0636, 0.0828, 0.0601, 0.0507, 0.063...</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0595, 0.0564, 0.0687, 0.0499, 0.057, 0.0627...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.1602, 0.0777, 0.1152, 0.0961, 0.1085, 0.114...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.1342, 0.0767, 0.1129, 0.107, 0.0811, 0.1228...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.2665, 0.1762, 0.2573, 0.2073, 0.2157, 0.284...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.1052, 0.0916, 0.103, 0.0995, 0.1194, 0.088,...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.1094, 0.1024, 0.1172, 0.0785, 0.1184, 0.112...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.169, 0.1508, 0.168, 0.114, 0.1247, 0.2076, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0861, 0.0712, 0.0607, 0.0609, 0.0526, 0.092...</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0839, 0.0371, 0.0624, 0.0378, 0.0361, 0.061...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0717, 0.0529, 0.0558, 0.0505, 0.0423, 0.057...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.1034, 0.064, 0.0816, 0.089, 0.0612, 0.0816,...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.1236, 0.0371, 0.1042, 0.0811, 0.0478, 0.053...</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0859, 0.0466, 0.0878, 0.0634, 0.0448, 0.071...</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.1228, 0.0902, 0.1078, 0.1081, 0.1091, 0.116...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.1313, 0.097, 0.109, 0.1021, 0.1275, 0.1158,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.1004, 0.052, 0.0794, 0.0536, 0.0406, 0.0804...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.1428, 0.09, 0.1669, 0.0825, 0.104, 0.125, 0...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0564, 0.0513, 0.0506, 0.0492, 0.0401, 0.064...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.1429, 0.1588, 0.1138, 0.1682, 0.2114, 0.174...</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.1178, 0.1102, 0.0999, 0.1349, 0.1173, 0.163...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.1086, 0.0812, 0.1056, 0.0945, 0.0939, 0.101...</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.1321, 0.0808, 0.1047, 0.1285, 0.1022, 0.089...</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0779, 0.0582, 0.0688, 0.066, 0.0723, 0.0723...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0622, 0.0808, 0.0734, 0.1032, 0.0773, 0.076...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0673, 0.0684, 0.0778, 0.0792, 0.0701, 0.067...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1653, 0.0871, 0.0919, 0.0675, 0.0987, 0.137...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0947, 0.055, 0.0936, 0.0835, 0.0582, 0.0904...</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0759, 0.0509, 0.0758, 0.065, 0.0616, 0.0718...</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0967, 0.056, 0.0741, 0.0676, 0.0781, 0.0772...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.1229, 0.0855, 0.0943, 0.0944, 0.081, 0.0964...</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0671, 0.0437, 0.0475, 0.0452, 0.0569, 0.050...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.1412, 0.0702, 0.0709, 0.0973, 0.0651, 0.09,...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.1252, 0.0701, 0.0612, 0.072, 0.0916, 0.1045...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.1146, 0.094, 0.0572, 0.0802, 0.0836, 0.1247...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0987, 0.0502, 0.0715, 0.06, 0.0475, 0.0705,...</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0996, 0.0475, 0.0585, 0.0919, 0.0498, 0.051...</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.1157, 0.0668, 0.0662, 0.0897, 0.0735, 0.085...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.2318, 0.1095, 0.1077, 0.1571, 0.1257, 0.146...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.1956, 0.1705, 0.1261, 0.1314, 0.1684, 0.199...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0895, 0.0596, 0.0824, 0.0573, 0.0543, 0.078...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.3021, 0.2197, 0.2361, 0.214, 0.292, 0.3137,...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0714, 0.0696, 0.0468, 0.06, 0.0787, 0.0702,...</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.1004, 0.0864, 0.075, 0.0601, 0.0944, 0.0967...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0683, 0.0441, 0.0502, 0.0428, 0.0349, 0.064...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0623, 0.0453, 0.0442, 0.0453, 0.0337, 0.058...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.2031, 0.068, 0.1209, 0.0931, 0.0846, 0.1358...</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0665, 0.0389, 0.0653, 0.0564, 0.056, 0.0411...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1585, 0.0457, 0.0924, 0.0568, 0.0361, 0.097...               0   \n",
       "1   [0.1684, 0.05, 0.1074, 0.0691, 0.0503, 0.0759,...               0   \n",
       "2   [0.1441, 0.0859, 0.1148, 0.0753, 0.0711, 0.145...               0   \n",
       "3   [0.1338, 0.0688, 0.0962, 0.0761, 0.068, 0.0949...               1   \n",
       "4   [0.0733, 0.0636, 0.0828, 0.0601, 0.0507, 0.063...               1   \n",
       "5   [0.0595, 0.0564, 0.0687, 0.0499, 0.057, 0.0627...               2   \n",
       "6   [0.1602, 0.0777, 0.1152, 0.0961, 0.1085, 0.114...               3   \n",
       "7   [0.1342, 0.0767, 0.1129, 0.107, 0.0811, 0.1228...               3   \n",
       "8   [0.2665, 0.1762, 0.2573, 0.2073, 0.2157, 0.284...               3   \n",
       "9   [0.1052, 0.0916, 0.103, 0.0995, 0.1194, 0.088,...               4   \n",
       "10  [0.1094, 0.1024, 0.1172, 0.0785, 0.1184, 0.112...               4   \n",
       "11  [0.169, 0.1508, 0.168, 0.114, 0.1247, 0.2076, ...               5   \n",
       "12  [0.0861, 0.0712, 0.0607, 0.0609, 0.0526, 0.092...               6   \n",
       "13  [0.0839, 0.0371, 0.0624, 0.0378, 0.0361, 0.061...               7   \n",
       "14  [0.0717, 0.0529, 0.0558, 0.0505, 0.0423, 0.057...               8   \n",
       "15  [0.1034, 0.064, 0.0816, 0.089, 0.0612, 0.0816,...               8   \n",
       "16  [0.1236, 0.0371, 0.1042, 0.0811, 0.0478, 0.053...               9   \n",
       "17  [0.0859, 0.0466, 0.0878, 0.0634, 0.0448, 0.071...               9   \n",
       "18  [0.1228, 0.0902, 0.1078, 0.1081, 0.1091, 0.116...              10   \n",
       "19  [0.1313, 0.097, 0.109, 0.1021, 0.1275, 0.1158,...              10   \n",
       "20  [0.1004, 0.052, 0.0794, 0.0536, 0.0406, 0.0804...              11   \n",
       "21  [0.1428, 0.09, 0.1669, 0.0825, 0.104, 0.125, 0...              11   \n",
       "22  [0.0564, 0.0513, 0.0506, 0.0492, 0.0401, 0.064...              12   \n",
       "23  [0.1429, 0.1588, 0.1138, 0.1682, 0.2114, 0.174...              13   \n",
       "24  [0.1178, 0.1102, 0.0999, 0.1349, 0.1173, 0.163...              13   \n",
       "25  [0.1086, 0.0812, 0.1056, 0.0945, 0.0939, 0.101...              14   \n",
       "26  [0.1321, 0.0808, 0.1047, 0.1285, 0.1022, 0.089...              14   \n",
       "27  [0.0779, 0.0582, 0.0688, 0.066, 0.0723, 0.0723...              15   \n",
       "28  [0.0622, 0.0808, 0.0734, 0.1032, 0.0773, 0.076...              15   \n",
       "29  [0.0673, 0.0684, 0.0778, 0.0792, 0.0701, 0.067...              15   \n",
       "30  [0.1653, 0.0871, 0.0919, 0.0675, 0.0987, 0.137...              16   \n",
       "31  [0.0947, 0.055, 0.0936, 0.0835, 0.0582, 0.0904...              17   \n",
       "32  [0.0759, 0.0509, 0.0758, 0.065, 0.0616, 0.0718...              17   \n",
       "33  [0.0967, 0.056, 0.0741, 0.0676, 0.0781, 0.0772...              18   \n",
       "34  [0.1229, 0.0855, 0.0943, 0.0944, 0.081, 0.0964...              19   \n",
       "35  [0.0671, 0.0437, 0.0475, 0.0452, 0.0569, 0.050...              20   \n",
       "36  [0.1412, 0.0702, 0.0709, 0.0973, 0.0651, 0.09,...              21   \n",
       "37  [0.1252, 0.0701, 0.0612, 0.072, 0.0916, 0.1045...              21   \n",
       "38  [0.1146, 0.094, 0.0572, 0.0802, 0.0836, 0.1247...              22   \n",
       "39  [0.0987, 0.0502, 0.0715, 0.06, 0.0475, 0.0705,...              22   \n",
       "40  [0.0996, 0.0475, 0.0585, 0.0919, 0.0498, 0.051...              22   \n",
       "41  [0.1157, 0.0668, 0.0662, 0.0897, 0.0735, 0.085...              22   \n",
       "42  [0.2318, 0.1095, 0.1077, 0.1571, 0.1257, 0.146...              23   \n",
       "43  [0.1956, 0.1705, 0.1261, 0.1314, 0.1684, 0.199...              23   \n",
       "44  [0.0895, 0.0596, 0.0824, 0.0573, 0.0543, 0.078...              23   \n",
       "45  [0.3021, 0.2197, 0.2361, 0.214, 0.292, 0.3137,...              23   \n",
       "46  [0.0714, 0.0696, 0.0468, 0.06, 0.0787, 0.0702,...              24   \n",
       "47  [0.1004, 0.0864, 0.075, 0.0601, 0.0944, 0.0967...              24   \n",
       "48  [0.0683, 0.0441, 0.0502, 0.0428, 0.0349, 0.064...              25   \n",
       "49  [0.0623, 0.0453, 0.0442, 0.0453, 0.0337, 0.058...              25   \n",
       "50  [0.2031, 0.068, 0.1209, 0.0931, 0.0846, 0.1358...              26   \n",
       "51  [0.0665, 0.0389, 0.0653, 0.0564, 0.056, 0.0411...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.230769  0.181263  \n",
       "1                  0       NaN       NaN  \n",
       "2                  8       NaN       NaN  \n",
       "3                  0       NaN       NaN  \n",
       "4                 26       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                 16       NaN       NaN  \n",
       "7                 16       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                 12       NaN       NaN  \n",
       "10                 8       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                21       NaN       NaN  \n",
       "13                 0       NaN       NaN  \n",
       "14                12       NaN       NaN  \n",
       "15                12       NaN       NaN  \n",
       "16                26       NaN       NaN  \n",
       "17                16       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 2       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                23       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                16       NaN       NaN  \n",
       "26                21       NaN       NaN  \n",
       "27                16       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                11       NaN       NaN  \n",
       "30                16       NaN       NaN  \n",
       "31                21       NaN       NaN  \n",
       "32                21       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                16       NaN       NaN  \n",
       "35                10       NaN       NaN  \n",
       "36                16       NaN       NaN  \n",
       "37                 8       NaN       NaN  \n",
       "38                 7       NaN       NaN  \n",
       "39                16       NaN       NaN  \n",
       "40                16       NaN       NaN  \n",
       "41                21       NaN       NaN  \n",
       "42                16       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                16       NaN       NaN  \n",
       "46                11       NaN       NaN  \n",
       "47                12       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                16       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 : Training: loss:  0.21889001\n",
      "362 : Training: loss:  0.17154483\n",
      "363 : Training: loss:  0.1888749\n",
      "364 : Training: loss:  0.17835163\n",
      "365 : Training: loss:  0.1841957\n",
      "366 : Training: loss:  0.1588125\n",
      "367 : Training: loss:  0.15948685\n",
      "368 : Training: loss:  0.16599101\n",
      "369 : Training: loss:  0.15894364\n",
      "370 : Training: loss:  0.15644275\n",
      "371 : Training: loss:  0.16124962\n",
      "372 : Training: loss:  0.16517116\n",
      "373 : Training: loss:  0.17759918\n",
      "374 : Training: loss:  0.17358771\n",
      "375 : Training: loss:  0.17384079\n",
      "376 : Training: loss:  0.15158698\n",
      "377 : Training: loss:  0.1766547\n",
      "378 : Training: loss:  0.17057753\n",
      "379 : Training: loss:  0.16872147\n",
      "380 : Training: loss:  0.17823079\n",
      "Validation: Loss:  0.17465474  Accuracy:  0.26923078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1439, 0.04, 0.0809, 0.0496, 0.0325, 0.0858,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.174655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1519, 0.0431, 0.0934, 0.0596, 0.0448, 0.066...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1317, 0.0755, 0.101, 0.0663, 0.0641, 0.1292...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1179, 0.0584, 0.082, 0.0643, 0.0599, 0.0817...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.065, 0.0556, 0.0723, 0.0518, 0.0455, 0.0559...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.054, 0.0515, 0.0624, 0.045, 0.0534, 0.0566,...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.149, 0.0714, 0.1055, 0.0881, 0.1019, 0.1055...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.1263, 0.0719, 0.1053, 0.0999, 0.0771, 0.114...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.2563, 0.1668, 0.2442, 0.1964, 0.2058, 0.271...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0953, 0.0806, 0.0909, 0.0876, 0.109, 0.0785...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.1001, 0.0917, 0.105, 0.0698, 0.1095, 0.1015...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.1562, 0.1362, 0.1522, 0.1022, 0.115, 0.1904...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0778, 0.0638, 0.0541, 0.0539, 0.0482, 0.082...</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0764, 0.0331, 0.0554, 0.0335, 0.0332, 0.054...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0633, 0.0459, 0.0482, 0.0434, 0.0381, 0.049...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0926, 0.0561, 0.0714, 0.0777, 0.0554, 0.071...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.1139, 0.0339, 0.095, 0.0732, 0.0444, 0.0489...</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0774, 0.0413, 0.0777, 0.0557, 0.0407, 0.063...</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.1104, 0.0797, 0.0962, 0.0952, 0.0995, 0.103...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.1192, 0.0866, 0.0982, 0.0907, 0.1173, 0.104...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0898, 0.0457, 0.0694, 0.0468, 0.0369, 0.070...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.1321, 0.0821, 0.1522, 0.0752, 0.0978, 0.113...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0488, 0.0435, 0.043, 0.0414, 0.0352, 0.0545...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.132, 0.1449, 0.1037, 0.1531, 0.1974, 0.1608...</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.1082, 0.101, 0.0913, 0.1229, 0.1097, 0.1504...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0993, 0.0735, 0.0955, 0.0855, 0.0874, 0.091...</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.1205, 0.0735, 0.095, 0.1164, 0.095, 0.0814,...</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0691, 0.0507, 0.0598, 0.0571, 0.0654, 0.063...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0558, 0.0728, 0.0658, 0.0918, 0.0714, 0.069...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0602, 0.0599, 0.0681, 0.0691, 0.0638, 0.059...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1511, 0.0764, 0.0812, 0.0596, 0.09, 0.1227,...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0846, 0.0488, 0.0828, 0.0736, 0.0529, 0.080...</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0701, 0.0468, 0.0693, 0.0596, 0.0582, 0.065...</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0861, 0.0489, 0.0649, 0.0589, 0.0708, 0.067...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.1119, 0.0775, 0.0847, 0.085, 0.0749, 0.088,...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0594, 0.0382, 0.0416, 0.0391, 0.0514, 0.043...</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.1302, 0.0642, 0.0646, 0.0876, 0.0603, 0.082...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.1138, 0.0627, 0.0547, 0.0638, 0.0841, 0.093...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.104, 0.0848, 0.0514, 0.0715, 0.0766, 0.1123...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.087, 0.0436, 0.0619, 0.0512, 0.0423, 0.0615...</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0898, 0.0423, 0.052, 0.0807, 0.045, 0.046, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.1053, 0.0602, 0.0594, 0.08, 0.0674, 0.0767,...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.2086, 0.0964, 0.0951, 0.1368, 0.112, 0.1292...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.1785, 0.1521, 0.1128, 0.1166, 0.1545, 0.178...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0784, 0.0509, 0.071, 0.0486, 0.0481, 0.067,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.2809, 0.1982, 0.2143, 0.1931, 0.27, 0.2878,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0629, 0.0603, 0.0407, 0.0516, 0.0702, 0.061...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0918, 0.0784, 0.0678, 0.0541, 0.0876, 0.088...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0596, 0.0376, 0.0429, 0.0364, 0.0311, 0.055...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0543, 0.0387, 0.0379, 0.0384, 0.0299, 0.050...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1842, 0.0583, 0.1053, 0.0802, 0.0748, 0.118...</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0583, 0.0336, 0.0565, 0.0481, 0.0502, 0.035...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1439, 0.04, 0.0809, 0.0496, 0.0325, 0.0858,...               0   \n",
       "1   [0.1519, 0.0431, 0.0934, 0.0596, 0.0448, 0.066...               0   \n",
       "2   [0.1317, 0.0755, 0.101, 0.0663, 0.0641, 0.1292...               0   \n",
       "3   [0.1179, 0.0584, 0.082, 0.0643, 0.0599, 0.0817...               1   \n",
       "4   [0.065, 0.0556, 0.0723, 0.0518, 0.0455, 0.0559...               1   \n",
       "5   [0.054, 0.0515, 0.0624, 0.045, 0.0534, 0.0566,...               2   \n",
       "6   [0.149, 0.0714, 0.1055, 0.0881, 0.1019, 0.1055...               3   \n",
       "7   [0.1263, 0.0719, 0.1053, 0.0999, 0.0771, 0.114...               3   \n",
       "8   [0.2563, 0.1668, 0.2442, 0.1964, 0.2058, 0.271...               3   \n",
       "9   [0.0953, 0.0806, 0.0909, 0.0876, 0.109, 0.0785...               4   \n",
       "10  [0.1001, 0.0917, 0.105, 0.0698, 0.1095, 0.1015...               4   \n",
       "11  [0.1562, 0.1362, 0.1522, 0.1022, 0.115, 0.1904...               5   \n",
       "12  [0.0778, 0.0638, 0.0541, 0.0539, 0.0482, 0.082...               6   \n",
       "13  [0.0764, 0.0331, 0.0554, 0.0335, 0.0332, 0.054...               7   \n",
       "14  [0.0633, 0.0459, 0.0482, 0.0434, 0.0381, 0.049...               8   \n",
       "15  [0.0926, 0.0561, 0.0714, 0.0777, 0.0554, 0.071...               8   \n",
       "16  [0.1139, 0.0339, 0.095, 0.0732, 0.0444, 0.0489...               9   \n",
       "17  [0.0774, 0.0413, 0.0777, 0.0557, 0.0407, 0.063...               9   \n",
       "18  [0.1104, 0.0797, 0.0962, 0.0952, 0.0995, 0.103...              10   \n",
       "19  [0.1192, 0.0866, 0.0982, 0.0907, 0.1173, 0.104...              10   \n",
       "20  [0.0898, 0.0457, 0.0694, 0.0468, 0.0369, 0.070...              11   \n",
       "21  [0.1321, 0.0821, 0.1522, 0.0752, 0.0978, 0.113...              11   \n",
       "22  [0.0488, 0.0435, 0.043, 0.0414, 0.0352, 0.0545...              12   \n",
       "23  [0.132, 0.1449, 0.1037, 0.1531, 0.1974, 0.1608...              13   \n",
       "24  [0.1082, 0.101, 0.0913, 0.1229, 0.1097, 0.1504...              13   \n",
       "25  [0.0993, 0.0735, 0.0955, 0.0855, 0.0874, 0.091...              14   \n",
       "26  [0.1205, 0.0735, 0.095, 0.1164, 0.095, 0.0814,...              14   \n",
       "27  [0.0691, 0.0507, 0.0598, 0.0571, 0.0654, 0.063...              15   \n",
       "28  [0.0558, 0.0728, 0.0658, 0.0918, 0.0714, 0.069...              15   \n",
       "29  [0.0602, 0.0599, 0.0681, 0.0691, 0.0638, 0.059...              15   \n",
       "30  [0.1511, 0.0764, 0.0812, 0.0596, 0.09, 0.1227,...              16   \n",
       "31  [0.0846, 0.0488, 0.0828, 0.0736, 0.0529, 0.080...              17   \n",
       "32  [0.0701, 0.0468, 0.0693, 0.0596, 0.0582, 0.065...              17   \n",
       "33  [0.0861, 0.0489, 0.0649, 0.0589, 0.0708, 0.067...              18   \n",
       "34  [0.1119, 0.0775, 0.0847, 0.085, 0.0749, 0.088,...              19   \n",
       "35  [0.0594, 0.0382, 0.0416, 0.0391, 0.0514, 0.043...              20   \n",
       "36  [0.1302, 0.0642, 0.0646, 0.0876, 0.0603, 0.082...              21   \n",
       "37  [0.1138, 0.0627, 0.0547, 0.0638, 0.0841, 0.093...              21   \n",
       "38  [0.104, 0.0848, 0.0514, 0.0715, 0.0766, 0.1123...              22   \n",
       "39  [0.087, 0.0436, 0.0619, 0.0512, 0.0423, 0.0615...              22   \n",
       "40  [0.0898, 0.0423, 0.052, 0.0807, 0.045, 0.046, ...              22   \n",
       "41  [0.1053, 0.0602, 0.0594, 0.08, 0.0674, 0.0767,...              22   \n",
       "42  [0.2086, 0.0964, 0.0951, 0.1368, 0.112, 0.1292...              23   \n",
       "43  [0.1785, 0.1521, 0.1128, 0.1166, 0.1545, 0.178...              23   \n",
       "44  [0.0784, 0.0509, 0.071, 0.0486, 0.0481, 0.067,...              23   \n",
       "45  [0.2809, 0.1982, 0.2143, 0.1931, 0.27, 0.2878,...              23   \n",
       "46  [0.0629, 0.0603, 0.0407, 0.0516, 0.0702, 0.061...              24   \n",
       "47  [0.0918, 0.0784, 0.0678, 0.0541, 0.0876, 0.088...              24   \n",
       "48  [0.0596, 0.0376, 0.0429, 0.0364, 0.0311, 0.055...              25   \n",
       "49  [0.0543, 0.0387, 0.0379, 0.0384, 0.0299, 0.050...              25   \n",
       "50  [0.1842, 0.0583, 0.1053, 0.0802, 0.0748, 0.118...              26   \n",
       "51  [0.0583, 0.0336, 0.0565, 0.0481, 0.0502, 0.035...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.269231  0.174655  \n",
       "1                  0       NaN       NaN  \n",
       "2                  8       NaN       NaN  \n",
       "3                  0       NaN       NaN  \n",
       "4                 12       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                 16       NaN       NaN  \n",
       "7                 16       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                 12       NaN       NaN  \n",
       "10                 8       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                21       NaN       NaN  \n",
       "13                 0       NaN       NaN  \n",
       "14                12       NaN       NaN  \n",
       "15                12       NaN       NaN  \n",
       "16                26       NaN       NaN  \n",
       "17                16       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 2       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                23       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                16       NaN       NaN  \n",
       "26                21       NaN       NaN  \n",
       "27                16       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                11       NaN       NaN  \n",
       "30                16       NaN       NaN  \n",
       "31                21       NaN       NaN  \n",
       "32                12       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                12       NaN       NaN  \n",
       "35                23       NaN       NaN  \n",
       "36                16       NaN       NaN  \n",
       "37                 8       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                16       NaN       NaN  \n",
       "40                16       NaN       NaN  \n",
       "41                21       NaN       NaN  \n",
       "42                16       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                12       NaN       NaN  \n",
       "47                12       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                16       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381 : Training: loss:  0.1446039\n",
      "382 : Training: loss:  0.15290216\n",
      "383 : Training: loss:  0.16884708\n",
      "384 : Training: loss:  0.17432827\n",
      "385 : Training: loss:  0.1548061\n",
      "386 : Training: loss:  0.16295207\n",
      "387 : Training: loss:  0.17466284\n",
      "388 : Training: loss:  0.18106712\n",
      "389 : Training: loss:  0.16937806\n",
      "390 : Training: loss:  0.19496292\n",
      "391 : Training: loss:  0.1667662\n",
      "392 : Training: loss:  0.15410271\n",
      "393 : Training: loss:  0.15483333\n",
      "394 : Training: loss:  0.16412674\n",
      "395 : Training: loss:  0.166331\n",
      "396 : Training: loss:  0.16127536\n",
      "397 : Training: loss:  0.15954879\n",
      "398 : Training: loss:  0.17559679\n",
      "399 : Training: loss:  0.176569\n",
      "400 : Training: loss:  0.16682093\n",
      "Validation: Loss:  0.16947462  Accuracy:  0.26923078\n",
      "401 : Training: loss:  0.15195043\n",
      "402 : Training: loss:  0.1588649\n",
      "403 : Training: loss:  0.16104098\n",
      "404 : Training: loss:  0.16461268\n",
      "405 : Training: loss:  0.1552048\n",
      "406 : Training: loss:  0.15173957\n",
      "407 : Training: loss:  0.16692725\n",
      "408 : Training: loss:  0.15993737\n",
      "409 : Training: loss:  0.16062573\n",
      "410 : Training: loss:  0.16470537\n",
      "411 : Training: loss:  0.15255623\n",
      "412 : Training: loss:  0.15061587\n",
      "413 : Training: loss:  0.18841875\n",
      "414 : Training: loss:  0.15588678\n",
      "415 : Training: loss:  0.16089372\n",
      "416 : Training: loss:  0.13920754\n",
      "417 : Training: loss:  0.15556641\n",
      "418 : Training: loss:  0.16448887\n",
      "419 : Training: loss:  0.1627693\n",
      "420 : Training: loss:  0.16775925\n",
      "Validation: Loss:  0.16541669  Accuracy:  0.28846154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1246, 0.0336, 0.0721, 0.043, 0.0274, 0.0714...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.165417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1302, 0.0355, 0.0813, 0.0507, 0.0375, 0.053...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1157, 0.064, 0.091, 0.0579, 0.0545, 0.11, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1015, 0.0509, 0.0739, 0.0557, 0.0521, 0.069...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0542, 0.0471, 0.0654, 0.0437, 0.0387, 0.046...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0437, 0.0424, 0.0564, 0.0371, 0.044, 0.0457...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.1247, 0.0589, 0.0912, 0.0761, 0.0856, 0.086...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.1076, 0.0607, 0.095, 0.0896, 0.066, 0.0963,...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.2274, 0.1419, 0.2206, 0.1779, 0.1787, 0.236...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0808, 0.0674, 0.0793, 0.0745, 0.0933, 0.066...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0852, 0.0771, 0.0935, 0.0591, 0.094, 0.0851...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.1371, 0.1175, 0.1372, 0.0899, 0.1005, 0.166...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0648, 0.0531, 0.0484, 0.0448, 0.0399, 0.067...</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0655, 0.0282, 0.0512, 0.0293, 0.0283, 0.046...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0534, 0.0394, 0.0431, 0.0372, 0.0329, 0.041...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0782, 0.0468, 0.0624, 0.0669, 0.0471, 0.059...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.095, 0.0284, 0.0852, 0.063, 0.037, 0.0399, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0645, 0.034, 0.0702, 0.0474, 0.0338, 0.0516...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0951, 0.0686, 0.089, 0.0822, 0.0872, 0.0883...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.1017, 0.0734, 0.0892, 0.0773, 0.1017, 0.088...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0781, 0.0404, 0.0639, 0.0413, 0.0323, 0.060...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.1175, 0.0736, 0.1428, 0.0686, 0.0888, 0.100...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0393, 0.0347, 0.0372, 0.0336, 0.0285, 0.042...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.1134, 0.1249, 0.0932, 0.1331, 0.1708, 0.139...</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.09, 0.0842, 0.0805, 0.1042, 0.0923, 0.1252,...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0843, 0.0625, 0.0864, 0.0745, 0.0754, 0.077...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.1, 0.061, 0.0824, 0.0978, 0.0794, 0.0671, 0...</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0566, 0.042, 0.0524, 0.0476, 0.0546, 0.052,...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0456, 0.0616, 0.0593, 0.0777, 0.0605, 0.057...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0503, 0.0504, 0.0609, 0.059, 0.0546, 0.0489...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1344, 0.0661, 0.0743, 0.0529, 0.0792, 0.106...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0699, 0.0407, 0.0732, 0.0623, 0.0441, 0.065...</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0585, 0.039, 0.0626, 0.0511, 0.0489, 0.0534...</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0717, 0.0405, 0.0575, 0.0495, 0.0596, 0.055...</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0954, 0.0675, 0.0762, 0.0742, 0.0655, 0.076...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0486, 0.0312, 0.037, 0.0324, 0.0421, 0.0354...</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.1061, 0.0513, 0.0538, 0.0709, 0.0485, 0.065...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0937, 0.0502, 0.0462, 0.0529, 0.0685, 0.074...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0872, 0.0709, 0.0458, 0.0605, 0.0637, 0.092...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0705, 0.0353, 0.0532, 0.0422, 0.0345, 0.049...</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0731, 0.0344, 0.0452, 0.0674, 0.0365, 0.036...</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0871, 0.0496, 0.0517, 0.0666, 0.0556, 0.062...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.1755, 0.0804, 0.0812, 0.1139, 0.0929, 0.106...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.1597, 0.1334, 0.1013, 0.101, 0.1376, 0.1559...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0651, 0.0418, 0.0632, 0.0413, 0.0405, 0.053...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.24, 0.1631, 0.182, 0.1632, 0.2281, 0.241, 0...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0518, 0.0502, 0.0362, 0.0439, 0.0588, 0.05,...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0749, 0.0625, 0.0577, 0.0447, 0.0714, 0.070...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0489, 0.0313, 0.0381, 0.031, 0.0263, 0.0444...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0448, 0.0324, 0.0339, 0.0329, 0.0254, 0.040...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1645, 0.0493, 0.0947, 0.0705, 0.0644, 0.100...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0463, 0.0267, 0.048, 0.0388, 0.0408, 0.0281...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1246, 0.0336, 0.0721, 0.043, 0.0274, 0.0714...               0   \n",
       "1   [0.1302, 0.0355, 0.0813, 0.0507, 0.0375, 0.053...               0   \n",
       "2   [0.1157, 0.064, 0.091, 0.0579, 0.0545, 0.11, 0...               0   \n",
       "3   [0.1015, 0.0509, 0.0739, 0.0557, 0.0521, 0.069...               1   \n",
       "4   [0.0542, 0.0471, 0.0654, 0.0437, 0.0387, 0.046...               1   \n",
       "5   [0.0437, 0.0424, 0.0564, 0.0371, 0.044, 0.0457...               2   \n",
       "6   [0.1247, 0.0589, 0.0912, 0.0761, 0.0856, 0.086...               3   \n",
       "7   [0.1076, 0.0607, 0.095, 0.0896, 0.066, 0.0963,...               3   \n",
       "8   [0.2274, 0.1419, 0.2206, 0.1779, 0.1787, 0.236...               3   \n",
       "9   [0.0808, 0.0674, 0.0793, 0.0745, 0.0933, 0.066...               4   \n",
       "10  [0.0852, 0.0771, 0.0935, 0.0591, 0.094, 0.0851...               4   \n",
       "11  [0.1371, 0.1175, 0.1372, 0.0899, 0.1005, 0.166...               5   \n",
       "12  [0.0648, 0.0531, 0.0484, 0.0448, 0.0399, 0.067...               6   \n",
       "13  [0.0655, 0.0282, 0.0512, 0.0293, 0.0283, 0.046...               7   \n",
       "14  [0.0534, 0.0394, 0.0431, 0.0372, 0.0329, 0.041...               8   \n",
       "15  [0.0782, 0.0468, 0.0624, 0.0669, 0.0471, 0.059...               8   \n",
       "16  [0.095, 0.0284, 0.0852, 0.063, 0.037, 0.0399, ...               9   \n",
       "17  [0.0645, 0.034, 0.0702, 0.0474, 0.0338, 0.0516...               9   \n",
       "18  [0.0951, 0.0686, 0.089, 0.0822, 0.0872, 0.0883...              10   \n",
       "19  [0.1017, 0.0734, 0.0892, 0.0773, 0.1017, 0.088...              10   \n",
       "20  [0.0781, 0.0404, 0.0639, 0.0413, 0.0323, 0.060...              11   \n",
       "21  [0.1175, 0.0736, 0.1428, 0.0686, 0.0888, 0.100...              11   \n",
       "22  [0.0393, 0.0347, 0.0372, 0.0336, 0.0285, 0.042...              12   \n",
       "23  [0.1134, 0.1249, 0.0932, 0.1331, 0.1708, 0.139...              13   \n",
       "24  [0.09, 0.0842, 0.0805, 0.1042, 0.0923, 0.1252,...              13   \n",
       "25  [0.0843, 0.0625, 0.0864, 0.0745, 0.0754, 0.077...              14   \n",
       "26  [0.1, 0.061, 0.0824, 0.0978, 0.0794, 0.0671, 0...              14   \n",
       "27  [0.0566, 0.042, 0.0524, 0.0476, 0.0546, 0.052,...              15   \n",
       "28  [0.0456, 0.0616, 0.0593, 0.0777, 0.0605, 0.057...              15   \n",
       "29  [0.0503, 0.0504, 0.0609, 0.059, 0.0546, 0.0489...              15   \n",
       "30  [0.1344, 0.0661, 0.0743, 0.0529, 0.0792, 0.106...              16   \n",
       "31  [0.0699, 0.0407, 0.0732, 0.0623, 0.0441, 0.065...              17   \n",
       "32  [0.0585, 0.039, 0.0626, 0.0511, 0.0489, 0.0534...              17   \n",
       "33  [0.0717, 0.0405, 0.0575, 0.0495, 0.0596, 0.055...              18   \n",
       "34  [0.0954, 0.0675, 0.0762, 0.0742, 0.0655, 0.076...              19   \n",
       "35  [0.0486, 0.0312, 0.037, 0.0324, 0.0421, 0.0354...              20   \n",
       "36  [0.1061, 0.0513, 0.0538, 0.0709, 0.0485, 0.065...              21   \n",
       "37  [0.0937, 0.0502, 0.0462, 0.0529, 0.0685, 0.074...              21   \n",
       "38  [0.0872, 0.0709, 0.0458, 0.0605, 0.0637, 0.092...              22   \n",
       "39  [0.0705, 0.0353, 0.0532, 0.0422, 0.0345, 0.049...              22   \n",
       "40  [0.0731, 0.0344, 0.0452, 0.0674, 0.0365, 0.036...              22   \n",
       "41  [0.0871, 0.0496, 0.0517, 0.0666, 0.0556, 0.062...              22   \n",
       "42  [0.1755, 0.0804, 0.0812, 0.1139, 0.0929, 0.106...              23   \n",
       "43  [0.1597, 0.1334, 0.1013, 0.101, 0.1376, 0.1559...              23   \n",
       "44  [0.0651, 0.0418, 0.0632, 0.0413, 0.0405, 0.053...              23   \n",
       "45  [0.24, 0.1631, 0.182, 0.1632, 0.2281, 0.241, 0...              23   \n",
       "46  [0.0518, 0.0502, 0.0362, 0.0439, 0.0588, 0.05,...              24   \n",
       "47  [0.0749, 0.0625, 0.0577, 0.0447, 0.0714, 0.070...              24   \n",
       "48  [0.0489, 0.0313, 0.0381, 0.031, 0.0263, 0.0444...              25   \n",
       "49  [0.0448, 0.0324, 0.0339, 0.0329, 0.0254, 0.040...              25   \n",
       "50  [0.1645, 0.0493, 0.0947, 0.0705, 0.0644, 0.100...              26   \n",
       "51  [0.0463, 0.0267, 0.048, 0.0388, 0.0408, 0.0281...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.288462  0.165417  \n",
       "1                  0       NaN       NaN  \n",
       "2                  8       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                 12       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                 16       NaN       NaN  \n",
       "7                 16       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                 12       NaN       NaN  \n",
       "10                23       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                21       NaN       NaN  \n",
       "13                 0       NaN       NaN  \n",
       "14                12       NaN       NaN  \n",
       "15                12       NaN       NaN  \n",
       "16                26       NaN       NaN  \n",
       "17                23       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 2       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                23       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                23       NaN       NaN  \n",
       "26                21       NaN       NaN  \n",
       "27                23       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                23       NaN       NaN  \n",
       "30                16       NaN       NaN  \n",
       "31                21       NaN       NaN  \n",
       "32                12       NaN       NaN  \n",
       "33                23       NaN       NaN  \n",
       "34                12       NaN       NaN  \n",
       "35                23       NaN       NaN  \n",
       "36                21       NaN       NaN  \n",
       "37                 8       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                16       NaN       NaN  \n",
       "40                 7       NaN       NaN  \n",
       "41                21       NaN       NaN  \n",
       "42                16       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                12       NaN       NaN  \n",
       "47                12       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421 : Training: loss:  0.1597361\n",
      "422 : Training: loss:  0.16030571\n",
      "423 : Training: loss:  0.14440826\n",
      "424 : Training: loss:  0.15904233\n",
      "425 : Training: loss:  0.15786564\n",
      "426 : Training: loss:  0.14886978\n",
      "427 : Training: loss:  0.15964805\n",
      "428 : Training: loss:  0.15625083\n",
      "429 : Training: loss:  0.15444857\n",
      "430 : Training: loss:  0.15108088\n",
      "431 : Training: loss:  0.18274927\n",
      "432 : Training: loss:  0.15395717\n",
      "433 : Training: loss:  0.14478837\n",
      "434 : Training: loss:  0.15078527\n",
      "435 : Training: loss:  0.16532356\n",
      "436 : Training: loss:  0.16731332\n",
      "437 : Training: loss:  0.15627834\n",
      "438 : Training: loss:  0.16259116\n",
      "439 : Training: loss:  0.16023166\n",
      "440 : Training: loss:  0.16694683\n",
      "Validation: Loss:  0.1622349  Accuracy:  0.28846154\n",
      "441 : Training: loss:  0.14351101\n",
      "442 : Training: loss:  0.15420301\n",
      "443 : Training: loss:  0.15625046\n",
      "444 : Training: loss:  0.17476088\n",
      "445 : Training: loss:  0.14641203\n",
      "446 : Training: loss:  0.15560445\n",
      "447 : Training: loss:  0.17860603\n",
      "448 : Training: loss:  0.16479054\n",
      "449 : Training: loss:  0.17179906\n",
      "450 : Training: loss:  0.17342548\n",
      "451 : Training: loss:  0.17206772\n",
      "452 : Training: loss:  0.14215806\n",
      "453 : Training: loss:  0.15091874\n",
      "454 : Training: loss:  0.15868568\n",
      "455 : Training: loss:  0.15315658\n",
      "456 : Training: loss:  0.15485808\n",
      "457 : Training: loss:  0.16355352\n",
      "458 : Training: loss:  0.1699293\n",
      "459 : Training: loss:  0.15046017\n",
      "460 : Training: loss:  0.15804237\n",
      "Validation: Loss:  0.15941519  Accuracy:  0.26923078\n",
      "461 : Training: loss:  0.16525838\n",
      "462 : Training: loss:  0.15541324\n",
      "463 : Training: loss:  0.15329626\n",
      "464 : Training: loss:  0.14479972\n",
      "465 : Training: loss:  0.15260647\n",
      "466 : Training: loss:  0.14913967\n",
      "467 : Training: loss:  0.15555695\n",
      "468 : Training: loss:  0.15035209\n",
      "469 : Training: loss:  0.1577914\n",
      "470 : Training: loss:  0.14575759\n",
      "471 : Training: loss:  0.1648134\n",
      "472 : Training: loss:  0.16057138\n",
      "473 : Training: loss:  0.15614189\n",
      "474 : Training: loss:  0.16019823\n",
      "475 : Training: loss:  0.15263532\n",
      "476 : Training: loss:  0.15369056\n",
      "477 : Training: loss:  0.15185444\n",
      "478 : Training: loss:  0.14012496\n",
      "479 : Training: loss:  0.14917634\n",
      "480 : Training: loss:  0.15833715\n",
      "Validation: Loss:  0.15702629  Accuracy:  0.34615386\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1096, 0.0297, 0.0646, 0.0398, 0.021, 0.0562...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.157026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1145, 0.0313, 0.0719, 0.046, 0.0287, 0.0422...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1035, 0.0577, 0.0814, 0.0538, 0.0416, 0.090...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0861, 0.0461, 0.0647, 0.0494, 0.0397, 0.054...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0455, 0.0439, 0.0598, 0.0386, 0.0291, 0.037...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0347, 0.0372, 0.0522, 0.0319, 0.0319, 0.035...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0992, 0.0493, 0.0764, 0.0675, 0.0625, 0.065...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0877, 0.0517, 0.0826, 0.0828, 0.0492, 0.074...</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.1972, 0.1191, 0.1921, 0.1661, 0.1412, 0.190...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0689, 0.0607, 0.0695, 0.0674, 0.0728, 0.054...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0711, 0.0707, 0.0832, 0.0518, 0.0719, 0.069...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.1189, 0.1047, 0.122, 0.081, 0.0798, 0.1402,...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0539, 0.0479, 0.0444, 0.0395, 0.0298, 0.054...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0558, 0.0255, 0.0467, 0.0265, 0.0208, 0.036...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0438, 0.0359, 0.0374, 0.0324, 0.0246, 0.032...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0661, 0.0408, 0.0539, 0.0608, 0.0357, 0.046...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0792, 0.0251, 0.0766, 0.0565, 0.0273, 0.030...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0539, 0.0304, 0.0642, 0.0423, 0.0248, 0.040...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0812, 0.0603, 0.082, 0.0715, 0.0693, 0.0712...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0857, 0.0638, 0.0808, 0.0664, 0.0798, 0.070...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0656, 0.0359, 0.0567, 0.0363, 0.0243, 0.047...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0995, 0.0664, 0.128, 0.062, 0.0698, 0.0819,...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.032, 0.0301, 0.0329, 0.0298, 0.0206, 0.0319...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0913, 0.1024, 0.0792, 0.1141, 0.1264, 0.109...</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.07, 0.0699, 0.0687, 0.0885, 0.0675, 0.0966,...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0705, 0.055, 0.0778, 0.0677, 0.0581, 0.0613...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0818, 0.0517, 0.0721, 0.0858, 0.0611, 0.052...</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0458, 0.0374, 0.0461, 0.0419, 0.0406, 0.040...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0361, 0.0549, 0.0528, 0.0684, 0.0443, 0.044...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0418, 0.0462, 0.055, 0.0538, 0.0416, 0.0392...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1203, 0.06, 0.0682, 0.0494, 0.0636, 0.0874,...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0569, 0.0351, 0.0643, 0.055, 0.0325, 0.05, ...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0482, 0.034, 0.0567, 0.0462, 0.0361, 0.0411...</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.06, 0.0354, 0.0518, 0.0435, 0.0453, 0.043, ...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0779, 0.0603, 0.0663, 0.0649, 0.0502, 0.062...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0409, 0.0276, 0.0337, 0.0289, 0.0312, 0.027...</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0874, 0.0454, 0.0466, 0.062, 0.0369, 0.0507...</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.077, 0.0426, 0.0393, 0.0465, 0.0509, 0.0548...</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0697, 0.0592, 0.0401, 0.0523, 0.0464, 0.07,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0577, 0.0306, 0.0463, 0.0372, 0.0255, 0.037...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.06, 0.0304, 0.04, 0.0607, 0.0268, 0.0286, 0...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0711, 0.0424, 0.0453, 0.0585, 0.0415, 0.047...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.1433, 0.0677, 0.0687, 0.0955, 0.0707, 0.081...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.1397, 0.119, 0.0909, 0.0876, 0.1156, 0.1288...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0546, 0.0378, 0.0581, 0.0378, 0.0311, 0.041...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.2045, 0.1373, 0.1556, 0.1463, 0.1822, 0.195...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0407, 0.0432, 0.0318, 0.0386, 0.0422, 0.037...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0613, 0.0543, 0.0509, 0.0403, 0.054, 0.0558...</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0397, 0.0282, 0.0342, 0.0283, 0.0195, 0.034...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0367, 0.0296, 0.0307, 0.0302, 0.0189, 0.031...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1473, 0.0429, 0.0828, 0.063, 0.0496, 0.0791...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.037, 0.0229, 0.0414, 0.0331, 0.0293, 0.0213...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1096, 0.0297, 0.0646, 0.0398, 0.021, 0.0562...               0   \n",
       "1   [0.1145, 0.0313, 0.0719, 0.046, 0.0287, 0.0422...               0   \n",
       "2   [0.1035, 0.0577, 0.0814, 0.0538, 0.0416, 0.090...               0   \n",
       "3   [0.0861, 0.0461, 0.0647, 0.0494, 0.0397, 0.054...               1   \n",
       "4   [0.0455, 0.0439, 0.0598, 0.0386, 0.0291, 0.037...               1   \n",
       "5   [0.0347, 0.0372, 0.0522, 0.0319, 0.0319, 0.035...               2   \n",
       "6   [0.0992, 0.0493, 0.0764, 0.0675, 0.0625, 0.065...               3   \n",
       "7   [0.0877, 0.0517, 0.0826, 0.0828, 0.0492, 0.074...               3   \n",
       "8   [0.1972, 0.1191, 0.1921, 0.1661, 0.1412, 0.190...               3   \n",
       "9   [0.0689, 0.0607, 0.0695, 0.0674, 0.0728, 0.054...               4   \n",
       "10  [0.0711, 0.0707, 0.0832, 0.0518, 0.0719, 0.069...               4   \n",
       "11  [0.1189, 0.1047, 0.122, 0.081, 0.0798, 0.1402,...               5   \n",
       "12  [0.0539, 0.0479, 0.0444, 0.0395, 0.0298, 0.054...               6   \n",
       "13  [0.0558, 0.0255, 0.0467, 0.0265, 0.0208, 0.036...               7   \n",
       "14  [0.0438, 0.0359, 0.0374, 0.0324, 0.0246, 0.032...               8   \n",
       "15  [0.0661, 0.0408, 0.0539, 0.0608, 0.0357, 0.046...               8   \n",
       "16  [0.0792, 0.0251, 0.0766, 0.0565, 0.0273, 0.030...               9   \n",
       "17  [0.0539, 0.0304, 0.0642, 0.0423, 0.0248, 0.040...               9   \n",
       "18  [0.0812, 0.0603, 0.082, 0.0715, 0.0693, 0.0712...              10   \n",
       "19  [0.0857, 0.0638, 0.0808, 0.0664, 0.0798, 0.070...              10   \n",
       "20  [0.0656, 0.0359, 0.0567, 0.0363, 0.0243, 0.047...              11   \n",
       "21  [0.0995, 0.0664, 0.128, 0.062, 0.0698, 0.0819,...              11   \n",
       "22  [0.032, 0.0301, 0.0329, 0.0298, 0.0206, 0.0319...              12   \n",
       "23  [0.0913, 0.1024, 0.0792, 0.1141, 0.1264, 0.109...              13   \n",
       "24  [0.07, 0.0699, 0.0687, 0.0885, 0.0675, 0.0966,...              13   \n",
       "25  [0.0705, 0.055, 0.0778, 0.0677, 0.0581, 0.0613...              14   \n",
       "26  [0.0818, 0.0517, 0.0721, 0.0858, 0.0611, 0.052...              14   \n",
       "27  [0.0458, 0.0374, 0.0461, 0.0419, 0.0406, 0.040...              15   \n",
       "28  [0.0361, 0.0549, 0.0528, 0.0684, 0.0443, 0.044...              15   \n",
       "29  [0.0418, 0.0462, 0.055, 0.0538, 0.0416, 0.0392...              15   \n",
       "30  [0.1203, 0.06, 0.0682, 0.0494, 0.0636, 0.0874,...              16   \n",
       "31  [0.0569, 0.0351, 0.0643, 0.055, 0.0325, 0.05, ...              17   \n",
       "32  [0.0482, 0.034, 0.0567, 0.0462, 0.0361, 0.0411...              17   \n",
       "33  [0.06, 0.0354, 0.0518, 0.0435, 0.0453, 0.043, ...              18   \n",
       "34  [0.0779, 0.0603, 0.0663, 0.0649, 0.0502, 0.062...              19   \n",
       "35  [0.0409, 0.0276, 0.0337, 0.0289, 0.0312, 0.027...              20   \n",
       "36  [0.0874, 0.0454, 0.0466, 0.062, 0.0369, 0.0507...              21   \n",
       "37  [0.077, 0.0426, 0.0393, 0.0465, 0.0509, 0.0548...              21   \n",
       "38  [0.0697, 0.0592, 0.0401, 0.0523, 0.0464, 0.07,...              22   \n",
       "39  [0.0577, 0.0306, 0.0463, 0.0372, 0.0255, 0.037...              22   \n",
       "40  [0.06, 0.0304, 0.04, 0.0607, 0.0268, 0.0286, 0...              22   \n",
       "41  [0.0711, 0.0424, 0.0453, 0.0585, 0.0415, 0.047...              22   \n",
       "42  [0.1433, 0.0677, 0.0687, 0.0955, 0.0707, 0.081...              23   \n",
       "43  [0.1397, 0.119, 0.0909, 0.0876, 0.1156, 0.1288...              23   \n",
       "44  [0.0546, 0.0378, 0.0581, 0.0378, 0.0311, 0.041...              23   \n",
       "45  [0.2045, 0.1373, 0.1556, 0.1463, 0.1822, 0.195...              23   \n",
       "46  [0.0407, 0.0432, 0.0318, 0.0386, 0.0422, 0.037...              24   \n",
       "47  [0.0613, 0.0543, 0.0509, 0.0403, 0.054, 0.0558...              24   \n",
       "48  [0.0397, 0.0282, 0.0342, 0.0283, 0.0195, 0.034...              25   \n",
       "49  [0.0367, 0.0296, 0.0307, 0.0302, 0.0189, 0.031...              25   \n",
       "50  [0.1473, 0.0429, 0.0828, 0.063, 0.0496, 0.0791...              26   \n",
       "51  [0.037, 0.0229, 0.0414, 0.0331, 0.0293, 0.0213...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.346154  0.157026  \n",
       "1                  0       NaN       NaN  \n",
       "2                  8       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  2       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                 16       NaN       NaN  \n",
       "7                 16       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                 12       NaN       NaN  \n",
       "10                23       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 0       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                23       NaN       NaN  \n",
       "17                23       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 2       NaN       NaN  \n",
       "22                23       NaN       NaN  \n",
       "23                23       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                23       NaN       NaN  \n",
       "26                21       NaN       NaN  \n",
       "27                23       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                23       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                23       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                23       NaN       NaN  \n",
       "36                 7       NaN       NaN  \n",
       "37                 8       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                21       NaN       NaN  \n",
       "42                16       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                12       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 : Training: loss:  0.15716517\n",
      "482 : Training: loss:  0.14789529\n",
      "483 : Training: loss:  0.1420212\n",
      "484 : Training: loss:  0.14533952\n",
      "485 : Training: loss:  0.15663765\n",
      "486 : Training: loss:  0.15323919\n",
      "487 : Training: loss:  0.15116748\n",
      "488 : Training: loss:  0.15250291\n",
      "489 : Training: loss:  0.1491968\n",
      "490 : Training: loss:  0.15565751\n",
      "491 : Training: loss:  0.15306412\n",
      "492 : Training: loss:  0.1549343\n",
      "493 : Training: loss:  0.15145414\n",
      "494 : Training: loss:  0.14984578\n",
      "495 : Training: loss:  0.13868012\n",
      "496 : Training: loss:  0.14936826\n",
      "497 : Training: loss:  0.13995774\n",
      "498 : Training: loss:  0.16289972\n",
      "499 : Training: loss:  0.14245556\n",
      "500 : Training: loss:  0.15683031\n",
      "Validation: Loss:  0.15478177  Accuracy:  0.34615386\n",
      "501 : Training: loss:  0.16335097\n",
      "502 : Training: loss:  0.14593282\n",
      "503 : Training: loss:  0.15241034\n",
      "504 : Training: loss:  0.1483833\n",
      "505 : Training: loss:  0.15597019\n",
      "506 : Training: loss:  0.1477927\n",
      "507 : Training: loss:  0.14299236\n",
      "508 : Training: loss:  0.13704023\n",
      "509 : Training: loss:  0.15991467\n",
      "510 : Training: loss:  0.16157359\n",
      "511 : Training: loss:  0.15582573\n",
      "512 : Training: loss:  0.15860973\n",
      "513 : Training: loss:  0.15584575\n",
      "514 : Training: loss:  0.1440026\n",
      "515 : Training: loss:  0.14827776\n",
      "516 : Training: loss:  0.15129824\n",
      "517 : Training: loss:  0.1448035\n",
      "518 : Training: loss:  0.14947146\n",
      "519 : Training: loss:  0.15139462\n",
      "520 : Training: loss:  0.15173538\n",
      "Validation: Loss:  0.15278824  Accuracy:  0.34615386\n",
      "521 : Training: loss:  0.13635373\n",
      "522 : Training: loss:  0.13421871\n",
      "523 : Training: loss:  0.14753403\n",
      "524 : Training: loss:  0.13555947\n",
      "525 : Training: loss:  0.14239684\n",
      "526 : Training: loss:  0.14700665\n",
      "527 : Training: loss:  0.14733422\n",
      "528 : Training: loss:  0.14631335\n",
      "529 : Training: loss:  0.15163122\n",
      "530 : Training: loss:  0.15184014\n",
      "531 : Training: loss:  0.13395938\n",
      "532 : Training: loss:  0.15184613\n",
      "533 : Training: loss:  0.15768844\n",
      "534 : Training: loss:  0.1521147\n",
      "535 : Training: loss:  0.13800688\n",
      "536 : Training: loss:  0.14767072\n",
      "537 : Training: loss:  0.15253645\n",
      "538 : Training: loss:  0.1471064\n",
      "539 : Training: loss:  0.15767384\n",
      "540 : Training: loss:  0.14460604\n",
      "Validation: Loss:  0.15112771  Accuracy:  0.3653846\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1039, 0.0258, 0.0568, 0.0378, 0.018, 0.0504...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.151128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1054, 0.0265, 0.0611, 0.0419, 0.0238, 0.036...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0956, 0.0502, 0.0688, 0.049, 0.0338, 0.0816...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0776, 0.0411, 0.0556, 0.0449, 0.034, 0.0488...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0394, 0.0395, 0.0513, 0.0341, 0.0239, 0.033...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0294, 0.0328, 0.0464, 0.0286, 0.0265, 0.031...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0821, 0.0402, 0.0614, 0.0601, 0.049, 0.0544...</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0749, 0.0441, 0.0699, 0.0784, 0.0396, 0.064...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.1739, 0.1, 0.1639, 0.1555, 0.114, 0.1632, 0...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0604, 0.0517, 0.0575, 0.0593, 0.0601, 0.049...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.059, 0.0606, 0.0676, 0.0435, 0.057, 0.0605,...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.1045, 0.0887, 0.1018, 0.0708, 0.0645, 0.126...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0463, 0.0412, 0.038, 0.0342, 0.024, 0.0481,...</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0502, 0.0225, 0.0403, 0.0243, 0.0171, 0.032...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0371, 0.0314, 0.0307, 0.0281, 0.0202, 0.028...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0571, 0.0334, 0.0435, 0.0537, 0.0285, 0.039...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0688, 0.0215, 0.0657, 0.0516, 0.0219, 0.026...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0453, 0.0252, 0.0531, 0.037, 0.0191, 0.0345...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0721, 0.0527, 0.0737, 0.0633, 0.0599, 0.064...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0762, 0.056, 0.0725, 0.0591, 0.0691, 0.0646...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.059, 0.0315, 0.0491, 0.0331, 0.021, 0.0418,...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0859, 0.0567, 0.1095, 0.0557, 0.0587, 0.071...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0274, 0.0252, 0.0274, 0.0264, 0.0166, 0.027...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0747, 0.0823, 0.0639, 0.0955, 0.0973, 0.091...</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0556, 0.0567, 0.0561, 0.0746, 0.0523, 0.081...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0603, 0.0461, 0.0661, 0.0607, 0.0477, 0.053...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0705, 0.0432, 0.0621, 0.0773, 0.0517, 0.045...</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0383, 0.0313, 0.038, 0.0366, 0.0328, 0.0351...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0293, 0.0467, 0.044, 0.0595, 0.0351, 0.0387...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0345, 0.0379, 0.0444, 0.0461, 0.0328, 0.033...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1092, 0.0513, 0.0584, 0.0444, 0.0535, 0.078...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0499, 0.0302, 0.0558, 0.0506, 0.0271, 0.043...</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0422, 0.0292, 0.0492, 0.0423, 0.0297, 0.036...</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0522, 0.0297, 0.0441, 0.0383, 0.0377, 0.037...</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.066, 0.0528, 0.0558, 0.0576, 0.0419, 0.0564...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0363, 0.0243, 0.0296, 0.0264, 0.026, 0.0241...</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0741, 0.039, 0.0386, 0.0541, 0.0297, 0.0436...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0635, 0.0347, 0.0313, 0.0398, 0.0393, 0.044...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.059, 0.0508, 0.0345, 0.0466, 0.0374, 0.061,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0494, 0.0262, 0.0392, 0.0336, 0.0209, 0.031...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0508, 0.0263, 0.0338, 0.0552, 0.021, 0.0247...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0607, 0.0359, 0.0383, 0.052, 0.0337, 0.0401...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.1161, 0.0553, 0.0554, 0.0787, 0.0551, 0.065...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.1171, 0.0979, 0.0748, 0.0711, 0.0955, 0.106...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0463, 0.0318, 0.0493, 0.0336, 0.0251, 0.034...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1705, 0.1073, 0.124, 0.1235, 0.1428, 0.1585...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0329, 0.0362, 0.0262, 0.0336, 0.0327, 0.032...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0518, 0.046, 0.0426, 0.0363, 0.0435, 0.0489...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0348, 0.0246, 0.0296, 0.0264, 0.0165, 0.030...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0317, 0.0257, 0.0261, 0.0277, 0.0156, 0.028...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1339, 0.0363, 0.0697, 0.056, 0.0402, 0.0671...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0311, 0.019, 0.0344, 0.0289, 0.0237, 0.0181...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1039, 0.0258, 0.0568, 0.0378, 0.018, 0.0504...               0   \n",
       "1   [0.1054, 0.0265, 0.0611, 0.0419, 0.0238, 0.036...               0   \n",
       "2   [0.0956, 0.0502, 0.0688, 0.049, 0.0338, 0.0816...               0   \n",
       "3   [0.0776, 0.0411, 0.0556, 0.0449, 0.034, 0.0488...               1   \n",
       "4   [0.0394, 0.0395, 0.0513, 0.0341, 0.0239, 0.033...               1   \n",
       "5   [0.0294, 0.0328, 0.0464, 0.0286, 0.0265, 0.031...               2   \n",
       "6   [0.0821, 0.0402, 0.0614, 0.0601, 0.049, 0.0544...               3   \n",
       "7   [0.0749, 0.0441, 0.0699, 0.0784, 0.0396, 0.064...               3   \n",
       "8   [0.1739, 0.1, 0.1639, 0.1555, 0.114, 0.1632, 0...               3   \n",
       "9   [0.0604, 0.0517, 0.0575, 0.0593, 0.0601, 0.049...               4   \n",
       "10  [0.059, 0.0606, 0.0676, 0.0435, 0.057, 0.0605,...               4   \n",
       "11  [0.1045, 0.0887, 0.1018, 0.0708, 0.0645, 0.126...               5   \n",
       "12  [0.0463, 0.0412, 0.038, 0.0342, 0.024, 0.0481,...               6   \n",
       "13  [0.0502, 0.0225, 0.0403, 0.0243, 0.0171, 0.032...               7   \n",
       "14  [0.0371, 0.0314, 0.0307, 0.0281, 0.0202, 0.028...               8   \n",
       "15  [0.0571, 0.0334, 0.0435, 0.0537, 0.0285, 0.039...               8   \n",
       "16  [0.0688, 0.0215, 0.0657, 0.0516, 0.0219, 0.026...               9   \n",
       "17  [0.0453, 0.0252, 0.0531, 0.037, 0.0191, 0.0345...               9   \n",
       "18  [0.0721, 0.0527, 0.0737, 0.0633, 0.0599, 0.064...              10   \n",
       "19  [0.0762, 0.056, 0.0725, 0.0591, 0.0691, 0.0646...              10   \n",
       "20  [0.059, 0.0315, 0.0491, 0.0331, 0.021, 0.0418,...              11   \n",
       "21  [0.0859, 0.0567, 0.1095, 0.0557, 0.0587, 0.071...              11   \n",
       "22  [0.0274, 0.0252, 0.0274, 0.0264, 0.0166, 0.027...              12   \n",
       "23  [0.0747, 0.0823, 0.0639, 0.0955, 0.0973, 0.091...              13   \n",
       "24  [0.0556, 0.0567, 0.0561, 0.0746, 0.0523, 0.081...              13   \n",
       "25  [0.0603, 0.0461, 0.0661, 0.0607, 0.0477, 0.053...              14   \n",
       "26  [0.0705, 0.0432, 0.0621, 0.0773, 0.0517, 0.045...              14   \n",
       "27  [0.0383, 0.0313, 0.038, 0.0366, 0.0328, 0.0351...              15   \n",
       "28  [0.0293, 0.0467, 0.044, 0.0595, 0.0351, 0.0387...              15   \n",
       "29  [0.0345, 0.0379, 0.0444, 0.0461, 0.0328, 0.033...              15   \n",
       "30  [0.1092, 0.0513, 0.0584, 0.0444, 0.0535, 0.078...              16   \n",
       "31  [0.0499, 0.0302, 0.0558, 0.0506, 0.0271, 0.043...              17   \n",
       "32  [0.0422, 0.0292, 0.0492, 0.0423, 0.0297, 0.036...              17   \n",
       "33  [0.0522, 0.0297, 0.0441, 0.0383, 0.0377, 0.037...              18   \n",
       "34  [0.066, 0.0528, 0.0558, 0.0576, 0.0419, 0.0564...              19   \n",
       "35  [0.0363, 0.0243, 0.0296, 0.0264, 0.026, 0.0241...              20   \n",
       "36  [0.0741, 0.039, 0.0386, 0.0541, 0.0297, 0.0436...              21   \n",
       "37  [0.0635, 0.0347, 0.0313, 0.0398, 0.0393, 0.044...              21   \n",
       "38  [0.059, 0.0508, 0.0345, 0.0466, 0.0374, 0.061,...              22   \n",
       "39  [0.0494, 0.0262, 0.0392, 0.0336, 0.0209, 0.031...              22   \n",
       "40  [0.0508, 0.0263, 0.0338, 0.0552, 0.021, 0.0247...              22   \n",
       "41  [0.0607, 0.0359, 0.0383, 0.052, 0.0337, 0.0401...              22   \n",
       "42  [0.1161, 0.0553, 0.0554, 0.0787, 0.0551, 0.065...              23   \n",
       "43  [0.1171, 0.0979, 0.0748, 0.0711, 0.0955, 0.106...              23   \n",
       "44  [0.0463, 0.0318, 0.0493, 0.0336, 0.0251, 0.034...              23   \n",
       "45  [0.1705, 0.1073, 0.124, 0.1235, 0.1428, 0.1585...              23   \n",
       "46  [0.0329, 0.0362, 0.0262, 0.0336, 0.0327, 0.032...              24   \n",
       "47  [0.0518, 0.046, 0.0426, 0.0363, 0.0435, 0.0489...              24   \n",
       "48  [0.0348, 0.0246, 0.0296, 0.0264, 0.0165, 0.030...              25   \n",
       "49  [0.0317, 0.0257, 0.0261, 0.0277, 0.0156, 0.028...              25   \n",
       "50  [0.1339, 0.0363, 0.0697, 0.056, 0.0402, 0.0671...              26   \n",
       "51  [0.0311, 0.019, 0.0344, 0.0289, 0.0237, 0.0181...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.365385  0.151128  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                 23       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                 23       NaN       NaN  \n",
       "7                 22       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                 12       NaN       NaN  \n",
       "10                23       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                23       NaN       NaN  \n",
       "13                 0       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                23       NaN       NaN  \n",
       "17                23       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 2       NaN       NaN  \n",
       "22                23       NaN       NaN  \n",
       "23                23       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                23       NaN       NaN  \n",
       "26                21       NaN       NaN  \n",
       "27                23       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                23       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                23       NaN       NaN  \n",
       "32                23       NaN       NaN  \n",
       "33                23       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                23       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                22       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541 : Training: loss:  0.15071781\n",
      "542 : Training: loss:  0.14317258\n",
      "543 : Training: loss:  0.14785673\n",
      "544 : Training: loss:  0.1535222\n",
      "545 : Training: loss:  0.15294077\n",
      "546 : Training: loss:  0.14898247\n",
      "547 : Training: loss:  0.15434752\n",
      "548 : Training: loss:  0.14871897\n",
      "549 : Training: loss:  0.15241548\n",
      "550 : Training: loss:  0.15308546\n",
      "551 : Training: loss:  0.13555625\n",
      "552 : Training: loss:  0.1527011\n",
      "553 : Training: loss:  0.14686015\n",
      "554 : Training: loss:  0.1498459\n",
      "555 : Training: loss:  0.15491632\n",
      "556 : Training: loss:  0.15679522\n",
      "557 : Training: loss:  0.13293515\n",
      "558 : Training: loss:  0.14456026\n",
      "559 : Training: loss:  0.14299773\n",
      "560 : Training: loss:  0.14238733\n",
      "Validation: Loss:  0.14974093  Accuracy:  0.3653846\n",
      "561 : Training: loss:  0.14991544\n",
      "562 : Training: loss:  0.13673437\n",
      "563 : Training: loss:  0.138022\n",
      "564 : Training: loss:  0.14449124\n",
      "565 : Training: loss:  0.15532838\n",
      "566 : Training: loss:  0.15554425\n",
      "567 : Training: loss:  0.15531692\n",
      "568 : Training: loss:  0.14907178\n",
      "569 : Training: loss:  0.13142814\n",
      "570 : Training: loss:  0.15611294\n",
      "571 : Training: loss:  0.14534879\n",
      "572 : Training: loss:  0.14539808\n",
      "573 : Training: loss:  0.15271851\n",
      "574 : Training: loss:  0.15119018\n",
      "575 : Training: loss:  0.14769533\n",
      "576 : Training: loss:  0.13941903\n",
      "577 : Training: loss:  0.1488901\n",
      "578 : Training: loss:  0.14211519\n",
      "579 : Training: loss:  0.15291288\n",
      "580 : Training: loss:  0.15976715\n",
      "Validation: Loss:  0.14850129  Accuracy:  0.3846154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1008, 0.0234, 0.053, 0.0393, 0.0179, 0.0461...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.148501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1003, 0.0234, 0.0556, 0.0425, 0.0232, 0.032...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0908, 0.0441, 0.0621, 0.0491, 0.0322, 0.073...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0751, 0.0383, 0.0521, 0.0458, 0.0347, 0.045...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0366, 0.0358, 0.0477, 0.034, 0.0235, 0.0313...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0265, 0.03, 0.0442, 0.0285, 0.026, 0.0291, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0737, 0.0349, 0.0544, 0.0609, 0.0463, 0.047...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0679, 0.0393, 0.0637, 0.0828, 0.0373, 0.057...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.1609, 0.0879, 0.1489, 0.1599, 0.1033, 0.146...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0567, 0.0465, 0.0522, 0.0588, 0.0598, 0.046...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0535, 0.0534, 0.0608, 0.042, 0.0549, 0.0552...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0965, 0.0789, 0.0916, 0.0695, 0.0613, 0.116...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0432, 0.0377, 0.0354, 0.0335, 0.0235, 0.044...</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0471, 0.0202, 0.0374, 0.0248, 0.0168, 0.030...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0349, 0.029, 0.0282, 0.0285, 0.0207, 0.0271...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.054, 0.0303, 0.0398, 0.0557, 0.0285, 0.0363...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0634, 0.0194, 0.0609, 0.0532, 0.021, 0.024,...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0419, 0.0225, 0.0494, 0.0377, 0.0184, 0.031...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0679, 0.049, 0.071, 0.0619, 0.0599, 0.061, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.071, 0.0513, 0.0687, 0.0573, 0.068, 0.0607,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0565, 0.0294, 0.0463, 0.0336, 0.0217, 0.038...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0807, 0.0522, 0.1026, 0.0567, 0.0594, 0.066...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0257, 0.0229, 0.0256, 0.027, 0.0166, 0.025,...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.067, 0.0719, 0.0573, 0.091, 0.0905, 0.083, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0498, 0.0512, 0.0517, 0.0735, 0.0503, 0.074...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0561, 0.0417, 0.0618, 0.0609, 0.0471, 0.049...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0651, 0.0395, 0.058, 0.0767, 0.051, 0.0416,...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0357, 0.0289, 0.0355, 0.0372, 0.0337, 0.032...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0268, 0.0435, 0.0415, 0.0607, 0.0353, 0.036...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0321, 0.0349, 0.0413, 0.0472, 0.0333, 0.031...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.105, 0.0465, 0.0542, 0.0444, 0.0532, 0.0721...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0474, 0.0279, 0.0532, 0.0519, 0.0273, 0.041...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0393, 0.0265, 0.0464, 0.0433, 0.0297, 0.033...</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0489, 0.0268, 0.0413, 0.0376, 0.0381, 0.034...</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0614, 0.0493, 0.0522, 0.0582, 0.0423, 0.053...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0339, 0.022, 0.0277, 0.0266, 0.0255, 0.0223...</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.068, 0.0352, 0.0347, 0.0538, 0.0281, 0.0396...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0584, 0.0305, 0.0279, 0.0396, 0.0373, 0.039...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0537, 0.0457, 0.0315, 0.0459, 0.035, 0.0555...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0464, 0.024, 0.0366, 0.0348, 0.0205, 0.0294...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0467, 0.0237, 0.0309, 0.0573, 0.0196, 0.022...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0563, 0.0327, 0.0354, 0.0525, 0.0326, 0.036...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.1053, 0.0493, 0.0499, 0.075, 0.0512, 0.0585...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.1093, 0.0894, 0.0688, 0.0666, 0.0935, 0.097...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0428, 0.0287, 0.0457, 0.0342, 0.0246, 0.031...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1569, 0.0935, 0.1115, 0.1188, 0.1332, 0.14,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0295, 0.0322, 0.0238, 0.0336, 0.0314, 0.029...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0468, 0.0405, 0.0385, 0.0363, 0.0411, 0.044...</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.033, 0.023, 0.028, 0.0276, 0.0172, 0.0287, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0299, 0.024, 0.0245, 0.0289, 0.0158, 0.0271...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1297, 0.0322, 0.064, 0.0561, 0.0387, 0.0612...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0289, 0.0172, 0.0321, 0.0294, 0.0242, 0.016...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1008, 0.0234, 0.053, 0.0393, 0.0179, 0.0461...               0   \n",
       "1   [0.1003, 0.0234, 0.0556, 0.0425, 0.0232, 0.032...               0   \n",
       "2   [0.0908, 0.0441, 0.0621, 0.0491, 0.0322, 0.073...               0   \n",
       "3   [0.0751, 0.0383, 0.0521, 0.0458, 0.0347, 0.045...               1   \n",
       "4   [0.0366, 0.0358, 0.0477, 0.034, 0.0235, 0.0313...               1   \n",
       "5   [0.0265, 0.03, 0.0442, 0.0285, 0.026, 0.0291, ...               2   \n",
       "6   [0.0737, 0.0349, 0.0544, 0.0609, 0.0463, 0.047...               3   \n",
       "7   [0.0679, 0.0393, 0.0637, 0.0828, 0.0373, 0.057...               3   \n",
       "8   [0.1609, 0.0879, 0.1489, 0.1599, 0.1033, 0.146...               3   \n",
       "9   [0.0567, 0.0465, 0.0522, 0.0588, 0.0598, 0.046...               4   \n",
       "10  [0.0535, 0.0534, 0.0608, 0.042, 0.0549, 0.0552...               4   \n",
       "11  [0.0965, 0.0789, 0.0916, 0.0695, 0.0613, 0.116...               5   \n",
       "12  [0.0432, 0.0377, 0.0354, 0.0335, 0.0235, 0.044...               6   \n",
       "13  [0.0471, 0.0202, 0.0374, 0.0248, 0.0168, 0.030...               7   \n",
       "14  [0.0349, 0.029, 0.0282, 0.0285, 0.0207, 0.0271...               8   \n",
       "15  [0.054, 0.0303, 0.0398, 0.0557, 0.0285, 0.0363...               8   \n",
       "16  [0.0634, 0.0194, 0.0609, 0.0532, 0.021, 0.024,...               9   \n",
       "17  [0.0419, 0.0225, 0.0494, 0.0377, 0.0184, 0.031...               9   \n",
       "18  [0.0679, 0.049, 0.071, 0.0619, 0.0599, 0.061, ...              10   \n",
       "19  [0.071, 0.0513, 0.0687, 0.0573, 0.068, 0.0607,...              10   \n",
       "20  [0.0565, 0.0294, 0.0463, 0.0336, 0.0217, 0.038...              11   \n",
       "21  [0.0807, 0.0522, 0.1026, 0.0567, 0.0594, 0.066...              11   \n",
       "22  [0.0257, 0.0229, 0.0256, 0.027, 0.0166, 0.025,...              12   \n",
       "23  [0.067, 0.0719, 0.0573, 0.091, 0.0905, 0.083, ...              13   \n",
       "24  [0.0498, 0.0512, 0.0517, 0.0735, 0.0503, 0.074...              13   \n",
       "25  [0.0561, 0.0417, 0.0618, 0.0609, 0.0471, 0.049...              14   \n",
       "26  [0.0651, 0.0395, 0.058, 0.0767, 0.051, 0.0416,...              14   \n",
       "27  [0.0357, 0.0289, 0.0355, 0.0372, 0.0337, 0.032...              15   \n",
       "28  [0.0268, 0.0435, 0.0415, 0.0607, 0.0353, 0.036...              15   \n",
       "29  [0.0321, 0.0349, 0.0413, 0.0472, 0.0333, 0.031...              15   \n",
       "30  [0.105, 0.0465, 0.0542, 0.0444, 0.0532, 0.0721...              16   \n",
       "31  [0.0474, 0.0279, 0.0532, 0.0519, 0.0273, 0.041...              17   \n",
       "32  [0.0393, 0.0265, 0.0464, 0.0433, 0.0297, 0.033...              17   \n",
       "33  [0.0489, 0.0268, 0.0413, 0.0376, 0.0381, 0.034...              18   \n",
       "34  [0.0614, 0.0493, 0.0522, 0.0582, 0.0423, 0.053...              19   \n",
       "35  [0.0339, 0.022, 0.0277, 0.0266, 0.0255, 0.0223...              20   \n",
       "36  [0.068, 0.0352, 0.0347, 0.0538, 0.0281, 0.0396...              21   \n",
       "37  [0.0584, 0.0305, 0.0279, 0.0396, 0.0373, 0.039...              21   \n",
       "38  [0.0537, 0.0457, 0.0315, 0.0459, 0.035, 0.0555...              22   \n",
       "39  [0.0464, 0.024, 0.0366, 0.0348, 0.0205, 0.0294...              22   \n",
       "40  [0.0467, 0.0237, 0.0309, 0.0573, 0.0196, 0.022...              22   \n",
       "41  [0.0563, 0.0327, 0.0354, 0.0525, 0.0326, 0.036...              22   \n",
       "42  [0.1053, 0.0493, 0.0499, 0.075, 0.0512, 0.0585...              23   \n",
       "43  [0.1093, 0.0894, 0.0688, 0.0666, 0.0935, 0.097...              23   \n",
       "44  [0.0428, 0.0287, 0.0457, 0.0342, 0.0246, 0.031...              23   \n",
       "45  [0.1569, 0.0935, 0.1115, 0.1188, 0.1332, 0.14,...              23   \n",
       "46  [0.0295, 0.0322, 0.0238, 0.0336, 0.0314, 0.029...              24   \n",
       "47  [0.0468, 0.0405, 0.0385, 0.0363, 0.0411, 0.044...              24   \n",
       "48  [0.033, 0.023, 0.028, 0.0276, 0.0172, 0.0287, ...              25   \n",
       "49  [0.0299, 0.024, 0.0245, 0.0289, 0.0158, 0.0271...              25   \n",
       "50  [0.1297, 0.0322, 0.064, 0.0561, 0.0387, 0.0612...              26   \n",
       "51  [0.0289, 0.0172, 0.0321, 0.0294, 0.0242, 0.016...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.384615  0.148501  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                 23       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  7       NaN       NaN  \n",
       "7                 22       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                23       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                23       NaN       NaN  \n",
       "13                 0       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                23       NaN       NaN  \n",
       "17                23       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 2       NaN       NaN  \n",
       "22                23       NaN       NaN  \n",
       "23                23       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                23       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                23       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                23       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                23       NaN       NaN  \n",
       "33                23       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                23       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                22       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                 7       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "581 : Training: loss:  0.1472619\n",
      "582 : Training: loss:  0.14032295\n",
      "583 : Training: loss:  0.14427832\n",
      "584 : Training: loss:  0.1386879\n",
      "585 : Training: loss:  0.13745195\n",
      "586 : Training: loss:  0.14979762\n",
      "587 : Training: loss:  0.1398443\n",
      "588 : Training: loss:  0.14612785\n",
      "589 : Training: loss:  0.14234033\n",
      "590 : Training: loss:  0.14778787\n",
      "591 : Training: loss:  0.14145376\n",
      "592 : Training: loss:  0.15072247\n",
      "593 : Training: loss:  0.13549839\n",
      "594 : Training: loss:  0.1448601\n",
      "595 : Training: loss:  0.1525792\n",
      "596 : Training: loss:  0.14358054\n",
      "597 : Training: loss:  0.15643413\n",
      "598 : Training: loss:  0.15198746\n",
      "599 : Training: loss:  0.13246197\n",
      "600 : Training: loss:  0.14192796\n",
      "Validation: Loss:  0.1473217  Accuracy:  0.3653846\n",
      "601 : Training: loss:  0.14442185\n",
      "602 : Training: loss:  0.13684115\n",
      "603 : Training: loss:  0.137201\n",
      "604 : Training: loss:  0.14434461\n",
      "605 : Training: loss:  0.14937326\n",
      "606 : Training: loss:  0.1469376\n",
      "607 : Training: loss:  0.14443937\n",
      "608 : Training: loss:  0.14425509\n",
      "609 : Training: loss:  0.15110913\n",
      "610 : Training: loss:  0.14434482\n",
      "611 : Training: loss:  0.14923368\n",
      "612 : Training: loss:  0.13369538\n",
      "613 : Training: loss:  0.14127944\n",
      "614 : Training: loss:  0.13828716\n",
      "615 : Training: loss:  0.15259488\n",
      "616 : Training: loss:  0.14218089\n",
      "617 : Training: loss:  0.14630233\n",
      "618 : Training: loss:  0.15150014\n",
      "619 : Training: loss:  0.1391929\n",
      "620 : Training: loss:  0.1263098\n",
      "Validation: Loss:  0.1461673  Accuracy:  0.3846154\n",
      "621 : Training: loss:  0.14964944\n",
      "622 : Training: loss:  0.15388864\n",
      "623 : Training: loss:  0.14091551\n",
      "624 : Training: loss:  0.14350972\n",
      "625 : Training: loss:  0.13247406\n",
      "626 : Training: loss:  0.15087163\n",
      "627 : Training: loss:  0.1431289\n",
      "628 : Training: loss:  0.14592531\n",
      "629 : Training: loss:  0.13398606\n",
      "630 : Training: loss:  0.15456907\n",
      "631 : Training: loss:  0.14503923\n",
      "632 : Training: loss:  0.13972238\n",
      "633 : Training: loss:  0.14121059\n",
      "634 : Training: loss:  0.14042385\n",
      "635 : Training: loss:  0.12536952\n",
      "636 : Training: loss:  0.147326\n",
      "637 : Training: loss:  0.13349172\n",
      "638 : Training: loss:  0.1354747\n",
      "639 : Training: loss:  0.14278466\n",
      "640 : Training: loss:  0.12986898\n",
      "Validation: Loss:  0.14519846  Accuracy:  0.42307693\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0944, 0.0216, 0.0512, 0.0435, 0.0174, 0.043...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.145198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0923, 0.0212, 0.0524, 0.0461, 0.0222, 0.029...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0826, 0.0396, 0.0581, 0.0536, 0.0303, 0.069...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0683, 0.0357, 0.0491, 0.0487, 0.034, 0.0432...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0321, 0.0332, 0.0461, 0.0356, 0.0232, 0.029...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0229, 0.028, 0.0451, 0.0303, 0.0258, 0.0277...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0615, 0.0296, 0.0486, 0.0658, 0.0429, 0.041...</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0571, 0.0338, 0.0591, 0.0935, 0.0347, 0.051...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.1382, 0.0731, 0.1339, 0.172, 0.0908, 0.126,...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0508, 0.0424, 0.0481, 0.0621, 0.0589, 0.044...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0461, 0.0476, 0.0558, 0.0426, 0.0528, 0.051...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0841, 0.0699, 0.083, 0.0701, 0.0568, 0.1097...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0378, 0.0352, 0.0344, 0.035, 0.0225, 0.0426...</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0424, 0.0186, 0.0365, 0.0272, 0.0162, 0.029...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0303, 0.0265, 0.0261, 0.0296, 0.0204, 0.025...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.047, 0.0269, 0.0364, 0.0606, 0.0273, 0.0332...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0556, 0.0175, 0.059, 0.0591, 0.02, 0.0218, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0366, 0.0206, 0.0485, 0.0416, 0.0176, 0.030...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0619, 0.0449, 0.07, 0.0618, 0.0584, 0.0579,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0638, 0.0463, 0.0663, 0.0567, 0.0657, 0.057...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.051, 0.0275, 0.0445, 0.0355, 0.0214, 0.0365...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0721, 0.0473, 0.0963, 0.0599, 0.0573, 0.060...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0224, 0.0214, 0.0252, 0.0302, 0.0166, 0.023...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0555, 0.0612, 0.0517, 0.0918, 0.0813, 0.074...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0413, 0.045, 0.0483, 0.0757, 0.0469, 0.0681...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0486, 0.037, 0.058, 0.0645, 0.045, 0.0443, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0566, 0.0354, 0.0546, 0.0794, 0.0491, 0.037...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0312, 0.027, 0.034, 0.0398, 0.0333, 0.0314,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0224, 0.0404, 0.0403, 0.066, 0.035, 0.0347,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0276, 0.0322, 0.0392, 0.0513, 0.0329, 0.029...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.0976, 0.0421, 0.051, 0.0468, 0.0505, 0.0685...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0423, 0.0263, 0.0525, 0.0578, 0.0272, 0.038...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0347, 0.0242, 0.046, 0.0489, 0.0294, 0.0306...</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0434, 0.0243, 0.0398, 0.0389, 0.0372, 0.031...</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0532, 0.0442, 0.048, 0.0594, 0.0407, 0.0501...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0307, 0.0206, 0.0277, 0.0291, 0.0252, 0.021...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0579, 0.0316, 0.0316, 0.055, 0.0262, 0.0363...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0495, 0.0265, 0.0252, 0.0412, 0.0338, 0.035...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0461, 0.0408, 0.03, 0.048, 0.0324, 0.0514, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0408, 0.0219, 0.0349, 0.0376, 0.0197, 0.027...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0407, 0.0217, 0.0297, 0.0649, 0.0187, 0.021...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0488, 0.0294, 0.0335, 0.0555, 0.0307, 0.033...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.088, 0.0423, 0.0442, 0.0714, 0.0451, 0.0511...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0962, 0.0791, 0.062, 0.0608, 0.0852, 0.0884...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0379, 0.0263, 0.0448, 0.0376, 0.0239, 0.028...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1349, 0.0795, 0.0986, 0.1196, 0.1185, 0.121...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0249, 0.029, 0.0226, 0.0364, 0.0299, 0.0272...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0404, 0.0362, 0.0362, 0.0388, 0.0391, 0.041...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0294, 0.0219, 0.0277, 0.0313, 0.0177, 0.027...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0265, 0.0229, 0.024, 0.0327, 0.016, 0.0265,...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1203, 0.0288, 0.0598, 0.059, 0.0358, 0.0566...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0253, 0.0157, 0.031, 0.0319, 0.0245, 0.0155...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.0944, 0.0216, 0.0512, 0.0435, 0.0174, 0.043...               0   \n",
       "1   [0.0923, 0.0212, 0.0524, 0.0461, 0.0222, 0.029...               0   \n",
       "2   [0.0826, 0.0396, 0.0581, 0.0536, 0.0303, 0.069...               0   \n",
       "3   [0.0683, 0.0357, 0.0491, 0.0487, 0.034, 0.0432...               1   \n",
       "4   [0.0321, 0.0332, 0.0461, 0.0356, 0.0232, 0.029...               1   \n",
       "5   [0.0229, 0.028, 0.0451, 0.0303, 0.0258, 0.0277...               2   \n",
       "6   [0.0615, 0.0296, 0.0486, 0.0658, 0.0429, 0.041...               3   \n",
       "7   [0.0571, 0.0338, 0.0591, 0.0935, 0.0347, 0.051...               3   \n",
       "8   [0.1382, 0.0731, 0.1339, 0.172, 0.0908, 0.126,...               3   \n",
       "9   [0.0508, 0.0424, 0.0481, 0.0621, 0.0589, 0.044...               4   \n",
       "10  [0.0461, 0.0476, 0.0558, 0.0426, 0.0528, 0.051...               4   \n",
       "11  [0.0841, 0.0699, 0.083, 0.0701, 0.0568, 0.1097...               5   \n",
       "12  [0.0378, 0.0352, 0.0344, 0.035, 0.0225, 0.0426...               6   \n",
       "13  [0.0424, 0.0186, 0.0365, 0.0272, 0.0162, 0.029...               7   \n",
       "14  [0.0303, 0.0265, 0.0261, 0.0296, 0.0204, 0.025...               8   \n",
       "15  [0.047, 0.0269, 0.0364, 0.0606, 0.0273, 0.0332...               8   \n",
       "16  [0.0556, 0.0175, 0.059, 0.0591, 0.02, 0.0218, ...               9   \n",
       "17  [0.0366, 0.0206, 0.0485, 0.0416, 0.0176, 0.030...               9   \n",
       "18  [0.0619, 0.0449, 0.07, 0.0618, 0.0584, 0.0579,...              10   \n",
       "19  [0.0638, 0.0463, 0.0663, 0.0567, 0.0657, 0.057...              10   \n",
       "20  [0.051, 0.0275, 0.0445, 0.0355, 0.0214, 0.0365...              11   \n",
       "21  [0.0721, 0.0473, 0.0963, 0.0599, 0.0573, 0.060...              11   \n",
       "22  [0.0224, 0.0214, 0.0252, 0.0302, 0.0166, 0.023...              12   \n",
       "23  [0.0555, 0.0612, 0.0517, 0.0918, 0.0813, 0.074...              13   \n",
       "24  [0.0413, 0.045, 0.0483, 0.0757, 0.0469, 0.0681...              13   \n",
       "25  [0.0486, 0.037, 0.058, 0.0645, 0.045, 0.0443, ...              14   \n",
       "26  [0.0566, 0.0354, 0.0546, 0.0794, 0.0491, 0.037...              14   \n",
       "27  [0.0312, 0.027, 0.034, 0.0398, 0.0333, 0.0314,...              15   \n",
       "28  [0.0224, 0.0404, 0.0403, 0.066, 0.035, 0.0347,...              15   \n",
       "29  [0.0276, 0.0322, 0.0392, 0.0513, 0.0329, 0.029...              15   \n",
       "30  [0.0976, 0.0421, 0.051, 0.0468, 0.0505, 0.0685...              16   \n",
       "31  [0.0423, 0.0263, 0.0525, 0.0578, 0.0272, 0.038...              17   \n",
       "32  [0.0347, 0.0242, 0.046, 0.0489, 0.0294, 0.0306...              17   \n",
       "33  [0.0434, 0.0243, 0.0398, 0.0389, 0.0372, 0.031...              18   \n",
       "34  [0.0532, 0.0442, 0.048, 0.0594, 0.0407, 0.0501...              19   \n",
       "35  [0.0307, 0.0206, 0.0277, 0.0291, 0.0252, 0.021...              20   \n",
       "36  [0.0579, 0.0316, 0.0316, 0.055, 0.0262, 0.0363...              21   \n",
       "37  [0.0495, 0.0265, 0.0252, 0.0412, 0.0338, 0.035...              21   \n",
       "38  [0.0461, 0.0408, 0.03, 0.048, 0.0324, 0.0514, ...              22   \n",
       "39  [0.0408, 0.0219, 0.0349, 0.0376, 0.0197, 0.027...              22   \n",
       "40  [0.0407, 0.0217, 0.0297, 0.0649, 0.0187, 0.021...              22   \n",
       "41  [0.0488, 0.0294, 0.0335, 0.0555, 0.0307, 0.033...              22   \n",
       "42  [0.088, 0.0423, 0.0442, 0.0714, 0.0451, 0.0511...              23   \n",
       "43  [0.0962, 0.0791, 0.062, 0.0608, 0.0852, 0.0884...              23   \n",
       "44  [0.0379, 0.0263, 0.0448, 0.0376, 0.0239, 0.028...              23   \n",
       "45  [0.1349, 0.0795, 0.0986, 0.1196, 0.1185, 0.121...              23   \n",
       "46  [0.0249, 0.029, 0.0226, 0.0364, 0.0299, 0.0272...              24   \n",
       "47  [0.0404, 0.0362, 0.0362, 0.0388, 0.0391, 0.041...              24   \n",
       "48  [0.0294, 0.0219, 0.0277, 0.0313, 0.0177, 0.027...              25   \n",
       "49  [0.0265, 0.0229, 0.024, 0.0327, 0.016, 0.0265,...              25   \n",
       "50  [0.1203, 0.0288, 0.0598, 0.059, 0.0358, 0.0566...              26   \n",
       "51  [0.0253, 0.0157, 0.031, 0.0319, 0.0245, 0.0155...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.423077  0.145198  \n",
       "1                 23       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                 23       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                 23       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                23       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                23       NaN       NaN  \n",
       "13                 0       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                23       NaN       NaN  \n",
       "17                23       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 2       NaN       NaN  \n",
       "22                23       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                23       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                23       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                23       NaN       NaN  \n",
       "33                23       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                22       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641 : Training: loss:  0.14590882\n",
      "642 : Training: loss:  0.14373419\n",
      "643 : Training: loss:  0.14141048\n",
      "644 : Training: loss:  0.14675848\n",
      "645 : Training: loss:  0.1365701\n",
      "646 : Training: loss:  0.13511631\n",
      "647 : Training: loss:  0.13364615\n",
      "648 : Training: loss:  0.1572529\n",
      "649 : Training: loss:  0.119832814\n",
      "650 : Training: loss:  0.13790058\n",
      "651 : Training: loss:  0.1498092\n",
      "652 : Training: loss:  0.15431586\n",
      "653 : Training: loss:  0.1476472\n",
      "654 : Training: loss:  0.13711032\n",
      "655 : Training: loss:  0.15416679\n",
      "656 : Training: loss:  0.14865449\n",
      "657 : Training: loss:  0.13907841\n",
      "658 : Training: loss:  0.1303253\n",
      "659 : Training: loss:  0.15302385\n",
      "660 : Training: loss:  0.14327028\n",
      "Validation: Loss:  0.14439984  Accuracy:  0.3653846\n",
      "661 : Training: loss:  0.14747848\n",
      "662 : Training: loss:  0.14679979\n",
      "663 : Training: loss:  0.1601678\n",
      "664 : Training: loss:  0.13713625\n",
      "665 : Training: loss:  0.12507221\n",
      "666 : Training: loss:  0.14359957\n",
      "667 : Training: loss:  0.124362715\n",
      "668 : Training: loss:  0.14596568\n",
      "669 : Training: loss:  0.1382903\n",
      "670 : Training: loss:  0.13329464\n",
      "671 : Training: loss:  0.13790385\n",
      "672 : Training: loss:  0.1385516\n",
      "673 : Training: loss:  0.13851617\n",
      "674 : Training: loss:  0.14469257\n",
      "675 : Training: loss:  0.13669395\n",
      "676 : Training: loss:  0.13908517\n",
      "677 : Training: loss:  0.14665805\n",
      "678 : Training: loss:  0.13414147\n",
      "679 : Training: loss:  0.15151614\n",
      "680 : Training: loss:  0.15337436\n",
      "Validation: Loss:  0.14359336  Accuracy:  0.3846154\n",
      "681 : Training: loss:  0.14192039\n",
      "682 : Training: loss:  0.15005738\n",
      "683 : Training: loss:  0.13374317\n",
      "684 : Training: loss:  0.1421635\n",
      "685 : Training: loss:  0.12925825\n",
      "686 : Training: loss:  0.13301145\n",
      "687 : Training: loss:  0.14487664\n",
      "688 : Training: loss:  0.14498007\n",
      "689 : Training: loss:  0.12695749\n",
      "690 : Training: loss:  0.13895404\n",
      "691 : Training: loss:  0.12903978\n",
      "692 : Training: loss:  0.15033633\n",
      "693 : Training: loss:  0.13726076\n",
      "694 : Training: loss:  0.13764639\n",
      "695 : Training: loss:  0.14212024\n",
      "696 : Training: loss:  0.12417304\n",
      "697 : Training: loss:  0.14725174\n",
      "698 : Training: loss:  0.1438729\n",
      "699 : Training: loss:  0.13267219\n",
      "700 : Training: loss:  0.13483067\n",
      "Validation: Loss:  0.14268856  Accuracy:  0.40384614\n",
      "701 : Training: loss:  0.1465861\n",
      "702 : Training: loss:  0.13683146\n",
      "703 : Training: loss:  0.1534878\n",
      "704 : Training: loss:  0.1316331\n",
      "705 : Training: loss:  0.14835331\n",
      "706 : Training: loss:  0.11164189\n",
      "707 : Training: loss:  0.12152702\n",
      "708 : Training: loss:  0.13888268\n",
      "709 : Training: loss:  0.13408147\n",
      "710 : Training: loss:  0.14527358\n",
      "711 : Training: loss:  0.13750266\n",
      "712 : Training: loss:  0.14505175\n",
      "713 : Training: loss:  0.14563133\n",
      "714 : Training: loss:  0.12811922\n",
      "715 : Training: loss:  0.12626673\n",
      "716 : Training: loss:  0.14309394\n",
      "717 : Training: loss:  0.120397575\n",
      "718 : Training: loss:  0.13522273\n",
      "719 : Training: loss:  0.12817666\n",
      "720 : Training: loss:  0.1371577\n",
      "Validation: Loss:  0.14163397  Accuracy:  0.3653846\n",
      "721 : Training: loss:  0.14996825\n",
      "722 : Training: loss:  0.1292432\n",
      "723 : Training: loss:  0.13048364\n",
      "724 : Training: loss:  0.12547508\n",
      "725 : Training: loss:  0.12577477\n",
      "726 : Training: loss:  0.12528111\n",
      "727 : Training: loss:  0.11752897\n",
      "728 : Training: loss:  0.1291681\n",
      "729 : Training: loss:  0.13645647\n",
      "730 : Training: loss:  0.14942892\n",
      "731 : Training: loss:  0.13518816\n",
      "732 : Training: loss:  0.15352736\n",
      "733 : Training: loss:  0.13653927\n",
      "734 : Training: loss:  0.138411\n",
      "735 : Training: loss:  0.13483548\n",
      "736 : Training: loss:  0.13761121\n",
      "737 : Training: loss:  0.14725618\n",
      "738 : Training: loss:  0.14574045\n",
      "739 : Training: loss:  0.13287094\n",
      "740 : Training: loss:  0.1565419\n",
      "Validation: Loss:  0.14054377  Accuracy:  0.3653846\n",
      "741 : Training: loss:  0.13040918\n",
      "742 : Training: loss:  0.13577503\n",
      "743 : Training: loss:  0.13551897\n",
      "744 : Training: loss:  0.14803827\n",
      "745 : Training: loss:  0.14018467\n",
      "746 : Training: loss:  0.13690339\n",
      "747 : Training: loss:  0.14131646\n",
      "748 : Training: loss:  0.11829599\n",
      "749 : Training: loss:  0.13752209\n",
      "750 : Training: loss:  0.13665248\n",
      "751 : Training: loss:  0.13498442\n",
      "752 : Training: loss:  0.13938004\n",
      "753 : Training: loss:  0.13848998\n",
      "754 : Training: loss:  0.13961186\n",
      "755 : Training: loss:  0.15548775\n",
      "756 : Training: loss:  0.14722785\n",
      "757 : Training: loss:  0.12970218\n",
      "758 : Training: loss:  0.14198388\n",
      "759 : Training: loss:  0.12508382\n",
      "760 : Training: loss:  0.14656514\n",
      "Validation: Loss:  0.1396974  Accuracy:  0.40384614\n",
      "761 : Training: loss:  0.13138041\n",
      "762 : Training: loss:  0.1484727\n",
      "763 : Training: loss:  0.12186363\n",
      "764 : Training: loss:  0.14577688\n",
      "765 : Training: loss:  0.13574514\n",
      "766 : Training: loss:  0.14385515\n",
      "767 : Training: loss:  0.13442706\n",
      "768 : Training: loss:  0.13438624\n",
      "769 : Training: loss:  0.1325129\n",
      "770 : Training: loss:  0.13174841\n",
      "771 : Training: loss:  0.14674145\n",
      "772 : Training: loss:  0.14012662\n",
      "773 : Training: loss:  0.14759779\n",
      "774 : Training: loss:  0.11694413\n",
      "775 : Training: loss:  0.14691697\n",
      "776 : Training: loss:  0.14072077\n",
      "777 : Training: loss:  0.14161351\n",
      "778 : Training: loss:  0.14041173\n",
      "779 : Training: loss:  0.13975365\n",
      "780 : Training: loss:  0.11751665\n",
      "Validation: Loss:  0.13890466  Accuracy:  0.44230768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0997, 0.0192, 0.0403, 0.0383, 0.0151, 0.038...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.138905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0963, 0.0183, 0.0403, 0.0396, 0.0193, 0.024...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0869, 0.0344, 0.0439, 0.0469, 0.0248, 0.063...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0693, 0.0356, 0.0391, 0.0413, 0.0319, 0.039...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0305, 0.0328, 0.0374, 0.0291, 0.0216, 0.027...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0202, 0.0285, 0.0407, 0.0259, 0.0253, 0.026...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0536, 0.026, 0.0372, 0.0617, 0.0375, 0.0352...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0504, 0.0309, 0.0478, 0.095, 0.0303, 0.0443...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.1229, 0.0587, 0.1035, 0.1676, 0.07, 0.0988,...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.046, 0.0377, 0.0349, 0.0522, 0.053, 0.0403,...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0419, 0.0437, 0.0427, 0.0339, 0.0486, 0.047...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0754, 0.0603, 0.0608, 0.0566, 0.0477, 0.099...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0364, 0.0351, 0.0285, 0.0292, 0.0199, 0.040...</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0443, 0.0178, 0.0302, 0.0237, 0.0149, 0.028...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0299, 0.0274, 0.0208, 0.0252, 0.0208, 0.024...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0457, 0.025, 0.0278, 0.0564, 0.0259, 0.0291...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0537, 0.0166, 0.0501, 0.0542, 0.0175, 0.019...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0359, 0.0196, 0.041, 0.0371, 0.0158, 0.0279...</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0555, 0.0402, 0.0581, 0.0491, 0.0557, 0.050...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0567, 0.0412, 0.054, 0.0444, 0.0614, 0.0504...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0497, 0.0266, 0.0358, 0.0304, 0.0202, 0.032...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0672, 0.0454, 0.0785, 0.0541, 0.0553, 0.054...</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0215, 0.0214, 0.0208, 0.027, 0.0159, 0.0211...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0456, 0.0517, 0.0391, 0.078, 0.0688, 0.0634...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0329, 0.0404, 0.0383, 0.0658, 0.0422, 0.059...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0439, 0.0337, 0.0464, 0.058, 0.0416, 0.0382...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.047, 0.0308, 0.0422, 0.068, 0.0435, 0.0305,...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0278, 0.0266, 0.0271, 0.0336, 0.0318, 0.029...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0188, 0.0427, 0.0345, 0.0606, 0.0345, 0.033...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0251, 0.0323, 0.0313, 0.0461, 0.032, 0.0273...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1039, 0.0394, 0.0412, 0.041, 0.0479, 0.064,...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0393, 0.0252, 0.0441, 0.052, 0.0247, 0.0339...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0329, 0.023, 0.0395, 0.0463, 0.0279, 0.0274...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0406, 0.0219, 0.0319, 0.0318, 0.0352, 0.027...</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0477, 0.0428, 0.0379, 0.0526, 0.0387, 0.048...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0298, 0.0198, 0.0231, 0.025, 0.0237, 0.0194...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0515, 0.0284, 0.0238, 0.0453, 0.0216, 0.031...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0464, 0.0237, 0.0194, 0.0354, 0.0291, 0.029...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0404, 0.0379, 0.0244, 0.0418, 0.0276, 0.045...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0384, 0.0207, 0.0281, 0.033, 0.0174, 0.024,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0374, 0.0204, 0.024, 0.061, 0.0157, 0.0194,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0435, 0.0264, 0.0263, 0.0485, 0.0261, 0.028...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0734, 0.0352, 0.0328, 0.0557, 0.0362, 0.039...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0842, 0.0657, 0.0462, 0.045, 0.0761, 0.0697...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0373, 0.0263, 0.0388, 0.0339, 0.0233, 0.024...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1209, 0.0653, 0.0752, 0.1036, 0.0995, 0.097...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0219, 0.0289, 0.0187, 0.033, 0.0283, 0.0252...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0362, 0.0333, 0.0287, 0.0343, 0.0352, 0.038...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.029, 0.0244, 0.024, 0.029, 0.0182, 0.0271, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0258, 0.0253, 0.0204, 0.0302, 0.0161, 0.027...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.129, 0.0242, 0.0464, 0.0495, 0.0312, 0.0468...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0239, 0.0152, 0.0257, 0.0278, 0.0254, 0.013...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.0997, 0.0192, 0.0403, 0.0383, 0.0151, 0.038...               0   \n",
       "1   [0.0963, 0.0183, 0.0403, 0.0396, 0.0193, 0.024...               0   \n",
       "2   [0.0869, 0.0344, 0.0439, 0.0469, 0.0248, 0.063...               0   \n",
       "3   [0.0693, 0.0356, 0.0391, 0.0413, 0.0319, 0.039...               1   \n",
       "4   [0.0305, 0.0328, 0.0374, 0.0291, 0.0216, 0.027...               1   \n",
       "5   [0.0202, 0.0285, 0.0407, 0.0259, 0.0253, 0.026...               2   \n",
       "6   [0.0536, 0.026, 0.0372, 0.0617, 0.0375, 0.0352...               3   \n",
       "7   [0.0504, 0.0309, 0.0478, 0.095, 0.0303, 0.0443...               3   \n",
       "8   [0.1229, 0.0587, 0.1035, 0.1676, 0.07, 0.0988,...               3   \n",
       "9   [0.046, 0.0377, 0.0349, 0.0522, 0.053, 0.0403,...               4   \n",
       "10  [0.0419, 0.0437, 0.0427, 0.0339, 0.0486, 0.047...               4   \n",
       "11  [0.0754, 0.0603, 0.0608, 0.0566, 0.0477, 0.099...               5   \n",
       "12  [0.0364, 0.0351, 0.0285, 0.0292, 0.0199, 0.040...               6   \n",
       "13  [0.0443, 0.0178, 0.0302, 0.0237, 0.0149, 0.028...               7   \n",
       "14  [0.0299, 0.0274, 0.0208, 0.0252, 0.0208, 0.024...               8   \n",
       "15  [0.0457, 0.025, 0.0278, 0.0564, 0.0259, 0.0291...               8   \n",
       "16  [0.0537, 0.0166, 0.0501, 0.0542, 0.0175, 0.019...               9   \n",
       "17  [0.0359, 0.0196, 0.041, 0.0371, 0.0158, 0.0279...               9   \n",
       "18  [0.0555, 0.0402, 0.0581, 0.0491, 0.0557, 0.050...              10   \n",
       "19  [0.0567, 0.0412, 0.054, 0.0444, 0.0614, 0.0504...              10   \n",
       "20  [0.0497, 0.0266, 0.0358, 0.0304, 0.0202, 0.032...              11   \n",
       "21  [0.0672, 0.0454, 0.0785, 0.0541, 0.0553, 0.054...              11   \n",
       "22  [0.0215, 0.0214, 0.0208, 0.027, 0.0159, 0.0211...              12   \n",
       "23  [0.0456, 0.0517, 0.0391, 0.078, 0.0688, 0.0634...              13   \n",
       "24  [0.0329, 0.0404, 0.0383, 0.0658, 0.0422, 0.059...              13   \n",
       "25  [0.0439, 0.0337, 0.0464, 0.058, 0.0416, 0.0382...              14   \n",
       "26  [0.047, 0.0308, 0.0422, 0.068, 0.0435, 0.0305,...              14   \n",
       "27  [0.0278, 0.0266, 0.0271, 0.0336, 0.0318, 0.029...              15   \n",
       "28  [0.0188, 0.0427, 0.0345, 0.0606, 0.0345, 0.033...              15   \n",
       "29  [0.0251, 0.0323, 0.0313, 0.0461, 0.032, 0.0273...              15   \n",
       "30  [0.1039, 0.0394, 0.0412, 0.041, 0.0479, 0.064,...              16   \n",
       "31  [0.0393, 0.0252, 0.0441, 0.052, 0.0247, 0.0339...              17   \n",
       "32  [0.0329, 0.023, 0.0395, 0.0463, 0.0279, 0.0274...              17   \n",
       "33  [0.0406, 0.0219, 0.0319, 0.0318, 0.0352, 0.027...              18   \n",
       "34  [0.0477, 0.0428, 0.0379, 0.0526, 0.0387, 0.048...              19   \n",
       "35  [0.0298, 0.0198, 0.0231, 0.025, 0.0237, 0.0194...              20   \n",
       "36  [0.0515, 0.0284, 0.0238, 0.0453, 0.0216, 0.031...              21   \n",
       "37  [0.0464, 0.0237, 0.0194, 0.0354, 0.0291, 0.029...              21   \n",
       "38  [0.0404, 0.0379, 0.0244, 0.0418, 0.0276, 0.045...              22   \n",
       "39  [0.0384, 0.0207, 0.0281, 0.033, 0.0174, 0.024,...              22   \n",
       "40  [0.0374, 0.0204, 0.024, 0.061, 0.0157, 0.0194,...              22   \n",
       "41  [0.0435, 0.0264, 0.0263, 0.0485, 0.0261, 0.028...              22   \n",
       "42  [0.0734, 0.0352, 0.0328, 0.0557, 0.0362, 0.039...              23   \n",
       "43  [0.0842, 0.0657, 0.0462, 0.045, 0.0761, 0.0697...              23   \n",
       "44  [0.0373, 0.0263, 0.0388, 0.0339, 0.0233, 0.024...              23   \n",
       "45  [0.1209, 0.0653, 0.0752, 0.1036, 0.0995, 0.097...              23   \n",
       "46  [0.0219, 0.0289, 0.0187, 0.033, 0.0283, 0.0252...              24   \n",
       "47  [0.0362, 0.0333, 0.0287, 0.0343, 0.0352, 0.038...              24   \n",
       "48  [0.029, 0.0244, 0.024, 0.029, 0.0182, 0.0271, ...              25   \n",
       "49  [0.0258, 0.0253, 0.0204, 0.0302, 0.0161, 0.027...              25   \n",
       "50  [0.129, 0.0242, 0.0464, 0.0495, 0.0312, 0.0468...              26   \n",
       "51  [0.0239, 0.0152, 0.0257, 0.0278, 0.0254, 0.013...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.442308  0.138905  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  9       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  9       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                23       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                23       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                23       NaN       NaN  \n",
       "17                23       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 9       NaN       NaN  \n",
       "22                23       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                23       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                23       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                13       NaN       NaN  \n",
       "33                23       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                22       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                22       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781 : Training: loss:  0.1190745\n",
      "782 : Training: loss:  0.1261605\n",
      "783 : Training: loss:  0.13052654\n",
      "784 : Training: loss:  0.13479242\n",
      "785 : Training: loss:  0.13558064\n",
      "786 : Training: loss:  0.1403042\n",
      "787 : Training: loss:  0.13563007\n",
      "788 : Training: loss:  0.14606011\n",
      "789 : Training: loss:  0.12622197\n",
      "790 : Training: loss:  0.13533527\n",
      "791 : Training: loss:  0.14357854\n",
      "792 : Training: loss:  0.14980109\n",
      "793 : Training: loss:  0.14484316\n",
      "794 : Training: loss:  0.14085026\n",
      "795 : Training: loss:  0.14213206\n",
      "796 : Training: loss:  0.12989813\n",
      "797 : Training: loss:  0.13396704\n",
      "798 : Training: loss:  0.12748455\n",
      "799 : Training: loss:  0.13659507\n",
      "800 : Training: loss:  0.1284404\n",
      "Validation: Loss:  0.13799477  Accuracy:  0.44230768\n",
      "801 : Training: loss:  0.12898754\n",
      "802 : Training: loss:  0.12943107\n",
      "803 : Training: loss:  0.13581353\n",
      "804 : Training: loss:  0.1274055\n",
      "805 : Training: loss:  0.141493\n",
      "806 : Training: loss:  0.124528326\n",
      "807 : Training: loss:  0.12581025\n",
      "808 : Training: loss:  0.121133834\n",
      "809 : Training: loss:  0.12257099\n",
      "810 : Training: loss:  0.11566833\n",
      "811 : Training: loss:  0.121847026\n",
      "812 : Training: loss:  0.13700697\n",
      "813 : Training: loss:  0.12594204\n",
      "814 : Training: loss:  0.1293719\n",
      "815 : Training: loss:  0.13044053\n",
      "816 : Training: loss:  0.1334953\n",
      "817 : Training: loss:  0.13694905\n",
      "818 : Training: loss:  0.12714191\n",
      "819 : Training: loss:  0.117948815\n",
      "820 : Training: loss:  0.12083734\n",
      "Validation: Loss:  0.13721845  Accuracy:  0.46153846\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0974, 0.0197, 0.0428, 0.038, 0.0144, 0.0382...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.137218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0927, 0.0186, 0.042, 0.0386, 0.0183, 0.0244...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0833, 0.0352, 0.0452, 0.0458, 0.0231, 0.063...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0642, 0.037, 0.0398, 0.0389, 0.0297, 0.0391...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0279, 0.0345, 0.0395, 0.027, 0.0201, 0.0275...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0187, 0.0299, 0.0468, 0.025, 0.0245, 0.0263...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0493, 0.026, 0.0384, 0.0611, 0.035, 0.0344,...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0461, 0.0305, 0.0499, 0.0954, 0.0284, 0.043...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.1136, 0.0553, 0.104, 0.1664, 0.0645, 0.0927...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0423, 0.0381, 0.0346, 0.0493, 0.0495, 0.040...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0379, 0.0449, 0.0436, 0.0314, 0.0447, 0.046...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0682, 0.0584, 0.0592, 0.0514, 0.0428, 0.096...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0342, 0.0371, 0.031, 0.0282, 0.0187, 0.0406...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0416, 0.0184, 0.0325, 0.0227, 0.0139, 0.028...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.027, 0.0285, 0.0209, 0.0234, 0.0194, 0.0239...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0421, 0.0252, 0.0279, 0.0544, 0.0244, 0.028...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0503, 0.0169, 0.0547, 0.0535, 0.0166, 0.018...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0338, 0.0204, 0.0457, 0.0367, 0.015, 0.0281...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0507, 0.0393, 0.0601, 0.0448, 0.0519, 0.048...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0512, 0.0401, 0.0548, 0.0399, 0.0562, 0.047...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0469, 0.0278, 0.0379, 0.0297, 0.0194, 0.032...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.062, 0.0456, 0.0804, 0.0521, 0.0519, 0.0517...</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0204, 0.0234, 0.0233, 0.0269, 0.0156, 0.021...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0403, 0.0497, 0.0394, 0.0735, 0.0626, 0.059...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0296, 0.0398, 0.0404, 0.0638, 0.04, 0.0574,...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0403, 0.0341, 0.0483, 0.0565, 0.0389, 0.037...</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0437, 0.0309, 0.0442, 0.0672, 0.0417, 0.029...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0255, 0.028, 0.029, 0.0324, 0.0303, 0.0296,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0169, 0.045, 0.0372, 0.0587, 0.0329, 0.0335...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0231, 0.0342, 0.0335, 0.0454, 0.0308, 0.027...</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.0976, 0.0395, 0.0417, 0.0389, 0.0441, 0.062...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0376, 0.0267, 0.0486, 0.0523, 0.0242, 0.034...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0311, 0.0239, 0.044, 0.0467, 0.0271, 0.0272...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0378, 0.0226, 0.0337, 0.0304, 0.0331, 0.026...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0427, 0.0426, 0.0376, 0.0492, 0.0355, 0.046...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0279, 0.0205, 0.0254, 0.024, 0.0226, 0.0194...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0478, 0.029, 0.0246, 0.0433, 0.0201, 0.0308...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0428, 0.024, 0.0202, 0.0342, 0.027, 0.0282,...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0373, 0.0379, 0.0263, 0.0405, 0.0259, 0.044...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0359, 0.0212, 0.0302, 0.0322, 0.0166, 0.023...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0349, 0.0207, 0.0261, 0.0609, 0.015, 0.0196...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0406, 0.0266, 0.0283, 0.0475, 0.0247, 0.028...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0659, 0.0343, 0.0329, 0.0518, 0.0329, 0.036...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0764, 0.0635, 0.0454, 0.0412, 0.0701, 0.064...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0352, 0.0274, 0.0427, 0.0332, 0.0225, 0.024...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1129, 0.0649, 0.0761, 0.1014, 0.0924, 0.093...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0199, 0.0298, 0.0202, 0.0319, 0.0268, 0.025...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0335, 0.0338, 0.0304, 0.0333, 0.0333, 0.038...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0278, 0.0268, 0.0265, 0.0287, 0.0179, 0.028...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0244, 0.0274, 0.0222, 0.0295, 0.0155, 0.028...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1213, 0.0238, 0.0465, 0.0468, 0.0288, 0.044...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.022, 0.0159, 0.0276, 0.0268, 0.0246, 0.0137...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.0974, 0.0197, 0.0428, 0.038, 0.0144, 0.0382...               0   \n",
       "1   [0.0927, 0.0186, 0.042, 0.0386, 0.0183, 0.0244...               0   \n",
       "2   [0.0833, 0.0352, 0.0452, 0.0458, 0.0231, 0.063...               0   \n",
       "3   [0.0642, 0.037, 0.0398, 0.0389, 0.0297, 0.0391...               1   \n",
       "4   [0.0279, 0.0345, 0.0395, 0.027, 0.0201, 0.0275...               1   \n",
       "5   [0.0187, 0.0299, 0.0468, 0.025, 0.0245, 0.0263...               2   \n",
       "6   [0.0493, 0.026, 0.0384, 0.0611, 0.035, 0.0344,...               3   \n",
       "7   [0.0461, 0.0305, 0.0499, 0.0954, 0.0284, 0.043...               3   \n",
       "8   [0.1136, 0.0553, 0.104, 0.1664, 0.0645, 0.0927...               3   \n",
       "9   [0.0423, 0.0381, 0.0346, 0.0493, 0.0495, 0.040...               4   \n",
       "10  [0.0379, 0.0449, 0.0436, 0.0314, 0.0447, 0.046...               4   \n",
       "11  [0.0682, 0.0584, 0.0592, 0.0514, 0.0428, 0.096...               5   \n",
       "12  [0.0342, 0.0371, 0.031, 0.0282, 0.0187, 0.0406...               6   \n",
       "13  [0.0416, 0.0184, 0.0325, 0.0227, 0.0139, 0.028...               7   \n",
       "14  [0.027, 0.0285, 0.0209, 0.0234, 0.0194, 0.0239...               8   \n",
       "15  [0.0421, 0.0252, 0.0279, 0.0544, 0.0244, 0.028...               8   \n",
       "16  [0.0503, 0.0169, 0.0547, 0.0535, 0.0166, 0.018...               9   \n",
       "17  [0.0338, 0.0204, 0.0457, 0.0367, 0.015, 0.0281...               9   \n",
       "18  [0.0507, 0.0393, 0.0601, 0.0448, 0.0519, 0.048...              10   \n",
       "19  [0.0512, 0.0401, 0.0548, 0.0399, 0.0562, 0.047...              10   \n",
       "20  [0.0469, 0.0278, 0.0379, 0.0297, 0.0194, 0.032...              11   \n",
       "21  [0.062, 0.0456, 0.0804, 0.0521, 0.0519, 0.0517...              11   \n",
       "22  [0.0204, 0.0234, 0.0233, 0.0269, 0.0156, 0.021...              12   \n",
       "23  [0.0403, 0.0497, 0.0394, 0.0735, 0.0626, 0.059...              13   \n",
       "24  [0.0296, 0.0398, 0.0404, 0.0638, 0.04, 0.0574,...              13   \n",
       "25  [0.0403, 0.0341, 0.0483, 0.0565, 0.0389, 0.037...              14   \n",
       "26  [0.0437, 0.0309, 0.0442, 0.0672, 0.0417, 0.029...              14   \n",
       "27  [0.0255, 0.028, 0.029, 0.0324, 0.0303, 0.0296,...              15   \n",
       "28  [0.0169, 0.045, 0.0372, 0.0587, 0.0329, 0.0335...              15   \n",
       "29  [0.0231, 0.0342, 0.0335, 0.0454, 0.0308, 0.027...              15   \n",
       "30  [0.0976, 0.0395, 0.0417, 0.0389, 0.0441, 0.062...              16   \n",
       "31  [0.0376, 0.0267, 0.0486, 0.0523, 0.0242, 0.034...              17   \n",
       "32  [0.0311, 0.0239, 0.044, 0.0467, 0.0271, 0.0272...              17   \n",
       "33  [0.0378, 0.0226, 0.0337, 0.0304, 0.0331, 0.026...              18   \n",
       "34  [0.0427, 0.0426, 0.0376, 0.0492, 0.0355, 0.046...              19   \n",
       "35  [0.0279, 0.0205, 0.0254, 0.024, 0.0226, 0.0194...              20   \n",
       "36  [0.0478, 0.029, 0.0246, 0.0433, 0.0201, 0.0308...              21   \n",
       "37  [0.0428, 0.024, 0.0202, 0.0342, 0.027, 0.0282,...              21   \n",
       "38  [0.0373, 0.0379, 0.0263, 0.0405, 0.0259, 0.044...              22   \n",
       "39  [0.0359, 0.0212, 0.0302, 0.0322, 0.0166, 0.023...              22   \n",
       "40  [0.0349, 0.0207, 0.0261, 0.0609, 0.015, 0.0196...              22   \n",
       "41  [0.0406, 0.0266, 0.0283, 0.0475, 0.0247, 0.028...              22   \n",
       "42  [0.0659, 0.0343, 0.0329, 0.0518, 0.0329, 0.036...              23   \n",
       "43  [0.0764, 0.0635, 0.0454, 0.0412, 0.0701, 0.064...              23   \n",
       "44  [0.0352, 0.0274, 0.0427, 0.0332, 0.0225, 0.024...              23   \n",
       "45  [0.1129, 0.0649, 0.0761, 0.1014, 0.0924, 0.093...              23   \n",
       "46  [0.0199, 0.0298, 0.0202, 0.0319, 0.0268, 0.025...              24   \n",
       "47  [0.0335, 0.0338, 0.0304, 0.0333, 0.0333, 0.038...              24   \n",
       "48  [0.0278, 0.0268, 0.0265, 0.0287, 0.0179, 0.028...              25   \n",
       "49  [0.0244, 0.0274, 0.0222, 0.0295, 0.0155, 0.028...              25   \n",
       "50  [0.1213, 0.0238, 0.0465, 0.0468, 0.0288, 0.044...              26   \n",
       "51  [0.022, 0.0159, 0.0276, 0.0268, 0.0246, 0.0137...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.461538  0.137218  \n",
       "1                  0       NaN       NaN  \n",
       "2                  8       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  9       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  9       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 8       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 9       NaN       NaN  \n",
       "22                23       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                 9       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                 8       NaN       NaN  \n",
       "30                 8       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                13       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                 8       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                22       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                22       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821 : Training: loss:  0.1327207\n",
      "822 : Training: loss:  0.11727776\n",
      "823 : Training: loss:  0.14128183\n",
      "824 : Training: loss:  0.14580998\n",
      "825 : Training: loss:  0.11756099\n",
      "826 : Training: loss:  0.12425342\n",
      "827 : Training: loss:  0.1362624\n",
      "828 : Training: loss:  0.14419535\n",
      "829 : Training: loss:  0.13828112\n",
      "830 : Training: loss:  0.12563133\n",
      "831 : Training: loss:  0.14784138\n",
      "832 : Training: loss:  0.13736631\n",
      "833 : Training: loss:  0.12969264\n",
      "834 : Training: loss:  0.124718376\n",
      "835 : Training: loss:  0.120568454\n",
      "836 : Training: loss:  0.13969003\n",
      "837 : Training: loss:  0.12688646\n",
      "838 : Training: loss:  0.13124241\n",
      "839 : Training: loss:  0.14088877\n",
      "840 : Training: loss:  0.1394953\n",
      "Validation: Loss:  0.13631631  Accuracy:  0.46153846\n",
      "841 : Training: loss:  0.117793895\n",
      "842 : Training: loss:  0.1413584\n",
      "843 : Training: loss:  0.11395301\n",
      "844 : Training: loss:  0.11874905\n",
      "845 : Training: loss:  0.12293438\n",
      "846 : Training: loss:  0.12598464\n",
      "847 : Training: loss:  0.13089757\n",
      "848 : Training: loss:  0.1493013\n",
      "849 : Training: loss:  0.14987117\n",
      "850 : Training: loss:  0.14451165\n",
      "851 : Training: loss:  0.0997365\n",
      "852 : Training: loss:  0.12691514\n",
      "853 : Training: loss:  0.14706582\n",
      "854 : Training: loss:  0.13968231\n",
      "855 : Training: loss:  0.1386827\n",
      "856 : Training: loss:  0.12273179\n",
      "857 : Training: loss:  0.13392003\n",
      "858 : Training: loss:  0.11633133\n",
      "859 : Training: loss:  0.111918256\n",
      "860 : Training: loss:  0.13646217\n",
      "Validation: Loss:  0.13530456  Accuracy:  0.46153846\n",
      "861 : Training: loss:  0.1192002\n",
      "862 : Training: loss:  0.1437382\n",
      "863 : Training: loss:  0.14192651\n",
      "864 : Training: loss:  0.12938347\n",
      "865 : Training: loss:  0.11918515\n",
      "866 : Training: loss:  0.1384074\n",
      "867 : Training: loss:  0.12910984\n",
      "868 : Training: loss:  0.12161101\n",
      "869 : Training: loss:  0.121424966\n",
      "870 : Training: loss:  0.13481809\n",
      "871 : Training: loss:  0.122464746\n",
      "872 : Training: loss:  0.13796762\n",
      "873 : Training: loss:  0.13456531\n",
      "874 : Training: loss:  0.13214225\n",
      "875 : Training: loss:  0.12928863\n",
      "876 : Training: loss:  0.12870611\n",
      "877 : Training: loss:  0.12177895\n",
      "878 : Training: loss:  0.119630136\n",
      "879 : Training: loss:  0.1350815\n",
      "880 : Training: loss:  0.12100002\n",
      "Validation: Loss:  0.13455056  Accuracy:  0.42307693\n",
      "881 : Training: loss:  0.13633627\n",
      "882 : Training: loss:  0.1347221\n",
      "883 : Training: loss:  0.115470536\n",
      "884 : Training: loss:  0.12980148\n",
      "885 : Training: loss:  0.124191456\n",
      "886 : Training: loss:  0.12942807\n",
      "887 : Training: loss:  0.12321106\n",
      "888 : Training: loss:  0.12257286\n",
      "889 : Training: loss:  0.13365611\n",
      "890 : Training: loss:  0.12876011\n",
      "891 : Training: loss:  0.12631634\n",
      "892 : Training: loss:  0.11960374\n",
      "893 : Training: loss:  0.13791066\n",
      "894 : Training: loss:  0.12294577\n",
      "895 : Training: loss:  0.13049434\n",
      "896 : Training: loss:  0.14282458\n",
      "897 : Training: loss:  0.13169697\n",
      "898 : Training: loss:  0.13566926\n",
      "899 : Training: loss:  0.11531217\n",
      "900 : Training: loss:  0.11816605\n",
      "Validation: Loss:  0.13359722  Accuracy:  0.44230768\n",
      "901 : Training: loss:  0.13016593\n",
      "902 : Training: loss:  0.11169536\n",
      "903 : Training: loss:  0.11681965\n",
      "904 : Training: loss:  0.11381382\n",
      "905 : Training: loss:  0.12684382\n",
      "906 : Training: loss:  0.13740797\n",
      "907 : Training: loss:  0.13964489\n",
      "908 : Training: loss:  0.146176\n",
      "909 : Training: loss:  0.12665512\n",
      "910 : Training: loss:  0.14484774\n",
      "911 : Training: loss:  0.1359807\n",
      "912 : Training: loss:  0.12523693\n",
      "913 : Training: loss:  0.12543838\n",
      "914 : Training: loss:  0.14596401\n",
      "915 : Training: loss:  0.11530077\n",
      "916 : Training: loss:  0.13540432\n",
      "917 : Training: loss:  0.1357233\n",
      "918 : Training: loss:  0.13829568\n",
      "919 : Training: loss:  0.11365155\n",
      "920 : Training: loss:  0.13969104\n",
      "Validation: Loss:  0.13262327  Accuracy:  0.46153846\n",
      "921 : Training: loss:  0.12584196\n",
      "922 : Training: loss:  0.13476859\n",
      "923 : Training: loss:  0.11620298\n",
      "924 : Training: loss:  0.13915595\n",
      "925 : Training: loss:  0.14256069\n",
      "926 : Training: loss:  0.13002676\n",
      "927 : Training: loss:  0.12356054\n",
      "928 : Training: loss:  0.1190855\n",
      "929 : Training: loss:  0.11023465\n",
      "930 : Training: loss:  0.12357887\n",
      "931 : Training: loss:  0.13363606\n",
      "932 : Training: loss:  0.1290669\n",
      "933 : Training: loss:  0.10536833\n",
      "934 : Training: loss:  0.12553382\n",
      "935 : Training: loss:  0.1414489\n",
      "936 : Training: loss:  0.14264308\n",
      "937 : Training: loss:  0.14209963\n",
      "938 : Training: loss:  0.11895105\n",
      "939 : Training: loss:  0.11846176\n",
      "940 : Training: loss:  0.14236654\n",
      "Validation: Loss:  0.13148971  Accuracy:  0.48076922\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.11, 0.0212, 0.0387, 0.0389, 0.0118, 0.0366,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.13149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1007, 0.0199, 0.0367, 0.0385, 0.0146, 0.022...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0928, 0.0409, 0.04, 0.0477, 0.0185, 0.0651,...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0671, 0.0476, 0.0358, 0.0386, 0.0257, 0.039...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0286, 0.0505, 0.04, 0.0272, 0.0177, 0.031, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0175, 0.0379, 0.0519, 0.0251, 0.022, 0.0281...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0459, 0.0287, 0.0342, 0.0687, 0.0288, 0.032...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0429, 0.0338, 0.0465, 0.1153, 0.0239, 0.041...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.1043, 0.0533, 0.0905, 0.1884, 0.0496, 0.080...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0427, 0.0458, 0.0297, 0.049, 0.0421, 0.0444...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0379, 0.0614, 0.0419, 0.031, 0.0396, 0.0516...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0678, 0.0646, 0.0504, 0.0487, 0.0347, 0.101...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0348, 0.0462, 0.0303, 0.0273, 0.0155, 0.042...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0461, 0.0241, 0.0328, 0.0236, 0.0117, 0.030...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0296, 0.0418, 0.02, 0.0243, 0.0188, 0.027, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0451, 0.0296, 0.0243, 0.0599, 0.0218, 0.028...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0496, 0.0204, 0.0544, 0.0581, 0.0136, 0.017...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0341, 0.0256, 0.0466, 0.039, 0.0126, 0.0293...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0502, 0.0434, 0.0582, 0.0405, 0.0451, 0.048...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0497, 0.0443, 0.0515, 0.0355, 0.0469, 0.048...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0491, 0.0338, 0.036, 0.0297, 0.0179, 0.0316...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0606, 0.0524, 0.0737, 0.0533, 0.0455, 0.049...</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0213, 0.0317, 0.0236, 0.0296, 0.0143, 0.022...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0363, 0.054, 0.0357, 0.0756, 0.0522, 0.0591...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0268, 0.0453, 0.0395, 0.0675, 0.0359, 0.06,...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0393, 0.039, 0.0449, 0.0586, 0.0332, 0.0357...</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0396, 0.0314, 0.0395, 0.066, 0.0355, 0.0268...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0243, 0.0364, 0.0276, 0.0324, 0.0273, 0.031...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0155, 0.0653, 0.0396, 0.0669, 0.0326, 0.039...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0222, 0.0452, 0.0317, 0.0484, 0.0282, 0.028...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.11, 0.0439, 0.0373, 0.0385, 0.0369, 0.0613,...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0384, 0.0334, 0.0493, 0.056, 0.0218, 0.0355...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0319, 0.0295, 0.0467, 0.0535, 0.0248, 0.028...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0388, 0.0264, 0.0322, 0.0286, 0.0288, 0.025...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0415, 0.0511, 0.0341, 0.05, 0.0312, 0.0504,...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.028, 0.0252, 0.0249, 0.0239, 0.019, 0.0195,...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0452, 0.0343, 0.022, 0.0427, 0.0162, 0.0301...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0425, 0.028, 0.0182, 0.0355, 0.0222, 0.0261...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0342, 0.0423, 0.0249, 0.0412, 0.021, 0.0443...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.035, 0.0255, 0.0286, 0.0333, 0.0137, 0.0237...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0316, 0.0244, 0.024, 0.0665, 0.0115, 0.02, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.037, 0.0297, 0.0262, 0.0486, 0.02, 0.0266, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0581, 0.0363, 0.0286, 0.0484, 0.0258, 0.031...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0737, 0.0649, 0.0395, 0.0354, 0.0609, 0.055...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0357, 0.0341, 0.0425, 0.0354, 0.0198, 0.022...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.11, 0.0642, 0.0662, 0.1036, 0.0744, 0.0803,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0182, 0.0385, 0.0198, 0.0349, 0.0233, 0.026...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0319, 0.0386, 0.0283, 0.0344, 0.0274, 0.039...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.03, 0.0377, 0.0266, 0.031, 0.0169, 0.0322, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0259, 0.0393, 0.0219, 0.032, 0.0144, 0.034,...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1357, 0.026, 0.0411, 0.0459, 0.0232, 0.04, ...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0228, 0.0206, 0.0274, 0.0281, 0.0228, 0.014...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.11, 0.0212, 0.0387, 0.0389, 0.0118, 0.0366,...               0   \n",
       "1   [0.1007, 0.0199, 0.0367, 0.0385, 0.0146, 0.022...               0   \n",
       "2   [0.0928, 0.0409, 0.04, 0.0477, 0.0185, 0.0651,...               0   \n",
       "3   [0.0671, 0.0476, 0.0358, 0.0386, 0.0257, 0.039...               1   \n",
       "4   [0.0286, 0.0505, 0.04, 0.0272, 0.0177, 0.031, ...               1   \n",
       "5   [0.0175, 0.0379, 0.0519, 0.0251, 0.022, 0.0281...               2   \n",
       "6   [0.0459, 0.0287, 0.0342, 0.0687, 0.0288, 0.032...               3   \n",
       "7   [0.0429, 0.0338, 0.0465, 0.1153, 0.0239, 0.041...               3   \n",
       "8   [0.1043, 0.0533, 0.0905, 0.1884, 0.0496, 0.080...               3   \n",
       "9   [0.0427, 0.0458, 0.0297, 0.049, 0.0421, 0.0444...               4   \n",
       "10  [0.0379, 0.0614, 0.0419, 0.031, 0.0396, 0.0516...               4   \n",
       "11  [0.0678, 0.0646, 0.0504, 0.0487, 0.0347, 0.101...               5   \n",
       "12  [0.0348, 0.0462, 0.0303, 0.0273, 0.0155, 0.042...               6   \n",
       "13  [0.0461, 0.0241, 0.0328, 0.0236, 0.0117, 0.030...               7   \n",
       "14  [0.0296, 0.0418, 0.02, 0.0243, 0.0188, 0.027, ...               8   \n",
       "15  [0.0451, 0.0296, 0.0243, 0.0599, 0.0218, 0.028...               8   \n",
       "16  [0.0496, 0.0204, 0.0544, 0.0581, 0.0136, 0.017...               9   \n",
       "17  [0.0341, 0.0256, 0.0466, 0.039, 0.0126, 0.0293...               9   \n",
       "18  [0.0502, 0.0434, 0.0582, 0.0405, 0.0451, 0.048...              10   \n",
       "19  [0.0497, 0.0443, 0.0515, 0.0355, 0.0469, 0.048...              10   \n",
       "20  [0.0491, 0.0338, 0.036, 0.0297, 0.0179, 0.0316...              11   \n",
       "21  [0.0606, 0.0524, 0.0737, 0.0533, 0.0455, 0.049...              11   \n",
       "22  [0.0213, 0.0317, 0.0236, 0.0296, 0.0143, 0.022...              12   \n",
       "23  [0.0363, 0.054, 0.0357, 0.0756, 0.0522, 0.0591...              13   \n",
       "24  [0.0268, 0.0453, 0.0395, 0.0675, 0.0359, 0.06,...              13   \n",
       "25  [0.0393, 0.039, 0.0449, 0.0586, 0.0332, 0.0357...              14   \n",
       "26  [0.0396, 0.0314, 0.0395, 0.066, 0.0355, 0.0268...              14   \n",
       "27  [0.0243, 0.0364, 0.0276, 0.0324, 0.0273, 0.031...              15   \n",
       "28  [0.0155, 0.0653, 0.0396, 0.0669, 0.0326, 0.039...              15   \n",
       "29  [0.0222, 0.0452, 0.0317, 0.0484, 0.0282, 0.028...              15   \n",
       "30  [0.11, 0.0439, 0.0373, 0.0385, 0.0369, 0.0613,...              16   \n",
       "31  [0.0384, 0.0334, 0.0493, 0.056, 0.0218, 0.0355...              17   \n",
       "32  [0.0319, 0.0295, 0.0467, 0.0535, 0.0248, 0.028...              17   \n",
       "33  [0.0388, 0.0264, 0.0322, 0.0286, 0.0288, 0.025...              18   \n",
       "34  [0.0415, 0.0511, 0.0341, 0.05, 0.0312, 0.0504,...              19   \n",
       "35  [0.028, 0.0252, 0.0249, 0.0239, 0.019, 0.0195,...              20   \n",
       "36  [0.0452, 0.0343, 0.022, 0.0427, 0.0162, 0.0301...              21   \n",
       "37  [0.0425, 0.028, 0.0182, 0.0355, 0.0222, 0.0261...              21   \n",
       "38  [0.0342, 0.0423, 0.0249, 0.0412, 0.021, 0.0443...              22   \n",
       "39  [0.035, 0.0255, 0.0286, 0.0333, 0.0137, 0.0237...              22   \n",
       "40  [0.0316, 0.0244, 0.024, 0.0665, 0.0115, 0.02, ...              22   \n",
       "41  [0.037, 0.0297, 0.0262, 0.0486, 0.02, 0.0266, ...              22   \n",
       "42  [0.0581, 0.0363, 0.0286, 0.0484, 0.0258, 0.031...              23   \n",
       "43  [0.0737, 0.0649, 0.0395, 0.0354, 0.0609, 0.055...              23   \n",
       "44  [0.0357, 0.0341, 0.0425, 0.0354, 0.0198, 0.022...              23   \n",
       "45  [0.11, 0.0642, 0.0662, 0.1036, 0.0744, 0.0803,...              23   \n",
       "46  [0.0182, 0.0385, 0.0198, 0.0349, 0.0233, 0.026...              24   \n",
       "47  [0.0319, 0.0386, 0.0283, 0.0344, 0.0274, 0.039...              24   \n",
       "48  [0.03, 0.0377, 0.0266, 0.031, 0.0169, 0.0322, ...              25   \n",
       "49  [0.0259, 0.0393, 0.0219, 0.032, 0.0144, 0.034,...              25   \n",
       "50  [0.1357, 0.026, 0.0411, 0.0459, 0.0232, 0.04, ...              26   \n",
       "51  [0.0228, 0.0206, 0.0274, 0.0281, 0.0228, 0.014...              26   \n",
       "\n",
       "    Predicted labels  Accuracy     Loss  \n",
       "0                  0  0.480769  0.13149  \n",
       "1                  0       NaN      NaN  \n",
       "2                  8       NaN      NaN  \n",
       "3                 23       NaN      NaN  \n",
       "4                  9       NaN      NaN  \n",
       "5                 10       NaN      NaN  \n",
       "6                  9       NaN      NaN  \n",
       "7                  3       NaN      NaN  \n",
       "8                 22       NaN      NaN  \n",
       "9                  8       NaN      NaN  \n",
       "10                 9       NaN      NaN  \n",
       "11                 5       NaN      NaN  \n",
       "12                 6       NaN      NaN  \n",
       "13                 9       NaN      NaN  \n",
       "14                 8       NaN      NaN  \n",
       "15                 8       NaN      NaN  \n",
       "16                 9       NaN      NaN  \n",
       "17                 9       NaN      NaN  \n",
       "18                10       NaN      NaN  \n",
       "19                10       NaN      NaN  \n",
       "20                 8       NaN      NaN  \n",
       "21                 9       NaN      NaN  \n",
       "22                23       NaN      NaN  \n",
       "23                13       NaN      NaN  \n",
       "24                13       NaN      NaN  \n",
       "25                 9       NaN      NaN  \n",
       "26                14       NaN      NaN  \n",
       "27                15       NaN      NaN  \n",
       "28                15       NaN      NaN  \n",
       "29                15       NaN      NaN  \n",
       "30                 0       NaN      NaN  \n",
       "31                25       NaN      NaN  \n",
       "32                13       NaN      NaN  \n",
       "33                 8       NaN      NaN  \n",
       "34                 8       NaN      NaN  \n",
       "35                22       NaN      NaN  \n",
       "36                22       NaN      NaN  \n",
       "37                22       NaN      NaN  \n",
       "38                22       NaN      NaN  \n",
       "39                22       NaN      NaN  \n",
       "40                22       NaN      NaN  \n",
       "41                22       NaN      NaN  \n",
       "42                22       NaN      NaN  \n",
       "43                 8       NaN      NaN  \n",
       "44                23       NaN      NaN  \n",
       "45                23       NaN      NaN  \n",
       "46                22       NaN      NaN  \n",
       "47                22       NaN      NaN  \n",
       "48                25       NaN      NaN  \n",
       "49                25       NaN      NaN  \n",
       "50                 0       NaN      NaN  \n",
       "51                23       NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941 : Training: loss:  0.13343337\n",
      "942 : Training: loss:  0.14545377\n",
      "943 : Training: loss:  0.12882923\n",
      "944 : Training: loss:  0.133839\n",
      "945 : Training: loss:  0.11393968\n",
      "946 : Training: loss:  0.14558132\n",
      "947 : Training: loss:  0.14457904\n",
      "948 : Training: loss:  0.123029865\n",
      "949 : Training: loss:  0.12708117\n",
      "950 : Training: loss:  0.12041583\n",
      "951 : Training: loss:  0.12176262\n",
      "952 : Training: loss:  0.11965033\n",
      "953 : Training: loss:  0.12803057\n",
      "954 : Training: loss:  0.13114707\n",
      "955 : Training: loss:  0.122430354\n",
      "956 : Training: loss:  0.13775127\n",
      "957 : Training: loss:  0.118860856\n",
      "958 : Training: loss:  0.1211861\n",
      "959 : Training: loss:  0.12260822\n",
      "960 : Training: loss:  0.11202316\n",
      "Validation: Loss:  0.13048398  Accuracy:  0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1131, 0.0209, 0.0367, 0.0397, 0.0116, 0.036...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.130484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1029, 0.0196, 0.0347, 0.0394, 0.0143, 0.021...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0952, 0.0405, 0.0378, 0.0489, 0.0182, 0.065...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.068, 0.0485, 0.0342, 0.0393, 0.0257, 0.0401...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0288, 0.0516, 0.0383, 0.0277, 0.0177, 0.031...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0172, 0.0381, 0.0501, 0.0255, 0.0218, 0.028...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0458, 0.0285, 0.0326, 0.0724, 0.0286, 0.032...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0425, 0.0336, 0.0446, 0.1238, 0.0237, 0.042...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.1031, 0.0518, 0.0858, 0.1993, 0.0481, 0.078...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0427, 0.0461, 0.0281, 0.0496, 0.042, 0.0456...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.038, 0.062, 0.0398, 0.0312, 0.0393, 0.0527,...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0673, 0.0639, 0.0475, 0.0488, 0.0341, 0.102...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0353, 0.0468, 0.029, 0.0276, 0.0155, 0.0432...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0472, 0.0242, 0.0314, 0.0242, 0.0116, 0.031...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0303, 0.043, 0.0191, 0.0249, 0.0192, 0.0278...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.046, 0.0298, 0.0231, 0.0631, 0.0223, 0.0284...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0499, 0.0205, 0.0522, 0.0609, 0.0134, 0.017...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0344, 0.0258, 0.0448, 0.0406, 0.0125, 0.029...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0497, 0.043, 0.0554, 0.0399, 0.0444, 0.0484...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0491, 0.044, 0.049, 0.0349, 0.0459, 0.0482,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0497, 0.0341, 0.0344, 0.03, 0.018, 0.0318, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0601, 0.0524, 0.07, 0.0546, 0.0456, 0.0492,...</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0217, 0.0326, 0.0229, 0.0311, 0.0146, 0.023...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0359, 0.0539, 0.0343, 0.0779, 0.0521, 0.059...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0264, 0.0452, 0.038, 0.0693, 0.0359, 0.0608...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0393, 0.0392, 0.043, 0.0609, 0.0333, 0.0359...</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0392, 0.0313, 0.0379, 0.0678, 0.0356, 0.026...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0243, 0.0375, 0.0267, 0.0332, 0.0279, 0.032...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0153, 0.0682, 0.0389, 0.0704, 0.0337, 0.040...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0223, 0.0467, 0.0306, 0.0506, 0.0291, 0.029...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.113, 0.0435, 0.0354, 0.0389, 0.0365, 0.0619...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0388, 0.0341, 0.048, 0.0584, 0.0221, 0.036,...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0321, 0.0296, 0.0452, 0.0564, 0.025, 0.0287...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0393, 0.0265, 0.0309, 0.0289, 0.0289, 0.026...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0414, 0.0516, 0.0325, 0.0509, 0.0311, 0.051...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0282, 0.0252, 0.0239, 0.0243, 0.0188, 0.019...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0454, 0.0342, 0.021, 0.0437, 0.0159, 0.0306...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0433, 0.028, 0.0175, 0.037, 0.022, 0.0262, ...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0339, 0.0419, 0.0238, 0.0419, 0.0204, 0.044...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.035, 0.0255, 0.0273, 0.0345, 0.0135, 0.024,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0314, 0.0244, 0.0229, 0.0698, 0.0112, 0.020...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0368, 0.0295, 0.0251, 0.0502, 0.0197, 0.026...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0578, 0.0359, 0.0272, 0.0485, 0.025, 0.0313...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0738, 0.0633, 0.0373, 0.0345, 0.0597, 0.054...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0358, 0.0341, 0.0405, 0.0363, 0.0195, 0.022...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1109, 0.0636, 0.0636, 0.1066, 0.0738, 0.079...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0181, 0.039, 0.0191, 0.0361, 0.0232, 0.0273...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0319, 0.0384, 0.027, 0.0354, 0.027, 0.0402,...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0305, 0.039, 0.0257, 0.0319, 0.0172, 0.0334...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0263, 0.0407, 0.0211, 0.0331, 0.0146, 0.035...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1398, 0.0257, 0.039, 0.0468, 0.0229, 0.0397...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.023, 0.0211, 0.0265, 0.0293, 0.0234, 0.0144...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1131, 0.0209, 0.0367, 0.0397, 0.0116, 0.036...               0   \n",
       "1   [0.1029, 0.0196, 0.0347, 0.0394, 0.0143, 0.021...               0   \n",
       "2   [0.0952, 0.0405, 0.0378, 0.0489, 0.0182, 0.065...               0   \n",
       "3   [0.068, 0.0485, 0.0342, 0.0393, 0.0257, 0.0401...               1   \n",
       "4   [0.0288, 0.0516, 0.0383, 0.0277, 0.0177, 0.031...               1   \n",
       "5   [0.0172, 0.0381, 0.0501, 0.0255, 0.0218, 0.028...               2   \n",
       "6   [0.0458, 0.0285, 0.0326, 0.0724, 0.0286, 0.032...               3   \n",
       "7   [0.0425, 0.0336, 0.0446, 0.1238, 0.0237, 0.042...               3   \n",
       "8   [0.1031, 0.0518, 0.0858, 0.1993, 0.0481, 0.078...               3   \n",
       "9   [0.0427, 0.0461, 0.0281, 0.0496, 0.042, 0.0456...               4   \n",
       "10  [0.038, 0.062, 0.0398, 0.0312, 0.0393, 0.0527,...               4   \n",
       "11  [0.0673, 0.0639, 0.0475, 0.0488, 0.0341, 0.102...               5   \n",
       "12  [0.0353, 0.0468, 0.029, 0.0276, 0.0155, 0.0432...               6   \n",
       "13  [0.0472, 0.0242, 0.0314, 0.0242, 0.0116, 0.031...               7   \n",
       "14  [0.0303, 0.043, 0.0191, 0.0249, 0.0192, 0.0278...               8   \n",
       "15  [0.046, 0.0298, 0.0231, 0.0631, 0.0223, 0.0284...               8   \n",
       "16  [0.0499, 0.0205, 0.0522, 0.0609, 0.0134, 0.017...               9   \n",
       "17  [0.0344, 0.0258, 0.0448, 0.0406, 0.0125, 0.029...               9   \n",
       "18  [0.0497, 0.043, 0.0554, 0.0399, 0.0444, 0.0484...              10   \n",
       "19  [0.0491, 0.044, 0.049, 0.0349, 0.0459, 0.0482,...              10   \n",
       "20  [0.0497, 0.0341, 0.0344, 0.03, 0.018, 0.0318, ...              11   \n",
       "21  [0.0601, 0.0524, 0.07, 0.0546, 0.0456, 0.0492,...              11   \n",
       "22  [0.0217, 0.0326, 0.0229, 0.0311, 0.0146, 0.023...              12   \n",
       "23  [0.0359, 0.0539, 0.0343, 0.0779, 0.0521, 0.059...              13   \n",
       "24  [0.0264, 0.0452, 0.038, 0.0693, 0.0359, 0.0608...              13   \n",
       "25  [0.0393, 0.0392, 0.043, 0.0609, 0.0333, 0.0359...              14   \n",
       "26  [0.0392, 0.0313, 0.0379, 0.0678, 0.0356, 0.026...              14   \n",
       "27  [0.0243, 0.0375, 0.0267, 0.0332, 0.0279, 0.032...              15   \n",
       "28  [0.0153, 0.0682, 0.0389, 0.0704, 0.0337, 0.040...              15   \n",
       "29  [0.0223, 0.0467, 0.0306, 0.0506, 0.0291, 0.029...              15   \n",
       "30  [0.113, 0.0435, 0.0354, 0.0389, 0.0365, 0.0619...              16   \n",
       "31  [0.0388, 0.0341, 0.048, 0.0584, 0.0221, 0.036,...              17   \n",
       "32  [0.0321, 0.0296, 0.0452, 0.0564, 0.025, 0.0287...              17   \n",
       "33  [0.0393, 0.0265, 0.0309, 0.0289, 0.0289, 0.026...              18   \n",
       "34  [0.0414, 0.0516, 0.0325, 0.0509, 0.0311, 0.051...              19   \n",
       "35  [0.0282, 0.0252, 0.0239, 0.0243, 0.0188, 0.019...              20   \n",
       "36  [0.0454, 0.0342, 0.021, 0.0437, 0.0159, 0.0306...              21   \n",
       "37  [0.0433, 0.028, 0.0175, 0.037, 0.022, 0.0262, ...              21   \n",
       "38  [0.0339, 0.0419, 0.0238, 0.0419, 0.0204, 0.044...              22   \n",
       "39  [0.035, 0.0255, 0.0273, 0.0345, 0.0135, 0.024,...              22   \n",
       "40  [0.0314, 0.0244, 0.0229, 0.0698, 0.0112, 0.020...              22   \n",
       "41  [0.0368, 0.0295, 0.0251, 0.0502, 0.0197, 0.026...              22   \n",
       "42  [0.0578, 0.0359, 0.0272, 0.0485, 0.025, 0.0313...              23   \n",
       "43  [0.0738, 0.0633, 0.0373, 0.0345, 0.0597, 0.054...              23   \n",
       "44  [0.0358, 0.0341, 0.0405, 0.0363, 0.0195, 0.022...              23   \n",
       "45  [0.1109, 0.0636, 0.0636, 0.1066, 0.0738, 0.079...              23   \n",
       "46  [0.0181, 0.039, 0.0191, 0.0361, 0.0232, 0.0273...              24   \n",
       "47  [0.0319, 0.0384, 0.027, 0.0354, 0.027, 0.0402,...              24   \n",
       "48  [0.0305, 0.039, 0.0257, 0.0319, 0.0172, 0.0334...              25   \n",
       "49  [0.0263, 0.0407, 0.0211, 0.0331, 0.0146, 0.035...              25   \n",
       "50  [0.1398, 0.0257, 0.039, 0.0468, 0.0229, 0.0397...              26   \n",
       "51  [0.023, 0.0211, 0.0265, 0.0293, 0.0234, 0.0144...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0       0.5  0.130484  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  9       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  9       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                 22       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 9       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                23       NaN       NaN  \n",
       "22                23       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                 9       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                13       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                 8       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                22       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                22       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961 : Training: loss:  0.14606282\n",
      "962 : Training: loss:  0.109508336\n",
      "963 : Training: loss:  0.108840436\n",
      "964 : Training: loss:  0.12988201\n",
      "965 : Training: loss:  0.13696839\n",
      "966 : Training: loss:  0.12356612\n",
      "967 : Training: loss:  0.11636146\n",
      "968 : Training: loss:  0.12399333\n",
      "969 : Training: loss:  0.124579854\n",
      "970 : Training: loss:  0.1383637\n",
      "971 : Training: loss:  0.120407\n",
      "972 : Training: loss:  0.13523263\n",
      "973 : Training: loss:  0.11857751\n",
      "974 : Training: loss:  0.10984961\n",
      "975 : Training: loss:  0.1107141\n",
      "976 : Training: loss:  0.11419817\n",
      "977 : Training: loss:  0.11133117\n",
      "978 : Training: loss:  0.13613704\n",
      "979 : Training: loss:  0.10991322\n",
      "980 : Training: loss:  0.12743635\n",
      "Validation: Loss:  0.12948158  Accuracy:  0.5\n",
      "981 : Training: loss:  0.13026758\n",
      "982 : Training: loss:  0.13677132\n",
      "983 : Training: loss:  0.14290452\n",
      "984 : Training: loss:  0.13343598\n",
      "985 : Training: loss:  0.117999114\n",
      "986 : Training: loss:  0.13076328\n",
      "987 : Training: loss:  0.11368067\n",
      "988 : Training: loss:  0.12082017\n",
      "989 : Training: loss:  0.11686288\n",
      "990 : Training: loss:  0.11930346\n",
      "991 : Training: loss:  0.11657466\n",
      "992 : Training: loss:  0.12618926\n",
      "993 : Training: loss:  0.08160324\n",
      "994 : Training: loss:  0.13705418\n",
      "995 : Training: loss:  0.13208991\n",
      "996 : Training: loss:  0.13592717\n",
      "997 : Training: loss:  0.10508436\n",
      "998 : Training: loss:  0.13269599\n",
      "999 : Training: loss:  0.13296215\n",
      "1000 : Training: loss:  0.12796566\n",
      "Validation: Loss:  0.12847842  Accuracy:  0.53846157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1222, 0.0224, 0.0363, 0.0406, 0.0116, 0.037...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.128478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1104, 0.021, 0.0341, 0.04, 0.0144, 0.0217, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1031, 0.045, 0.0373, 0.0504, 0.0182, 0.069,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0708, 0.056, 0.0338, 0.0394, 0.0263, 0.0409...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0299, 0.0616, 0.0392, 0.0281, 0.0186, 0.033...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0173, 0.0428, 0.0536, 0.0261, 0.0229, 0.029...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0457, 0.0301, 0.0318, 0.0772, 0.0286, 0.032...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.042, 0.0359, 0.0441, 0.1352, 0.0237, 0.0408...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.102, 0.0532, 0.083, 0.2125, 0.0465, 0.0752,...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0434, 0.0505, 0.027, 0.0494, 0.043, 0.0471,...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.039, 0.0708, 0.0396, 0.0312, 0.0411, 0.0545...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0682, 0.068, 0.0457, 0.048, 0.0337, 0.1047,...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0368, 0.0531, 0.0297, 0.0278, 0.0158, 0.045...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0507, 0.0272, 0.0319, 0.025, 0.0119, 0.0329...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0319, 0.0506, 0.0189, 0.0252, 0.0207, 0.028...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0482, 0.0325, 0.0223, 0.0654, 0.0232, 0.028...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0515, 0.0225, 0.0533, 0.0643, 0.0136, 0.017...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0357, 0.0289, 0.0461, 0.0422, 0.0128, 0.030...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0507, 0.0457, 0.056, 0.0389, 0.0457, 0.0482...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0499, 0.047, 0.049, 0.0341, 0.0468, 0.0484,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0518, 0.038, 0.0345, 0.0301, 0.0188, 0.0325...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.06, 0.0559, 0.0677, 0.0546, 0.0465, 0.0481,...</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0225, 0.038, 0.0236, 0.0326, 0.0157, 0.0236...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0352, 0.0561, 0.0334, 0.0783, 0.052, 0.0597...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0256, 0.0473, 0.0378, 0.0708, 0.0367, 0.059...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0392, 0.0416, 0.0418, 0.0621, 0.034, 0.0352...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0387, 0.0324, 0.0373, 0.0688, 0.0362, 0.026...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0243, 0.0424, 0.0268, 0.0334, 0.0289, 0.033...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0149, 0.0791, 0.0403, 0.0736, 0.036, 0.0417...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0222, 0.0531, 0.0304, 0.0514, 0.0306, 0.029...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.121, 0.0468, 0.0348, 0.0388, 0.0368, 0.0632...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0398, 0.038, 0.049, 0.061, 0.0232, 0.0366, ...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0331, 0.0325, 0.0464, 0.0598, 0.0266, 0.028...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0407, 0.0287, 0.0308, 0.0288, 0.0299, 0.026...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0416, 0.0572, 0.0318, 0.052, 0.032, 0.0524,...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.029, 0.0279, 0.0244, 0.0247, 0.0191, 0.0203...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0465, 0.0379, 0.0209, 0.0448, 0.0159, 0.030...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0448, 0.0303, 0.0173, 0.0383, 0.0219, 0.026...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0338, 0.0452, 0.0242, 0.0428, 0.02, 0.0458,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0351, 0.0282, 0.0273, 0.0354, 0.0134, 0.023...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0312, 0.0267, 0.023, 0.0736, 0.0109, 0.0204...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0367, 0.032, 0.0253, 0.0518, 0.0196, 0.0268...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0573, 0.0379, 0.0267, 0.0486, 0.0243, 0.030...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0748, 0.0652, 0.0361, 0.0327, 0.0605, 0.053...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0366, 0.0378, 0.0412, 0.0371, 0.02, 0.0221,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1119, 0.0645, 0.0612, 0.1083, 0.0732, 0.076...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0178, 0.0439, 0.0194, 0.0373, 0.0236, 0.027...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0319, 0.0412, 0.0268, 0.0366, 0.0272, 0.040...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0316, 0.0454, 0.0261, 0.0327, 0.018, 0.0348...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0273, 0.0479, 0.0216, 0.0342, 0.0152, 0.037...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1507, 0.0273, 0.0378, 0.0472, 0.0231, 0.038...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0238, 0.0234, 0.0267, 0.0301, 0.0254, 0.014...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1222, 0.0224, 0.0363, 0.0406, 0.0116, 0.037...               0   \n",
       "1   [0.1104, 0.021, 0.0341, 0.04, 0.0144, 0.0217, ...               0   \n",
       "2   [0.1031, 0.045, 0.0373, 0.0504, 0.0182, 0.069,...               0   \n",
       "3   [0.0708, 0.056, 0.0338, 0.0394, 0.0263, 0.0409...               1   \n",
       "4   [0.0299, 0.0616, 0.0392, 0.0281, 0.0186, 0.033...               1   \n",
       "5   [0.0173, 0.0428, 0.0536, 0.0261, 0.0229, 0.029...               2   \n",
       "6   [0.0457, 0.0301, 0.0318, 0.0772, 0.0286, 0.032...               3   \n",
       "7   [0.042, 0.0359, 0.0441, 0.1352, 0.0237, 0.0408...               3   \n",
       "8   [0.102, 0.0532, 0.083, 0.2125, 0.0465, 0.0752,...               3   \n",
       "9   [0.0434, 0.0505, 0.027, 0.0494, 0.043, 0.0471,...               4   \n",
       "10  [0.039, 0.0708, 0.0396, 0.0312, 0.0411, 0.0545...               4   \n",
       "11  [0.0682, 0.068, 0.0457, 0.048, 0.0337, 0.1047,...               5   \n",
       "12  [0.0368, 0.0531, 0.0297, 0.0278, 0.0158, 0.045...               6   \n",
       "13  [0.0507, 0.0272, 0.0319, 0.025, 0.0119, 0.0329...               7   \n",
       "14  [0.0319, 0.0506, 0.0189, 0.0252, 0.0207, 0.028...               8   \n",
       "15  [0.0482, 0.0325, 0.0223, 0.0654, 0.0232, 0.028...               8   \n",
       "16  [0.0515, 0.0225, 0.0533, 0.0643, 0.0136, 0.017...               9   \n",
       "17  [0.0357, 0.0289, 0.0461, 0.0422, 0.0128, 0.030...               9   \n",
       "18  [0.0507, 0.0457, 0.056, 0.0389, 0.0457, 0.0482...              10   \n",
       "19  [0.0499, 0.047, 0.049, 0.0341, 0.0468, 0.0484,...              10   \n",
       "20  [0.0518, 0.038, 0.0345, 0.0301, 0.0188, 0.0325...              11   \n",
       "21  [0.06, 0.0559, 0.0677, 0.0546, 0.0465, 0.0481,...              11   \n",
       "22  [0.0225, 0.038, 0.0236, 0.0326, 0.0157, 0.0236...              12   \n",
       "23  [0.0352, 0.0561, 0.0334, 0.0783, 0.052, 0.0597...              13   \n",
       "24  [0.0256, 0.0473, 0.0378, 0.0708, 0.0367, 0.059...              13   \n",
       "25  [0.0392, 0.0416, 0.0418, 0.0621, 0.034, 0.0352...              14   \n",
       "26  [0.0387, 0.0324, 0.0373, 0.0688, 0.0362, 0.026...              14   \n",
       "27  [0.0243, 0.0424, 0.0268, 0.0334, 0.0289, 0.033...              15   \n",
       "28  [0.0149, 0.0791, 0.0403, 0.0736, 0.036, 0.0417...              15   \n",
       "29  [0.0222, 0.0531, 0.0304, 0.0514, 0.0306, 0.029...              15   \n",
       "30  [0.121, 0.0468, 0.0348, 0.0388, 0.0368, 0.0632...              16   \n",
       "31  [0.0398, 0.038, 0.049, 0.061, 0.0232, 0.0366, ...              17   \n",
       "32  [0.0331, 0.0325, 0.0464, 0.0598, 0.0266, 0.028...              17   \n",
       "33  [0.0407, 0.0287, 0.0308, 0.0288, 0.0299, 0.026...              18   \n",
       "34  [0.0416, 0.0572, 0.0318, 0.052, 0.032, 0.0524,...              19   \n",
       "35  [0.029, 0.0279, 0.0244, 0.0247, 0.0191, 0.0203...              20   \n",
       "36  [0.0465, 0.0379, 0.0209, 0.0448, 0.0159, 0.030...              21   \n",
       "37  [0.0448, 0.0303, 0.0173, 0.0383, 0.0219, 0.026...              21   \n",
       "38  [0.0338, 0.0452, 0.0242, 0.0428, 0.02, 0.0458,...              22   \n",
       "39  [0.0351, 0.0282, 0.0273, 0.0354, 0.0134, 0.023...              22   \n",
       "40  [0.0312, 0.0267, 0.023, 0.0736, 0.0109, 0.0204...              22   \n",
       "41  [0.0367, 0.032, 0.0253, 0.0518, 0.0196, 0.0268...              22   \n",
       "42  [0.0573, 0.0379, 0.0267, 0.0486, 0.0243, 0.030...              23   \n",
       "43  [0.0748, 0.0652, 0.0361, 0.0327, 0.0605, 0.053...              23   \n",
       "44  [0.0366, 0.0378, 0.0412, 0.0371, 0.02, 0.0221,...              23   \n",
       "45  [0.1119, 0.0645, 0.0612, 0.1083, 0.0732, 0.076...              23   \n",
       "46  [0.0178, 0.0439, 0.0194, 0.0373, 0.0236, 0.027...              24   \n",
       "47  [0.0319, 0.0412, 0.0268, 0.0366, 0.0272, 0.040...              24   \n",
       "48  [0.0316, 0.0454, 0.0261, 0.0327, 0.018, 0.0348...              25   \n",
       "49  [0.0273, 0.0479, 0.0216, 0.0342, 0.0152, 0.037...              25   \n",
       "50  [0.1507, 0.0273, 0.0378, 0.0472, 0.0231, 0.038...              26   \n",
       "51  [0.0238, 0.0234, 0.0267, 0.0301, 0.0254, 0.014...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.538462  0.128478  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  9       NaN       NaN  \n",
       "5                 15       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                23       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                23       NaN       NaN  \n",
       "22                23       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                23       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                 3       NaN       NaN  \n",
       "32                13       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                 8       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                22       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 : Training: loss:  0.13069715\n",
      "1002 : Training: loss:  0.10854481\n",
      "1003 : Training: loss:  0.14437626\n",
      "1004 : Training: loss:  0.1198151\n",
      "1005 : Training: loss:  0.12914401\n",
      "1006 : Training: loss:  0.11744356\n",
      "1007 : Training: loss:  0.1401039\n",
      "1008 : Training: loss:  0.11413436\n",
      "1009 : Training: loss:  0.12058472\n",
      "1010 : Training: loss:  0.12889686\n",
      "1011 : Training: loss:  0.11897807\n",
      "1012 : Training: loss:  0.13750535\n",
      "1013 : Training: loss:  0.13795854\n",
      "1014 : Training: loss:  0.1310618\n",
      "1015 : Training: loss:  0.13702804\n",
      "1016 : Training: loss:  0.10607077\n",
      "1017 : Training: loss:  0.119584195\n",
      "1018 : Training: loss:  0.121367104\n",
      "1019 : Training: loss:  0.12563688\n",
      "1020 : Training: loss:  0.11635632\n",
      "Validation: Loss:  0.12744395  Accuracy:  0.5576923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1246, 0.0233, 0.0366, 0.0404, 0.0117, 0.035...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.127444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1119, 0.0218, 0.0344, 0.0397, 0.0147, 0.020...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1052, 0.0477, 0.0376, 0.0506, 0.0186, 0.067...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0715, 0.0608, 0.0343, 0.0389, 0.0271, 0.04,...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.03, 0.0686, 0.0407, 0.0278, 0.0195, 0.0326,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.017, 0.0454, 0.0566, 0.0256, 0.0234, 0.0284...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0448, 0.031, 0.032, 0.0782, 0.0292, 0.0308,...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0409, 0.0366, 0.0444, 0.1371, 0.024, 0.0387...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0993, 0.0533, 0.0826, 0.2159, 0.046, 0.071,...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0439, 0.054, 0.0274, 0.0492, 0.0455, 0.0468...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0392, 0.0772, 0.0406, 0.0309, 0.0434, 0.053...</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0684, 0.0709, 0.0457, 0.0467, 0.0346, 0.102...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0372, 0.0574, 0.0309, 0.0275, 0.0163, 0.044...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0513, 0.0291, 0.0327, 0.0248, 0.0121, 0.032...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0325, 0.0558, 0.0192, 0.0248, 0.022, 0.0281...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0489, 0.0341, 0.0224, 0.0656, 0.0243, 0.027...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0509, 0.0237, 0.0548, 0.0647, 0.0137, 0.016...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0358, 0.0308, 0.048, 0.0425, 0.0131, 0.0292...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0507, 0.0481, 0.0578, 0.0378, 0.0467, 0.046...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0495, 0.0492, 0.0501, 0.033, 0.0475, 0.047,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0519, 0.0404, 0.035, 0.0297, 0.0194, 0.0317...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0595, 0.0582, 0.0681, 0.0541, 0.0478, 0.046...</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0227, 0.0415, 0.0247, 0.033, 0.0166, 0.0231...</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0346, 0.0577, 0.0339, 0.078, 0.0533, 0.0577...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0253, 0.0488, 0.0388, 0.0706, 0.0379, 0.058...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0387, 0.0433, 0.0421, 0.0621, 0.0348, 0.033...</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0378, 0.0331, 0.0374, 0.068, 0.0366, 0.0252...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0242, 0.0454, 0.0276, 0.033, 0.0301, 0.033,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0147, 0.0861, 0.0423, 0.0742, 0.0382, 0.041...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0221, 0.0571, 0.0313, 0.0516, 0.0323, 0.029...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1242, 0.0492, 0.0351, 0.0385, 0.0377, 0.061...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0401, 0.0409, 0.051, 0.0622, 0.0243, 0.036,...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.033, 0.0345, 0.0485, 0.0611, 0.0279, 0.0281...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0404, 0.0301, 0.0312, 0.0283, 0.0306, 0.025...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.041, 0.0606, 0.0317, 0.0511, 0.0327, 0.0509...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0289, 0.0294, 0.0254, 0.0244, 0.0193, 0.019...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0463, 0.0399, 0.0212, 0.0442, 0.0161, 0.030...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.045, 0.0315, 0.0176, 0.0382, 0.0222, 0.025,...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0334, 0.0472, 0.0251, 0.0424, 0.0201, 0.045...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0347, 0.0297, 0.0281, 0.0352, 0.0135, 0.023...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0309, 0.0279, 0.0239, 0.0743, 0.0109, 0.019...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0361, 0.0333, 0.0261, 0.0518, 0.0198, 0.026...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.056, 0.0391, 0.0269, 0.0477, 0.0241, 0.0289...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0746, 0.0665, 0.0359, 0.0314, 0.061, 0.051,...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0366, 0.0404, 0.0429, 0.037, 0.0207, 0.0213...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1112, 0.0654, 0.0609, 0.109, 0.0741, 0.0726...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0176, 0.0473, 0.0203, 0.0375, 0.0245, 0.027...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0314, 0.0428, 0.0272, 0.0362, 0.0277, 0.039...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0322, 0.0503, 0.0272, 0.0327, 0.0193, 0.034...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.028, 0.0533, 0.0226, 0.0345, 0.0163, 0.0377...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.154, 0.0282, 0.0379, 0.0469, 0.0232, 0.037,...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0239, 0.025, 0.0274, 0.03, 0.0269, 0.0138, ...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1246, 0.0233, 0.0366, 0.0404, 0.0117, 0.035...               0   \n",
       "1   [0.1119, 0.0218, 0.0344, 0.0397, 0.0147, 0.020...               0   \n",
       "2   [0.1052, 0.0477, 0.0376, 0.0506, 0.0186, 0.067...               0   \n",
       "3   [0.0715, 0.0608, 0.0343, 0.0389, 0.0271, 0.04,...               1   \n",
       "4   [0.03, 0.0686, 0.0407, 0.0278, 0.0195, 0.0326,...               1   \n",
       "5   [0.017, 0.0454, 0.0566, 0.0256, 0.0234, 0.0284...               2   \n",
       "6   [0.0448, 0.031, 0.032, 0.0782, 0.0292, 0.0308,...               3   \n",
       "7   [0.0409, 0.0366, 0.0444, 0.1371, 0.024, 0.0387...               3   \n",
       "8   [0.0993, 0.0533, 0.0826, 0.2159, 0.046, 0.071,...               3   \n",
       "9   [0.0439, 0.054, 0.0274, 0.0492, 0.0455, 0.0468...               4   \n",
       "10  [0.0392, 0.0772, 0.0406, 0.0309, 0.0434, 0.053...               4   \n",
       "11  [0.0684, 0.0709, 0.0457, 0.0467, 0.0346, 0.102...               5   \n",
       "12  [0.0372, 0.0574, 0.0309, 0.0275, 0.0163, 0.044...               6   \n",
       "13  [0.0513, 0.0291, 0.0327, 0.0248, 0.0121, 0.032...               7   \n",
       "14  [0.0325, 0.0558, 0.0192, 0.0248, 0.022, 0.0281...               8   \n",
       "15  [0.0489, 0.0341, 0.0224, 0.0656, 0.0243, 0.027...               8   \n",
       "16  [0.0509, 0.0237, 0.0548, 0.0647, 0.0137, 0.016...               9   \n",
       "17  [0.0358, 0.0308, 0.048, 0.0425, 0.0131, 0.0292...               9   \n",
       "18  [0.0507, 0.0481, 0.0578, 0.0378, 0.0467, 0.046...              10   \n",
       "19  [0.0495, 0.0492, 0.0501, 0.033, 0.0475, 0.047,...              10   \n",
       "20  [0.0519, 0.0404, 0.035, 0.0297, 0.0194, 0.0317...              11   \n",
       "21  [0.0595, 0.0582, 0.0681, 0.0541, 0.0478, 0.046...              11   \n",
       "22  [0.0227, 0.0415, 0.0247, 0.033, 0.0166, 0.0231...              12   \n",
       "23  [0.0346, 0.0577, 0.0339, 0.078, 0.0533, 0.0577...              13   \n",
       "24  [0.0253, 0.0488, 0.0388, 0.0706, 0.0379, 0.058...              13   \n",
       "25  [0.0387, 0.0433, 0.0421, 0.0621, 0.0348, 0.033...              14   \n",
       "26  [0.0378, 0.0331, 0.0374, 0.068, 0.0366, 0.0252...              14   \n",
       "27  [0.0242, 0.0454, 0.0276, 0.033, 0.0301, 0.033,...              15   \n",
       "28  [0.0147, 0.0861, 0.0423, 0.0742, 0.0382, 0.041...              15   \n",
       "29  [0.0221, 0.0571, 0.0313, 0.0516, 0.0323, 0.029...              15   \n",
       "30  [0.1242, 0.0492, 0.0351, 0.0385, 0.0377, 0.061...              16   \n",
       "31  [0.0401, 0.0409, 0.051, 0.0622, 0.0243, 0.036,...              17   \n",
       "32  [0.033, 0.0345, 0.0485, 0.0611, 0.0279, 0.0281...              17   \n",
       "33  [0.0404, 0.0301, 0.0312, 0.0283, 0.0306, 0.025...              18   \n",
       "34  [0.041, 0.0606, 0.0317, 0.0511, 0.0327, 0.0509...              19   \n",
       "35  [0.0289, 0.0294, 0.0254, 0.0244, 0.0193, 0.019...              20   \n",
       "36  [0.0463, 0.0399, 0.0212, 0.0442, 0.0161, 0.030...              21   \n",
       "37  [0.045, 0.0315, 0.0176, 0.0382, 0.0222, 0.025,...              21   \n",
       "38  [0.0334, 0.0472, 0.0251, 0.0424, 0.0201, 0.045...              22   \n",
       "39  [0.0347, 0.0297, 0.0281, 0.0352, 0.0135, 0.023...              22   \n",
       "40  [0.0309, 0.0279, 0.0239, 0.0743, 0.0109, 0.019...              22   \n",
       "41  [0.0361, 0.0333, 0.0261, 0.0518, 0.0198, 0.026...              22   \n",
       "42  [0.056, 0.0391, 0.0269, 0.0477, 0.0241, 0.0289...              23   \n",
       "43  [0.0746, 0.0665, 0.0359, 0.0314, 0.061, 0.051,...              23   \n",
       "44  [0.0366, 0.0404, 0.0429, 0.037, 0.0207, 0.0213...              23   \n",
       "45  [0.1112, 0.0654, 0.0609, 0.109, 0.0741, 0.0726...              23   \n",
       "46  [0.0176, 0.0473, 0.0203, 0.0375, 0.0245, 0.027...              24   \n",
       "47  [0.0314, 0.0428, 0.0272, 0.0362, 0.0277, 0.039...              24   \n",
       "48  [0.0322, 0.0503, 0.0272, 0.0327, 0.0193, 0.034...              25   \n",
       "49  [0.028, 0.0533, 0.0226, 0.0345, 0.0163, 0.0377...              25   \n",
       "50  [0.154, 0.0282, 0.0379, 0.0469, 0.0232, 0.037,...              26   \n",
       "51  [0.0239, 0.025, 0.0274, 0.03, 0.0269, 0.0138, ...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.557692  0.127444  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 15       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                23       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                23       NaN       NaN  \n",
       "22                23       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                23       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                13       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                 8       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                22       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021 : Training: loss:  0.13877101\n",
      "1022 : Training: loss:  0.13296336\n",
      "1023 : Training: loss:  0.12571014\n",
      "1024 : Training: loss:  0.1343712\n",
      "1025 : Training: loss:  0.12930004\n",
      "1026 : Training: loss:  0.096837334\n",
      "1027 : Training: loss:  0.10634641\n",
      "1028 : Training: loss:  0.12057372\n",
      "1029 : Training: loss:  0.14852771\n",
      "1030 : Training: loss:  0.10111595\n",
      "1031 : Training: loss:  0.116495594\n",
      "1032 : Training: loss:  0.12505314\n",
      "1033 : Training: loss:  0.14522316\n",
      "1034 : Training: loss:  0.1174832\n",
      "1035 : Training: loss:  0.12719062\n",
      "1036 : Training: loss:  0.109425366\n",
      "1037 : Training: loss:  0.13354379\n",
      "1038 : Training: loss:  0.12479926\n",
      "1039 : Training: loss:  0.1395937\n",
      "1040 : Training: loss:  0.13343616\n",
      "Validation: Loss:  0.12652464  Accuracy:  0.53846157\n",
      "1041 : Training: loss:  0.13491008\n",
      "1042 : Training: loss:  0.11391463\n",
      "1043 : Training: loss:  0.12963316\n",
      "1044 : Training: loss:  0.11064157\n",
      "1045 : Training: loss:  0.12049299\n",
      "1046 : Training: loss:  0.110683784\n",
      "1047 : Training: loss:  0.13501367\n",
      "1048 : Training: loss:  0.12550972\n",
      "1049 : Training: loss:  0.11362316\n",
      "1050 : Training: loss:  0.11835619\n",
      "1051 : Training: loss:  0.10034394\n",
      "1052 : Training: loss:  0.11146036\n",
      "1053 : Training: loss:  0.11963701\n",
      "1054 : Training: loss:  0.12119008\n",
      "1055 : Training: loss:  0.12756313\n",
      "1056 : Training: loss:  0.12356036\n",
      "1057 : Training: loss:  0.121311575\n",
      "1058 : Training: loss:  0.10841093\n",
      "1059 : Training: loss:  0.12577198\n",
      "1060 : Training: loss:  0.11200902\n",
      "Validation: Loss:  0.12548167  Accuracy:  0.5576923\n",
      "1061 : Training: loss:  0.13076913\n",
      "1062 : Training: loss:  0.12882714\n",
      "1063 : Training: loss:  0.11266099\n",
      "1064 : Training: loss:  0.12599196\n",
      "1065 : Training: loss:  0.11618085\n",
      "1066 : Training: loss:  0.11684526\n",
      "1067 : Training: loss:  0.09316927\n",
      "1068 : Training: loss:  0.12310069\n",
      "1069 : Training: loss:  0.13498145\n",
      "1070 : Training: loss:  0.13700134\n",
      "1071 : Training: loss:  0.12367491\n",
      "1072 : Training: loss:  0.10035285\n",
      "1073 : Training: loss:  0.12311304\n",
      "1074 : Training: loss:  0.10711311\n",
      "1075 : Training: loss:  0.12266622\n",
      "1076 : Training: loss:  0.11643613\n",
      "1077 : Training: loss:  0.1259772\n",
      "1078 : Training: loss:  0.124808885\n",
      "1079 : Training: loss:  0.10752682\n",
      "1080 : Training: loss:  0.095172755\n",
      "Validation: Loss:  0.12437531  Accuracy:  0.53846157\n",
      "1081 : Training: loss:  0.10968689\n",
      "1082 : Training: loss:  0.12768106\n",
      "1083 : Training: loss:  0.12166544\n",
      "1084 : Training: loss:  0.11974858\n",
      "1085 : Training: loss:  0.13704832\n",
      "1086 : Training: loss:  0.12947217\n",
      "1087 : Training: loss:  0.12259163\n",
      "1088 : Training: loss:  0.12196178\n",
      "1089 : Training: loss:  0.11772248\n",
      "1090 : Training: loss:  0.0929767\n",
      "1091 : Training: loss:  0.11762819\n",
      "1092 : Training: loss:  0.12632753\n",
      "1093 : Training: loss:  0.109671935\n",
      "1094 : Training: loss:  0.11583813\n",
      "1095 : Training: loss:  0.13714418\n",
      "1096 : Training: loss:  0.10030845\n",
      "1097 : Training: loss:  0.1400463\n",
      "1098 : Training: loss:  0.106162935\n",
      "1099 : Training: loss:  0.123705\n",
      "1100 : Training: loss:  0.12681392\n",
      "Validation: Loss:  0.1233295  Accuracy:  0.5576923\n",
      "1101 : Training: loss:  0.11366066\n",
      "1102 : Training: loss:  0.14137767\n",
      "1103 : Training: loss:  0.0971923\n",
      "1104 : Training: loss:  0.11915649\n",
      "1105 : Training: loss:  0.12253185\n",
      "1106 : Training: loss:  0.11306171\n",
      "1107 : Training: loss:  0.106819615\n",
      "1108 : Training: loss:  0.12799187\n",
      "1109 : Training: loss:  0.11170345\n",
      "1110 : Training: loss:  0.13895652\n",
      "1111 : Training: loss:  0.14014871\n",
      "1112 : Training: loss:  0.1398321\n",
      "1113 : Training: loss:  0.101676166\n",
      "1114 : Training: loss:  0.12111911\n",
      "1115 : Training: loss:  0.11694552\n",
      "1116 : Training: loss:  0.099688254\n",
      "1117 : Training: loss:  0.111607686\n",
      "1118 : Training: loss:  0.12410498\n",
      "1119 : Training: loss:  0.13353367\n",
      "1120 : Training: loss:  0.11653929\n",
      "Validation: Loss:  0.12234  Accuracy:  0.5576923\n",
      "1121 : Training: loss:  0.10883327\n",
      "1122 : Training: loss:  0.10940758\n",
      "1123 : Training: loss:  0.10670865\n",
      "1124 : Training: loss:  0.11356309\n",
      "1125 : Training: loss:  0.11859556\n",
      "1126 : Training: loss:  0.12165326\n",
      "1127 : Training: loss:  0.10191761\n",
      "1128 : Training: loss:  0.10965913\n",
      "1129 : Training: loss:  0.13570516\n",
      "1130 : Training: loss:  0.124907956\n",
      "1131 : Training: loss:  0.12393585\n",
      "1132 : Training: loss:  0.1232618\n",
      "1133 : Training: loss:  0.09841963\n",
      "1134 : Training: loss:  0.09853989\n",
      "1135 : Training: loss:  0.1116608\n",
      "1136 : Training: loss:  0.124349035\n",
      "1137 : Training: loss:  0.12214748\n",
      "1138 : Training: loss:  0.10229837\n",
      "1139 : Training: loss:  0.1262615\n",
      "1140 : Training: loss:  0.11358264\n",
      "Validation: Loss:  0.12123423  Accuracy:  0.59615386\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.137, 0.0236, 0.0325, 0.0417, 0.0113, 0.0315...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.121234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1203, 0.0221, 0.0302, 0.0404, 0.0142, 0.017...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1178, 0.0545, 0.0341, 0.053, 0.0181, 0.0664...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0704, 0.0762, 0.03, 0.0356, 0.0278, 0.0374,...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0283, 0.0942, 0.0399, 0.0263, 0.0213, 0.032...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0141, 0.0515, 0.0619, 0.0238, 0.0249, 0.026...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0409, 0.0317, 0.0294, 0.0955, 0.0303, 0.026...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0371, 0.0369, 0.0417, 0.1766, 0.024, 0.0341...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0886, 0.0482, 0.0719, 0.2606, 0.0393, 0.055...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0426, 0.0639, 0.0237, 0.0484, 0.0501, 0.048...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.037, 0.1011, 0.0391, 0.0293, 0.0507, 0.0538...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0616, 0.073, 0.0368, 0.0404, 0.0321, 0.0949...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0355, 0.0699, 0.0304, 0.0244, 0.0159, 0.043...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0531, 0.0334, 0.0315, 0.0249, 0.0125, 0.030...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.032, 0.075, 0.017, 0.023, 0.0256, 0.0275, 0...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0496, 0.0369, 0.0186, 0.0699, 0.0261, 0.023...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0485, 0.0256, 0.0539, 0.0723, 0.0134, 0.014...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0338, 0.0348, 0.0482, 0.0449, 0.0135, 0.027...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0454, 0.0478, 0.0531, 0.0313, 0.0487, 0.040...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0439, 0.049, 0.0446, 0.0273, 0.048, 0.0412,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0513, 0.0478, 0.033, 0.028, 0.021, 0.029, 0...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0524, 0.062, 0.0593, 0.0526, 0.0492, 0.0397...</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0223, 0.0535, 0.0251, 0.0349, 0.0189, 0.022...</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0296, 0.0563, 0.0308, 0.077, 0.0537, 0.052,...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0202, 0.0496, 0.0372, 0.0699, 0.04, 0.0532,...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0362, 0.0457, 0.0389, 0.0665, 0.0376, 0.029...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.033, 0.0322, 0.0338, 0.0688, 0.0372, 0.0212...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0212, 0.0558, 0.0259, 0.031, 0.0335, 0.0319...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0123, 0.1138, 0.0439, 0.077, 0.0456, 0.0428...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0201, 0.0731, 0.0299, 0.0533, 0.0382, 0.028...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1352, 0.0506, 0.0305, 0.0363, 0.0383, 0.055...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0379, 0.0493, 0.0513, 0.0656, 0.0261, 0.034...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0318, 0.0393, 0.0517, 0.0696, 0.0313, 0.026...</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0403, 0.0325, 0.0297, 0.0265, 0.0344, 0.022...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0372, 0.0698, 0.0275, 0.0505, 0.0346, 0.050...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0272, 0.0319, 0.0248, 0.023, 0.0194, 0.0178...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0408, 0.0457, 0.0189, 0.0422, 0.0146, 0.025...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.042, 0.0337, 0.0159, 0.0394, 0.0212, 0.0201...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0281, 0.0486, 0.024, 0.0407, 0.0179, 0.0398...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0302, 0.0327, 0.0257, 0.0352, 0.0125, 0.020...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0265, 0.0302, 0.0222, 0.0825, 0.0096, 0.018...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0305, 0.0354, 0.0245, 0.0527, 0.0184, 0.022...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0467, 0.0382, 0.0233, 0.0439, 0.0217, 0.022...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.067, 0.0637, 0.0308, 0.0252, 0.0612, 0.0394...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.034, 0.0446, 0.042, 0.0371, 0.0216, 0.0174,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.107, 0.0603, 0.0538, 0.1144, 0.073, 0.0586,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0149, 0.0546, 0.0199, 0.0389, 0.0261, 0.025...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0278, 0.0437, 0.0248, 0.0373, 0.0273, 0.036...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0326, 0.0692, 0.0272, 0.0331, 0.0227, 0.037...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0273, 0.0729, 0.0218, 0.0347, 0.0185, 0.040...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1652, 0.0275, 0.0319, 0.0448, 0.0221, 0.029...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0227, 0.0286, 0.026, 0.0309, 0.0327, 0.0126...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.137, 0.0236, 0.0325, 0.0417, 0.0113, 0.0315...               0   \n",
       "1   [0.1203, 0.0221, 0.0302, 0.0404, 0.0142, 0.017...               0   \n",
       "2   [0.1178, 0.0545, 0.0341, 0.053, 0.0181, 0.0664...               0   \n",
       "3   [0.0704, 0.0762, 0.03, 0.0356, 0.0278, 0.0374,...               1   \n",
       "4   [0.0283, 0.0942, 0.0399, 0.0263, 0.0213, 0.032...               1   \n",
       "5   [0.0141, 0.0515, 0.0619, 0.0238, 0.0249, 0.026...               2   \n",
       "6   [0.0409, 0.0317, 0.0294, 0.0955, 0.0303, 0.026...               3   \n",
       "7   [0.0371, 0.0369, 0.0417, 0.1766, 0.024, 0.0341...               3   \n",
       "8   [0.0886, 0.0482, 0.0719, 0.2606, 0.0393, 0.055...               3   \n",
       "9   [0.0426, 0.0639, 0.0237, 0.0484, 0.0501, 0.048...               4   \n",
       "10  [0.037, 0.1011, 0.0391, 0.0293, 0.0507, 0.0538...               4   \n",
       "11  [0.0616, 0.073, 0.0368, 0.0404, 0.0321, 0.0949...               5   \n",
       "12  [0.0355, 0.0699, 0.0304, 0.0244, 0.0159, 0.043...               6   \n",
       "13  [0.0531, 0.0334, 0.0315, 0.0249, 0.0125, 0.030...               7   \n",
       "14  [0.032, 0.075, 0.017, 0.023, 0.0256, 0.0275, 0...               8   \n",
       "15  [0.0496, 0.0369, 0.0186, 0.0699, 0.0261, 0.023...               8   \n",
       "16  [0.0485, 0.0256, 0.0539, 0.0723, 0.0134, 0.014...               9   \n",
       "17  [0.0338, 0.0348, 0.0482, 0.0449, 0.0135, 0.027...               9   \n",
       "18  [0.0454, 0.0478, 0.0531, 0.0313, 0.0487, 0.040...              10   \n",
       "19  [0.0439, 0.049, 0.0446, 0.0273, 0.048, 0.0412,...              10   \n",
       "20  [0.0513, 0.0478, 0.033, 0.028, 0.021, 0.029, 0...              11   \n",
       "21  [0.0524, 0.062, 0.0593, 0.0526, 0.0492, 0.0397...              11   \n",
       "22  [0.0223, 0.0535, 0.0251, 0.0349, 0.0189, 0.022...              12   \n",
       "23  [0.0296, 0.0563, 0.0308, 0.077, 0.0537, 0.052,...              13   \n",
       "24  [0.0202, 0.0496, 0.0372, 0.0699, 0.04, 0.0532,...              13   \n",
       "25  [0.0362, 0.0457, 0.0389, 0.0665, 0.0376, 0.029...              14   \n",
       "26  [0.033, 0.0322, 0.0338, 0.0688, 0.0372, 0.0212...              14   \n",
       "27  [0.0212, 0.0558, 0.0259, 0.031, 0.0335, 0.0319...              15   \n",
       "28  [0.0123, 0.1138, 0.0439, 0.077, 0.0456, 0.0428...              15   \n",
       "29  [0.0201, 0.0731, 0.0299, 0.0533, 0.0382, 0.028...              15   \n",
       "30  [0.1352, 0.0506, 0.0305, 0.0363, 0.0383, 0.055...              16   \n",
       "31  [0.0379, 0.0493, 0.0513, 0.0656, 0.0261, 0.034...              17   \n",
       "32  [0.0318, 0.0393, 0.0517, 0.0696, 0.0313, 0.026...              17   \n",
       "33  [0.0403, 0.0325, 0.0297, 0.0265, 0.0344, 0.022...              18   \n",
       "34  [0.0372, 0.0698, 0.0275, 0.0505, 0.0346, 0.050...              19   \n",
       "35  [0.0272, 0.0319, 0.0248, 0.023, 0.0194, 0.0178...              20   \n",
       "36  [0.0408, 0.0457, 0.0189, 0.0422, 0.0146, 0.025...              21   \n",
       "37  [0.042, 0.0337, 0.0159, 0.0394, 0.0212, 0.0201...              21   \n",
       "38  [0.0281, 0.0486, 0.024, 0.0407, 0.0179, 0.0398...              22   \n",
       "39  [0.0302, 0.0327, 0.0257, 0.0352, 0.0125, 0.020...              22   \n",
       "40  [0.0265, 0.0302, 0.0222, 0.0825, 0.0096, 0.018...              22   \n",
       "41  [0.0305, 0.0354, 0.0245, 0.0527, 0.0184, 0.022...              22   \n",
       "42  [0.0467, 0.0382, 0.0233, 0.0439, 0.0217, 0.022...              23   \n",
       "43  [0.067, 0.0637, 0.0308, 0.0252, 0.0612, 0.0394...              23   \n",
       "44  [0.034, 0.0446, 0.042, 0.0371, 0.0216, 0.0174,...              23   \n",
       "45  [0.107, 0.0603, 0.0538, 0.1144, 0.073, 0.0586,...              23   \n",
       "46  [0.0149, 0.0546, 0.0199, 0.0389, 0.0261, 0.025...              24   \n",
       "47  [0.0278, 0.0437, 0.0248, 0.0373, 0.0273, 0.036...              24   \n",
       "48  [0.0326, 0.0692, 0.0272, 0.0331, 0.0227, 0.037...              25   \n",
       "49  [0.0273, 0.0729, 0.0218, 0.0347, 0.0185, 0.040...              25   \n",
       "50  [0.1652, 0.0275, 0.0319, 0.0448, 0.0221, 0.029...              26   \n",
       "51  [0.0227, 0.0286, 0.026, 0.0309, 0.0327, 0.0126...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.596154  0.121234  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                23       NaN       NaN  \n",
       "22                15       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                 3       NaN       NaN  \n",
       "26                15       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                24       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141 : Training: loss:  0.11224809\n",
      "1142 : Training: loss:  0.10264471\n",
      "1143 : Training: loss:  0.10584768\n",
      "1144 : Training: loss:  0.12174329\n",
      "1145 : Training: loss:  0.13580886\n",
      "1146 : Training: loss:  0.12409658\n",
      "1147 : Training: loss:  0.10042666\n",
      "1148 : Training: loss:  0.14092039\n",
      "1149 : Training: loss:  0.10165028\n",
      "1150 : Training: loss:  0.13239564\n",
      "1151 : Training: loss:  0.09360231\n",
      "1152 : Training: loss:  0.11218988\n",
      "1153 : Training: loss:  0.10162441\n",
      "1154 : Training: loss:  0.124744065\n",
      "1155 : Training: loss:  0.11985679\n",
      "1156 : Training: loss:  0.12293594\n",
      "1157 : Training: loss:  0.12094154\n",
      "1158 : Training: loss:  0.114961386\n",
      "1159 : Training: loss:  0.12192885\n",
      "1160 : Training: loss:  0.1428551\n",
      "Validation: Loss:  0.12028173  Accuracy:  0.61538464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1435, 0.0224, 0.0335, 0.0419, 0.0113, 0.030...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.120282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1271, 0.021, 0.0313, 0.0408, 0.0143, 0.0167...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.125, 0.0512, 0.0348, 0.0535, 0.0179, 0.0645...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0723, 0.074, 0.0308, 0.0352, 0.0282, 0.0363...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0291, 0.0911, 0.0422, 0.0258, 0.0218, 0.031...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0141, 0.0499, 0.0684, 0.0236, 0.0254, 0.025...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.041, 0.0298, 0.0301, 0.098, 0.0303, 0.0255,...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0371, 0.0346, 0.043, 0.1821, 0.0238, 0.0324...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0886, 0.045, 0.073, 0.2668, 0.0383, 0.0525,...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.043, 0.0607, 0.0237, 0.0479, 0.0509, 0.047,...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0373, 0.0964, 0.0403, 0.0287, 0.0514, 0.051...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0619, 0.0693, 0.0372, 0.0396, 0.0319, 0.091...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0361, 0.0673, 0.0321, 0.0238, 0.0159, 0.041...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0554, 0.0319, 0.0336, 0.0249, 0.0126, 0.030...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0326, 0.0727, 0.0175, 0.0226, 0.0263, 0.026...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0507, 0.0349, 0.0187, 0.0702, 0.0264, 0.022...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0496, 0.0243, 0.0572, 0.0736, 0.0133, 0.013...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0345, 0.0333, 0.0516, 0.0452, 0.0136, 0.026...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0457, 0.0449, 0.0552, 0.0302, 0.0487, 0.039...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.044, 0.0462, 0.0463, 0.0264, 0.048, 0.0395,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0523, 0.0461, 0.0342, 0.0276, 0.0213, 0.028...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0522, 0.0597, 0.0614, 0.0525, 0.0501, 0.038...</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0229, 0.0521, 0.0268, 0.0349, 0.0195, 0.021...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0289, 0.0528, 0.0317, 0.0761, 0.0533, 0.049...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0195, 0.0469, 0.0386, 0.0689, 0.0399, 0.051...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0362, 0.0433, 0.0404, 0.0665, 0.0382, 0.028...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0325, 0.0306, 0.0347, 0.0681, 0.0373, 0.020...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0208, 0.0539, 0.0268, 0.0304, 0.0339, 0.031...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0119, 0.1099, 0.0461, 0.0762, 0.0465, 0.041...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0199, 0.0705, 0.031, 0.0529, 0.0391, 0.0274...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1415, 0.0483, 0.0316, 0.0364, 0.0388, 0.054...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0383, 0.0474, 0.0536, 0.0657, 0.0263, 0.033...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0324, 0.0373, 0.0553, 0.0707, 0.0321, 0.025...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.041, 0.0307, 0.0308, 0.026, 0.0347, 0.0215,...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.037, 0.0662, 0.0279, 0.0499, 0.0348, 0.0484...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.028, 0.0305, 0.0265, 0.0229, 0.0195, 0.0173...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.041, 0.0439, 0.0194, 0.0416, 0.0145, 0.0249...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0424, 0.0321, 0.0165, 0.0395, 0.021, 0.0191...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0281, 0.0462, 0.0254, 0.0402, 0.0176, 0.038...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0305, 0.0316, 0.0272, 0.0352, 0.0126, 0.019...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0267, 0.0286, 0.0232, 0.0835, 0.0094, 0.017...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0305, 0.0338, 0.0258, 0.0525, 0.0183, 0.021...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0464, 0.0362, 0.0239, 0.0431, 0.0212, 0.020...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0669, 0.061, 0.0314, 0.0243, 0.0614, 0.0379...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0349, 0.0429, 0.0448, 0.0373, 0.022, 0.0166...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1076, 0.0572, 0.0546, 0.1147, 0.073, 0.056,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0149, 0.052, 0.021, 0.0387, 0.0262, 0.0248,...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0279, 0.0417, 0.0261, 0.0374, 0.0275, 0.035...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0331, 0.0672, 0.0283, 0.0329, 0.0233, 0.036...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0277, 0.0707, 0.0225, 0.0344, 0.0188, 0.039...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1723, 0.026, 0.0325, 0.0447, 0.022, 0.0285,...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0228, 0.0275, 0.0273, 0.0309, 0.034, 0.0121...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1435, 0.0224, 0.0335, 0.0419, 0.0113, 0.030...               0   \n",
       "1   [0.1271, 0.021, 0.0313, 0.0408, 0.0143, 0.0167...               0   \n",
       "2   [0.125, 0.0512, 0.0348, 0.0535, 0.0179, 0.0645...               0   \n",
       "3   [0.0723, 0.074, 0.0308, 0.0352, 0.0282, 0.0363...               1   \n",
       "4   [0.0291, 0.0911, 0.0422, 0.0258, 0.0218, 0.031...               1   \n",
       "5   [0.0141, 0.0499, 0.0684, 0.0236, 0.0254, 0.025...               2   \n",
       "6   [0.041, 0.0298, 0.0301, 0.098, 0.0303, 0.0255,...               3   \n",
       "7   [0.0371, 0.0346, 0.043, 0.1821, 0.0238, 0.0324...               3   \n",
       "8   [0.0886, 0.045, 0.073, 0.2668, 0.0383, 0.0525,...               3   \n",
       "9   [0.043, 0.0607, 0.0237, 0.0479, 0.0509, 0.047,...               4   \n",
       "10  [0.0373, 0.0964, 0.0403, 0.0287, 0.0514, 0.051...               4   \n",
       "11  [0.0619, 0.0693, 0.0372, 0.0396, 0.0319, 0.091...               5   \n",
       "12  [0.0361, 0.0673, 0.0321, 0.0238, 0.0159, 0.041...               6   \n",
       "13  [0.0554, 0.0319, 0.0336, 0.0249, 0.0126, 0.030...               7   \n",
       "14  [0.0326, 0.0727, 0.0175, 0.0226, 0.0263, 0.026...               8   \n",
       "15  [0.0507, 0.0349, 0.0187, 0.0702, 0.0264, 0.022...               8   \n",
       "16  [0.0496, 0.0243, 0.0572, 0.0736, 0.0133, 0.013...               9   \n",
       "17  [0.0345, 0.0333, 0.0516, 0.0452, 0.0136, 0.026...               9   \n",
       "18  [0.0457, 0.0449, 0.0552, 0.0302, 0.0487, 0.039...              10   \n",
       "19  [0.044, 0.0462, 0.0463, 0.0264, 0.048, 0.0395,...              10   \n",
       "20  [0.0523, 0.0461, 0.0342, 0.0276, 0.0213, 0.028...              11   \n",
       "21  [0.0522, 0.0597, 0.0614, 0.0525, 0.0501, 0.038...              11   \n",
       "22  [0.0229, 0.0521, 0.0268, 0.0349, 0.0195, 0.021...              12   \n",
       "23  [0.0289, 0.0528, 0.0317, 0.0761, 0.0533, 0.049...              13   \n",
       "24  [0.0195, 0.0469, 0.0386, 0.0689, 0.0399, 0.051...              13   \n",
       "25  [0.0362, 0.0433, 0.0404, 0.0665, 0.0382, 0.028...              14   \n",
       "26  [0.0325, 0.0306, 0.0347, 0.0681, 0.0373, 0.020...              14   \n",
       "27  [0.0208, 0.0539, 0.0268, 0.0304, 0.0339, 0.031...              15   \n",
       "28  [0.0119, 0.1099, 0.0461, 0.0762, 0.0465, 0.041...              15   \n",
       "29  [0.0199, 0.0705, 0.031, 0.0529, 0.0391, 0.0274...              15   \n",
       "30  [0.1415, 0.0483, 0.0316, 0.0364, 0.0388, 0.054...              16   \n",
       "31  [0.0383, 0.0474, 0.0536, 0.0657, 0.0263, 0.033...              17   \n",
       "32  [0.0324, 0.0373, 0.0553, 0.0707, 0.0321, 0.025...              17   \n",
       "33  [0.041, 0.0307, 0.0308, 0.026, 0.0347, 0.0215,...              18   \n",
       "34  [0.037, 0.0662, 0.0279, 0.0499, 0.0348, 0.0484...              19   \n",
       "35  [0.028, 0.0305, 0.0265, 0.0229, 0.0195, 0.0173...              20   \n",
       "36  [0.041, 0.0439, 0.0194, 0.0416, 0.0145, 0.0249...              21   \n",
       "37  [0.0424, 0.0321, 0.0165, 0.0395, 0.021, 0.0191...              21   \n",
       "38  [0.0281, 0.0462, 0.0254, 0.0402, 0.0176, 0.038...              22   \n",
       "39  [0.0305, 0.0316, 0.0272, 0.0352, 0.0126, 0.019...              22   \n",
       "40  [0.0267, 0.0286, 0.0232, 0.0835, 0.0094, 0.017...              22   \n",
       "41  [0.0305, 0.0338, 0.0258, 0.0525, 0.0183, 0.021...              22   \n",
       "42  [0.0464, 0.0362, 0.0239, 0.0431, 0.0212, 0.020...              23   \n",
       "43  [0.0669, 0.061, 0.0314, 0.0243, 0.0614, 0.0379...              23   \n",
       "44  [0.0349, 0.0429, 0.0448, 0.0373, 0.022, 0.0166...              23   \n",
       "45  [0.1076, 0.0572, 0.0546, 0.1147, 0.073, 0.056,...              23   \n",
       "46  [0.0149, 0.052, 0.021, 0.0387, 0.0262, 0.0248,...              24   \n",
       "47  [0.0279, 0.0417, 0.0261, 0.0374, 0.0275, 0.035...              24   \n",
       "48  [0.0331, 0.0672, 0.0283, 0.0329, 0.0233, 0.036...              25   \n",
       "49  [0.0277, 0.0707, 0.0225, 0.0344, 0.0188, 0.039...              25   \n",
       "50  [0.1723, 0.026, 0.0325, 0.0447, 0.022, 0.0285,...              26   \n",
       "51  [0.0228, 0.0275, 0.0273, 0.0309, 0.034, 0.0121...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.615385  0.120282  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                23       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                 3       NaN       NaN  \n",
       "26                15       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                13       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161 : Training: loss:  0.107243255\n",
      "1162 : Training: loss:  0.10500354\n",
      "1163 : Training: loss:  0.1193423\n",
      "1164 : Training: loss:  0.094564624\n",
      "1165 : Training: loss:  0.13093492\n",
      "1166 : Training: loss:  0.10284639\n",
      "1167 : Training: loss:  0.11480141\n",
      "1168 : Training: loss:  0.10027633\n",
      "1169 : Training: loss:  0.10354382\n",
      "1170 : Training: loss:  0.12237043\n",
      "1171 : Training: loss:  0.103114374\n",
      "1172 : Training: loss:  0.10764629\n",
      "1173 : Training: loss:  0.13240379\n",
      "1174 : Training: loss:  0.100507006\n",
      "1175 : Training: loss:  0.11270816\n",
      "1176 : Training: loss:  0.12797311\n",
      "1177 : Training: loss:  0.10124324\n",
      "1178 : Training: loss:  0.11816997\n",
      "1179 : Training: loss:  0.12125755\n",
      "1180 : Training: loss:  0.12596418\n",
      "Validation: Loss:  0.119325005  Accuracy:  0.59615386\n",
      "1181 : Training: loss:  0.10197162\n",
      "1182 : Training: loss:  0.11323938\n",
      "1183 : Training: loss:  0.10074032\n",
      "1184 : Training: loss:  0.12785529\n",
      "1185 : Training: loss:  0.11221296\n",
      "1186 : Training: loss:  0.11692594\n",
      "1187 : Training: loss:  0.11022195\n",
      "1188 : Training: loss:  0.09263995\n",
      "1189 : Training: loss:  0.10337267\n",
      "1190 : Training: loss:  0.12983443\n",
      "1191 : Training: loss:  0.11428909\n",
      "1192 : Training: loss:  0.114838704\n",
      "1193 : Training: loss:  0.11706442\n",
      "1194 : Training: loss:  0.12773839\n",
      "1195 : Training: loss:  0.09674515\n",
      "1196 : Training: loss:  0.13558051\n",
      "1197 : Training: loss:  0.10030905\n",
      "1198 : Training: loss:  0.12725453\n",
      "1199 : Training: loss:  0.12927729\n",
      "1200 : Training: loss:  0.10865575\n",
      "Validation: Loss:  0.1183167  Accuracy:  0.61538464\n",
      "1201 : Training: loss:  0.124684766\n",
      "1202 : Training: loss:  0.10399031\n",
      "1203 : Training: loss:  0.1262604\n",
      "1204 : Training: loss:  0.13098818\n",
      "1205 : Training: loss:  0.110792704\n",
      "1206 : Training: loss:  0.11211181\n",
      "1207 : Training: loss:  0.093203336\n",
      "1208 : Training: loss:  0.12462742\n",
      "1209 : Training: loss:  0.1345698\n",
      "1210 : Training: loss:  0.087473385\n",
      "1211 : Training: loss:  0.10186208\n",
      "1212 : Training: loss:  0.104817525\n",
      "1213 : Training: loss:  0.088582136\n",
      "1214 : Training: loss:  0.12449182\n",
      "1215 : Training: loss:  0.108157076\n",
      "1216 : Training: loss:  0.118091695\n",
      "1217 : Training: loss:  0.10607638\n",
      "1218 : Training: loss:  0.10148978\n",
      "1219 : Training: loss:  0.12270378\n",
      "1220 : Training: loss:  0.09307784\n",
      "Validation: Loss:  0.11728164  Accuracy:  0.63461536\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1387, 0.0207, 0.0301, 0.0376, 0.0115, 0.030...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.117282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1223, 0.0192, 0.0279, 0.0357, 0.0149, 0.016...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1234, 0.0496, 0.0316, 0.0488, 0.0182, 0.068...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0671, 0.0745, 0.0272, 0.0303, 0.0299, 0.037...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0272, 0.0952, 0.0403, 0.0227, 0.0245, 0.033...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0125, 0.0493, 0.0701, 0.0206, 0.0281, 0.027...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.037, 0.0272, 0.0275, 0.094, 0.0322, 0.025, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0332, 0.0312, 0.0391, 0.1805, 0.0246, 0.031...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0794, 0.0395, 0.0643, 0.2582, 0.0363, 0.048...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0397, 0.06, 0.0213, 0.0438, 0.057, 0.0508, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.035, 0.0977, 0.0381, 0.0255, 0.0588, 0.0557...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0569, 0.0661, 0.0331, 0.0346, 0.0336, 0.097...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0338, 0.0676, 0.031, 0.0208, 0.0168, 0.0445...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0533, 0.0307, 0.0319, 0.0224, 0.0134, 0.032...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0302, 0.075, 0.0158, 0.02, 0.0303, 0.0284, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0459, 0.0326, 0.016, 0.0642, 0.0289, 0.0227...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0465, 0.0228, 0.0545, 0.0675, 0.0139, 0.013...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.032, 0.0311, 0.0489, 0.0411, 0.0144, 0.0266...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0418, 0.0423, 0.0521, 0.0259, 0.0527, 0.039...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0403, 0.0437, 0.0433, 0.0226, 0.0517, 0.040...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0477, 0.0454, 0.0317, 0.0245, 0.023, 0.0285...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0464, 0.0561, 0.0552, 0.0474, 0.0537, 0.037...</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0206, 0.052, 0.0249, 0.0312, 0.0217, 0.022,...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0252, 0.0491, 0.0292, 0.0692, 0.0557, 0.050...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0168, 0.0441, 0.0367, 0.0634, 0.0427, 0.052...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0325, 0.0398, 0.0368, 0.0621, 0.0413, 0.027...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0283, 0.028, 0.0319, 0.0623, 0.0399, 0.0196...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0179, 0.0523, 0.0245, 0.0264, 0.0367, 0.032...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0103, 0.1119, 0.0444, 0.0707, 0.0531, 0.043...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0174, 0.0679, 0.0278, 0.0474, 0.0438, 0.027...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1411, 0.0461, 0.0291, 0.0329, 0.0411, 0.055...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0349, 0.0466, 0.0508, 0.0609, 0.0285, 0.034...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0298, 0.0361, 0.0545, 0.0671, 0.0358, 0.026...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0381, 0.0286, 0.0287, 0.023, 0.0378, 0.0213...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0335, 0.0658, 0.0255, 0.0466, 0.0382, 0.051...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0256, 0.0287, 0.0248, 0.0195, 0.0201, 0.017...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0375, 0.0421, 0.0178, 0.0366, 0.0149, 0.024...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0385, 0.0294, 0.0148, 0.035, 0.0208, 0.0182...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0251, 0.0442, 0.0239, 0.0352, 0.0174, 0.038...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0267, 0.0295, 0.0241, 0.0301, 0.0125, 0.019...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0238, 0.0263, 0.0209, 0.0748, 0.0092, 0.017...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0266, 0.0312, 0.0233, 0.0456, 0.0182, 0.020...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0417, 0.0334, 0.0218, 0.0377, 0.021, 0.0193...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0608, 0.0559, 0.0287, 0.0207, 0.0636, 0.035...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0328, 0.0408, 0.0424, 0.033, 0.0237, 0.0159...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1009, 0.0522, 0.0502, 0.1069, 0.0744, 0.053...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0133, 0.0507, 0.0198, 0.0348, 0.0282, 0.025...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0254, 0.0389, 0.0243, 0.034, 0.029, 0.0364,...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0309, 0.0703, 0.0265, 0.0297, 0.0271, 0.039...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0259, 0.0736, 0.0209, 0.0313, 0.0215, 0.043...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1678, 0.0233, 0.0285, 0.0395, 0.0217, 0.027...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0204, 0.0262, 0.0252, 0.0277, 0.0395, 0.012...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1387, 0.0207, 0.0301, 0.0376, 0.0115, 0.030...               0   \n",
       "1   [0.1223, 0.0192, 0.0279, 0.0357, 0.0149, 0.016...               0   \n",
       "2   [0.1234, 0.0496, 0.0316, 0.0488, 0.0182, 0.068...               0   \n",
       "3   [0.0671, 0.0745, 0.0272, 0.0303, 0.0299, 0.037...               1   \n",
       "4   [0.0272, 0.0952, 0.0403, 0.0227, 0.0245, 0.033...               1   \n",
       "5   [0.0125, 0.0493, 0.0701, 0.0206, 0.0281, 0.027...               2   \n",
       "6   [0.037, 0.0272, 0.0275, 0.094, 0.0322, 0.025, ...               3   \n",
       "7   [0.0332, 0.0312, 0.0391, 0.1805, 0.0246, 0.031...               3   \n",
       "8   [0.0794, 0.0395, 0.0643, 0.2582, 0.0363, 0.048...               3   \n",
       "9   [0.0397, 0.06, 0.0213, 0.0438, 0.057, 0.0508, ...               4   \n",
       "10  [0.035, 0.0977, 0.0381, 0.0255, 0.0588, 0.0557...               4   \n",
       "11  [0.0569, 0.0661, 0.0331, 0.0346, 0.0336, 0.097...               5   \n",
       "12  [0.0338, 0.0676, 0.031, 0.0208, 0.0168, 0.0445...               6   \n",
       "13  [0.0533, 0.0307, 0.0319, 0.0224, 0.0134, 0.032...               7   \n",
       "14  [0.0302, 0.075, 0.0158, 0.02, 0.0303, 0.0284, ...               8   \n",
       "15  [0.0459, 0.0326, 0.016, 0.0642, 0.0289, 0.0227...               8   \n",
       "16  [0.0465, 0.0228, 0.0545, 0.0675, 0.0139, 0.013...               9   \n",
       "17  [0.032, 0.0311, 0.0489, 0.0411, 0.0144, 0.0266...               9   \n",
       "18  [0.0418, 0.0423, 0.0521, 0.0259, 0.0527, 0.039...              10   \n",
       "19  [0.0403, 0.0437, 0.0433, 0.0226, 0.0517, 0.040...              10   \n",
       "20  [0.0477, 0.0454, 0.0317, 0.0245, 0.023, 0.0285...              11   \n",
       "21  [0.0464, 0.0561, 0.0552, 0.0474, 0.0537, 0.037...              11   \n",
       "22  [0.0206, 0.052, 0.0249, 0.0312, 0.0217, 0.022,...              12   \n",
       "23  [0.0252, 0.0491, 0.0292, 0.0692, 0.0557, 0.050...              13   \n",
       "24  [0.0168, 0.0441, 0.0367, 0.0634, 0.0427, 0.052...              13   \n",
       "25  [0.0325, 0.0398, 0.0368, 0.0621, 0.0413, 0.027...              14   \n",
       "26  [0.0283, 0.028, 0.0319, 0.0623, 0.0399, 0.0196...              14   \n",
       "27  [0.0179, 0.0523, 0.0245, 0.0264, 0.0367, 0.032...              15   \n",
       "28  [0.0103, 0.1119, 0.0444, 0.0707, 0.0531, 0.043...              15   \n",
       "29  [0.0174, 0.0679, 0.0278, 0.0474, 0.0438, 0.027...              15   \n",
       "30  [0.1411, 0.0461, 0.0291, 0.0329, 0.0411, 0.055...              16   \n",
       "31  [0.0349, 0.0466, 0.0508, 0.0609, 0.0285, 0.034...              17   \n",
       "32  [0.0298, 0.0361, 0.0545, 0.0671, 0.0358, 0.026...              17   \n",
       "33  [0.0381, 0.0286, 0.0287, 0.023, 0.0378, 0.0213...              18   \n",
       "34  [0.0335, 0.0658, 0.0255, 0.0466, 0.0382, 0.051...              19   \n",
       "35  [0.0256, 0.0287, 0.0248, 0.0195, 0.0201, 0.017...              20   \n",
       "36  [0.0375, 0.0421, 0.0178, 0.0366, 0.0149, 0.024...              21   \n",
       "37  [0.0385, 0.0294, 0.0148, 0.035, 0.0208, 0.0182...              21   \n",
       "38  [0.0251, 0.0442, 0.0239, 0.0352, 0.0174, 0.038...              22   \n",
       "39  [0.0267, 0.0295, 0.0241, 0.0301, 0.0125, 0.019...              22   \n",
       "40  [0.0238, 0.0263, 0.0209, 0.0748, 0.0092, 0.017...              22   \n",
       "41  [0.0266, 0.0312, 0.0233, 0.0456, 0.0182, 0.020...              22   \n",
       "42  [0.0417, 0.0334, 0.0218, 0.0377, 0.021, 0.0193...              23   \n",
       "43  [0.0608, 0.0559, 0.0287, 0.0207, 0.0636, 0.035...              23   \n",
       "44  [0.0328, 0.0408, 0.0424, 0.033, 0.0237, 0.0159...              23   \n",
       "45  [0.1009, 0.0522, 0.0502, 0.1069, 0.0744, 0.053...              23   \n",
       "46  [0.0133, 0.0507, 0.0198, 0.0348, 0.0282, 0.025...              24   \n",
       "47  [0.0254, 0.0389, 0.0243, 0.034, 0.029, 0.0364,...              24   \n",
       "48  [0.0309, 0.0703, 0.0265, 0.0297, 0.0271, 0.039...              25   \n",
       "49  [0.0259, 0.0736, 0.0209, 0.0313, 0.0215, 0.043...              25   \n",
       "50  [0.1678, 0.0233, 0.0285, 0.0395, 0.0217, 0.027...              26   \n",
       "51  [0.0204, 0.0262, 0.0252, 0.0277, 0.0395, 0.012...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.634615  0.117282  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                23       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                 3       NaN       NaN  \n",
       "26                15       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221 : Training: loss:  0.11413587\n",
      "1222 : Training: loss:  0.14259759\n",
      "1223 : Training: loss:  0.106099166\n",
      "1224 : Training: loss:  0.11823011\n",
      "1225 : Training: loss:  0.14223285\n",
      "1226 : Training: loss:  0.13013478\n",
      "1227 : Training: loss:  0.12200292\n",
      "1228 : Training: loss:  0.12127641\n",
      "1229 : Training: loss:  0.11797376\n",
      "1230 : Training: loss:  0.0999343\n",
      "1231 : Training: loss:  0.12643293\n",
      "1232 : Training: loss:  0.13594368\n",
      "1233 : Training: loss:  0.10652035\n",
      "1234 : Training: loss:  0.07010332\n",
      "1235 : Training: loss:  0.13247657\n",
      "1236 : Training: loss:  0.09868678\n",
      "1237 : Training: loss:  0.10500571\n",
      "1238 : Training: loss:  0.09295282\n",
      "1239 : Training: loss:  0.10497449\n",
      "1240 : Training: loss:  0.10809304\n",
      "Validation: Loss:  0.11633225  Accuracy:  0.65384614\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1345, 0.0197, 0.0297, 0.0382, 0.0113, 0.032...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.116332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1182, 0.0182, 0.0273, 0.036, 0.0147, 0.0167...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1209, 0.0479, 0.0312, 0.0504, 0.018, 0.0731...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0643, 0.0724, 0.0266, 0.0303, 0.0299, 0.038...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0261, 0.0935, 0.0404, 0.0227, 0.0246, 0.035...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0117, 0.0476, 0.0729, 0.0207, 0.028, 0.0287...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0353, 0.0258, 0.0274, 0.1011, 0.0321, 0.025...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0318, 0.0296, 0.0394, 0.1933, 0.0246, 0.032...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0757, 0.0369, 0.0636, 0.2728, 0.0355, 0.048...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0388, 0.0592, 0.0211, 0.0451, 0.0586, 0.055...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0338, 0.0964, 0.0382, 0.0259, 0.0598, 0.060...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0547, 0.0642, 0.0326, 0.0346, 0.0335, 0.105...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0322, 0.0656, 0.0313, 0.0208, 0.0166, 0.047...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0513, 0.0297, 0.0321, 0.0228, 0.0132, 0.034...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0292, 0.0741, 0.0156, 0.0203, 0.0311, 0.030...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0443, 0.0311, 0.0157, 0.0668, 0.0292, 0.023...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0445, 0.0216, 0.055, 0.0694, 0.0137, 0.0136...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0304, 0.0299, 0.0497, 0.0417, 0.0142, 0.027...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0404, 0.041, 0.0531, 0.0255, 0.0528, 0.042,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0388, 0.0425, 0.0439, 0.0224, 0.0519, 0.043...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0459, 0.0437, 0.0313, 0.0248, 0.0229, 0.029...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0437, 0.0533, 0.054, 0.0485, 0.0538, 0.0385...</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0197, 0.0504, 0.0253, 0.0323, 0.0221, 0.023...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0241, 0.0475, 0.0298, 0.0726, 0.0562, 0.053...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.016, 0.0427, 0.0376, 0.0659, 0.0431, 0.0554...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.031, 0.038, 0.0367, 0.0646, 0.0418, 0.029, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0269, 0.0266, 0.0317, 0.0639, 0.0398, 0.020...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0169, 0.0508, 0.0244, 0.0265, 0.0366, 0.034...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0097, 0.11, 0.0454, 0.073, 0.0541, 0.0466, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0165, 0.0658, 0.0276, 0.0486, 0.0444, 0.029...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1379, 0.0445, 0.0288, 0.0335, 0.041, 0.0596...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0334, 0.0448, 0.0512, 0.0633, 0.0287, 0.035...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0287, 0.0344, 0.0558, 0.0713, 0.0364, 0.027...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0367, 0.0275, 0.0289, 0.0232, 0.0377, 0.022...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0326, 0.0643, 0.0253, 0.0481, 0.0388, 0.054...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0244, 0.0275, 0.0251, 0.0195, 0.0198, 0.018...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0354, 0.0405, 0.0175, 0.0365, 0.0145, 0.025...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0363, 0.0278, 0.0146, 0.0358, 0.0202, 0.018...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0238, 0.0423, 0.0244, 0.0359, 0.0171, 0.040...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0252, 0.0281, 0.0239, 0.0302, 0.0123, 0.019...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0225, 0.0252, 0.021, 0.0765, 0.009, 0.0177,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0251, 0.0296, 0.0232, 0.0464, 0.0178, 0.021...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0393, 0.0317, 0.0215, 0.0376, 0.0203, 0.019...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0578, 0.0533, 0.028, 0.0203, 0.0623, 0.0363...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.031, 0.0387, 0.0427, 0.0333, 0.0236, 0.0163...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.0971, 0.0498, 0.0499, 0.1115, 0.0736, 0.054...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0126, 0.049, 0.0203, 0.0363, 0.0285, 0.0269...</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0242, 0.0373, 0.0245, 0.0352, 0.029, 0.0386...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0299, 0.0698, 0.0268, 0.0304, 0.0278, 0.042...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.025, 0.073, 0.021, 0.032, 0.0219, 0.0477, 0...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1635, 0.0222, 0.0281, 0.04, 0.0215, 0.0278,...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0196, 0.0255, 0.0256, 0.0285, 0.041, 0.013,...</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1345, 0.0197, 0.0297, 0.0382, 0.0113, 0.032...               0   \n",
       "1   [0.1182, 0.0182, 0.0273, 0.036, 0.0147, 0.0167...               0   \n",
       "2   [0.1209, 0.0479, 0.0312, 0.0504, 0.018, 0.0731...               0   \n",
       "3   [0.0643, 0.0724, 0.0266, 0.0303, 0.0299, 0.038...               1   \n",
       "4   [0.0261, 0.0935, 0.0404, 0.0227, 0.0246, 0.035...               1   \n",
       "5   [0.0117, 0.0476, 0.0729, 0.0207, 0.028, 0.0287...               2   \n",
       "6   [0.0353, 0.0258, 0.0274, 0.1011, 0.0321, 0.025...               3   \n",
       "7   [0.0318, 0.0296, 0.0394, 0.1933, 0.0246, 0.032...               3   \n",
       "8   [0.0757, 0.0369, 0.0636, 0.2728, 0.0355, 0.048...               3   \n",
       "9   [0.0388, 0.0592, 0.0211, 0.0451, 0.0586, 0.055...               4   \n",
       "10  [0.0338, 0.0964, 0.0382, 0.0259, 0.0598, 0.060...               4   \n",
       "11  [0.0547, 0.0642, 0.0326, 0.0346, 0.0335, 0.105...               5   \n",
       "12  [0.0322, 0.0656, 0.0313, 0.0208, 0.0166, 0.047...               6   \n",
       "13  [0.0513, 0.0297, 0.0321, 0.0228, 0.0132, 0.034...               7   \n",
       "14  [0.0292, 0.0741, 0.0156, 0.0203, 0.0311, 0.030...               8   \n",
       "15  [0.0443, 0.0311, 0.0157, 0.0668, 0.0292, 0.023...               8   \n",
       "16  [0.0445, 0.0216, 0.055, 0.0694, 0.0137, 0.0136...               9   \n",
       "17  [0.0304, 0.0299, 0.0497, 0.0417, 0.0142, 0.027...               9   \n",
       "18  [0.0404, 0.041, 0.0531, 0.0255, 0.0528, 0.042,...              10   \n",
       "19  [0.0388, 0.0425, 0.0439, 0.0224, 0.0519, 0.043...              10   \n",
       "20  [0.0459, 0.0437, 0.0313, 0.0248, 0.0229, 0.029...              11   \n",
       "21  [0.0437, 0.0533, 0.054, 0.0485, 0.0538, 0.0385...              11   \n",
       "22  [0.0197, 0.0504, 0.0253, 0.0323, 0.0221, 0.023...              12   \n",
       "23  [0.0241, 0.0475, 0.0298, 0.0726, 0.0562, 0.053...              13   \n",
       "24  [0.016, 0.0427, 0.0376, 0.0659, 0.0431, 0.0554...              13   \n",
       "25  [0.031, 0.038, 0.0367, 0.0646, 0.0418, 0.029, ...              14   \n",
       "26  [0.0269, 0.0266, 0.0317, 0.0639, 0.0398, 0.020...              14   \n",
       "27  [0.0169, 0.0508, 0.0244, 0.0265, 0.0366, 0.034...              15   \n",
       "28  [0.0097, 0.11, 0.0454, 0.073, 0.0541, 0.0466, ...              15   \n",
       "29  [0.0165, 0.0658, 0.0276, 0.0486, 0.0444, 0.029...              15   \n",
       "30  [0.1379, 0.0445, 0.0288, 0.0335, 0.041, 0.0596...              16   \n",
       "31  [0.0334, 0.0448, 0.0512, 0.0633, 0.0287, 0.035...              17   \n",
       "32  [0.0287, 0.0344, 0.0558, 0.0713, 0.0364, 0.027...              17   \n",
       "33  [0.0367, 0.0275, 0.0289, 0.0232, 0.0377, 0.022...              18   \n",
       "34  [0.0326, 0.0643, 0.0253, 0.0481, 0.0388, 0.054...              19   \n",
       "35  [0.0244, 0.0275, 0.0251, 0.0195, 0.0198, 0.018...              20   \n",
       "36  [0.0354, 0.0405, 0.0175, 0.0365, 0.0145, 0.025...              21   \n",
       "37  [0.0363, 0.0278, 0.0146, 0.0358, 0.0202, 0.018...              21   \n",
       "38  [0.0238, 0.0423, 0.0244, 0.0359, 0.0171, 0.040...              22   \n",
       "39  [0.0252, 0.0281, 0.0239, 0.0302, 0.0123, 0.019...              22   \n",
       "40  [0.0225, 0.0252, 0.021, 0.0765, 0.009, 0.0177,...              22   \n",
       "41  [0.0251, 0.0296, 0.0232, 0.0464, 0.0178, 0.021...              22   \n",
       "42  [0.0393, 0.0317, 0.0215, 0.0376, 0.0203, 0.019...              23   \n",
       "43  [0.0578, 0.0533, 0.028, 0.0203, 0.0623, 0.0363...              23   \n",
       "44  [0.031, 0.0387, 0.0427, 0.0333, 0.0236, 0.0163...              23   \n",
       "45  [0.0971, 0.0498, 0.0499, 0.1115, 0.0736, 0.054...              23   \n",
       "46  [0.0126, 0.049, 0.0203, 0.0363, 0.0285, 0.0269...              24   \n",
       "47  [0.0242, 0.0373, 0.0245, 0.0352, 0.029, 0.0386...              24   \n",
       "48  [0.0299, 0.0698, 0.0268, 0.0304, 0.0278, 0.042...              25   \n",
       "49  [0.025, 0.073, 0.021, 0.032, 0.0219, 0.0477, 0...              25   \n",
       "50  [0.1635, 0.0222, 0.0281, 0.04, 0.0215, 0.0278,...              26   \n",
       "51  [0.0196, 0.0255, 0.0256, 0.0285, 0.041, 0.013,...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.653846  0.116332  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                23       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                 3       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                 8       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                23       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                23       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1241 : Training: loss:  0.09905882\n",
      "1242 : Training: loss:  0.111707576\n",
      "1243 : Training: loss:  0.11506215\n",
      "1244 : Training: loss:  0.09170359\n",
      "1245 : Training: loss:  0.11500448\n",
      "1246 : Training: loss:  0.12795693\n",
      "1247 : Training: loss:  0.09970587\n",
      "1248 : Training: loss:  0.10612179\n",
      "1249 : Training: loss:  0.11011205\n",
      "1250 : Training: loss:  0.09546753\n",
      "1251 : Training: loss:  0.1240389\n",
      "1252 : Training: loss:  0.10035127\n",
      "1253 : Training: loss:  0.09841763\n",
      "1254 : Training: loss:  0.08964247\n",
      "1255 : Training: loss:  0.09997402\n",
      "1256 : Training: loss:  0.081683785\n",
      "1257 : Training: loss:  0.10549799\n",
      "1258 : Training: loss:  0.09343849\n",
      "1259 : Training: loss:  0.11352572\n",
      "1260 : Training: loss:  0.116340704\n",
      "Validation: Loss:  0.11524222  Accuracy:  0.65384614\n",
      "1261 : Training: loss:  0.11317421\n",
      "1262 : Training: loss:  0.09780116\n",
      "1263 : Training: loss:  0.11671668\n",
      "1264 : Training: loss:  0.098357104\n",
      "1265 : Training: loss:  0.10366831\n",
      "1266 : Training: loss:  0.10582897\n",
      "1267 : Training: loss:  0.12513714\n",
      "1268 : Training: loss:  0.10253988\n",
      "1269 : Training: loss:  0.10450268\n",
      "1270 : Training: loss:  0.12403087\n",
      "1271 : Training: loss:  0.09981389\n",
      "1272 : Training: loss:  0.105574064\n",
      "1273 : Training: loss:  0.09115788\n",
      "1274 : Training: loss:  0.11488004\n",
      "1275 : Training: loss:  0.10571609\n",
      "1276 : Training: loss:  0.12754793\n",
      "1277 : Training: loss:  0.12526616\n",
      "1278 : Training: loss:  0.11962525\n",
      "1279 : Training: loss:  0.12301542\n",
      "1280 : Training: loss:  0.100640185\n",
      "Validation: Loss:  0.11416603  Accuracy:  0.63461536\n",
      "1281 : Training: loss:  0.12859482\n",
      "1282 : Training: loss:  0.113045745\n",
      "1283 : Training: loss:  0.10272876\n",
      "1284 : Training: loss:  0.08470565\n",
      "1285 : Training: loss:  0.12491287\n",
      "1286 : Training: loss:  0.1112737\n",
      "1287 : Training: loss:  0.09421314\n",
      "1288 : Training: loss:  0.11578675\n",
      "1289 : Training: loss:  0.10343088\n",
      "1290 : Training: loss:  0.103677936\n",
      "1291 : Training: loss:  0.09817356\n",
      "1292 : Training: loss:  0.09480664\n",
      "1293 : Training: loss:  0.09050573\n",
      "1294 : Training: loss:  0.09219677\n",
      "1295 : Training: loss:  0.13059628\n",
      "1296 : Training: loss:  0.10997532\n",
      "1297 : Training: loss:  0.087828025\n",
      "1298 : Training: loss:  0.10337199\n",
      "1299 : Training: loss:  0.10774711\n",
      "1300 : Training: loss:  0.11322035\n",
      "Validation: Loss:  0.11331814  Accuracy:  0.6730769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1502, 0.018, 0.0287, 0.0386, 0.0107, 0.0321...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.113318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.13, 0.0163, 0.0262, 0.0355, 0.0139, 0.0161,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1373, 0.0436, 0.0299, 0.0515, 0.0168, 0.076...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0691, 0.0707, 0.0255, 0.0293, 0.0296, 0.040...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0272, 0.0923, 0.0411, 0.0216, 0.0244, 0.037...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0113, 0.0461, 0.0846, 0.02, 0.0285, 0.0303,...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0344, 0.0226, 0.0265, 0.1124, 0.0307, 0.024...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.031, 0.0261, 0.0391, 0.2141, 0.0234, 0.0307...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0747, 0.0314, 0.0612, 0.3006, 0.0314, 0.043...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.039, 0.0561, 0.0193, 0.0436, 0.0585, 0.0599...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0342, 0.095, 0.0383, 0.0251, 0.0621, 0.0647...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.054, 0.0592, 0.0299, 0.0319, 0.0315, 0.1112...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0323, 0.063, 0.0324, 0.0195, 0.0156, 0.0509...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0565, 0.028, 0.0335, 0.023, 0.0129, 0.0364,...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0306, 0.0728, 0.0146, 0.0193, 0.0326, 0.031...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0461, 0.0276, 0.0139, 0.0673, 0.0291, 0.022...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0459, 0.0198, 0.0576, 0.0719, 0.0128, 0.013...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0312, 0.0283, 0.054, 0.0422, 0.0139, 0.0288...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0405, 0.0381, 0.0547, 0.0233, 0.0529, 0.042...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0389, 0.0397, 0.0447, 0.0205, 0.0515, 0.044...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0471, 0.0406, 0.0305, 0.0236, 0.0223, 0.029...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0423, 0.0492, 0.0525, 0.0479, 0.0537, 0.036...</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.02, 0.0471, 0.0253, 0.0326, 0.0219, 0.023, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0223, 0.0411, 0.0293, 0.0725, 0.0536, 0.053...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0142, 0.0385, 0.0383, 0.066, 0.0425, 0.0559...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0305, 0.0342, 0.0363, 0.0658, 0.0413, 0.028...</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0252, 0.0234, 0.0306, 0.0625, 0.0379, 0.018...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.016, 0.0487, 0.0242, 0.0254, 0.0366, 0.0355...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0089, 0.1056, 0.0464, 0.0728, 0.0545, 0.048...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0157, 0.0629, 0.0269, 0.0472, 0.0453, 0.029...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1523, 0.0419, 0.028, 0.0327, 0.0409, 0.0615...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0333, 0.0417, 0.0521, 0.0662, 0.0278, 0.035...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0289, 0.0312, 0.0589, 0.0764, 0.0363, 0.027...</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0383, 0.0252, 0.0293, 0.0223, 0.0379, 0.022...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0321, 0.0611, 0.0238, 0.0468, 0.0388, 0.056...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0252, 0.0252, 0.0267, 0.0187, 0.019, 0.0186...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0344, 0.038, 0.0169, 0.0352, 0.0132, 0.0262...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0359, 0.0247, 0.0142, 0.0364, 0.0185, 0.017...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0224, 0.0385, 0.0254, 0.0356, 0.0155, 0.041...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0249, 0.026, 0.0241, 0.0302, 0.0113, 0.0196...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0219, 0.0229, 0.0214, 0.0788, 0.0081, 0.017...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.024, 0.0269, 0.0237, 0.0473, 0.0163, 0.0207...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0371, 0.0283, 0.021, 0.036, 0.0183, 0.018, ...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0557, 0.0485, 0.0268, 0.018, 0.0611, 0.0339...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0307, 0.0358, 0.0441, 0.0327, 0.0228, 0.015...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.0971, 0.0436, 0.0477, 0.1181, 0.0699, 0.051...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0116, 0.0452, 0.0207, 0.0365, 0.0274, 0.027...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0232, 0.0338, 0.0243, 0.0353, 0.0276, 0.04,...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0307, 0.0714, 0.0268, 0.0301, 0.0286, 0.047...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0251, 0.0743, 0.0206, 0.0315, 0.0222, 0.053...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.1791, 0.0194, 0.0265, 0.0393, 0.0203, 0.025...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0199, 0.0235, 0.0254, 0.0286, 0.0433, 0.012...</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1502, 0.018, 0.0287, 0.0386, 0.0107, 0.0321...               0   \n",
       "1   [0.13, 0.0163, 0.0262, 0.0355, 0.0139, 0.0161,...               0   \n",
       "2   [0.1373, 0.0436, 0.0299, 0.0515, 0.0168, 0.076...               0   \n",
       "3   [0.0691, 0.0707, 0.0255, 0.0293, 0.0296, 0.040...               1   \n",
       "4   [0.0272, 0.0923, 0.0411, 0.0216, 0.0244, 0.037...               1   \n",
       "5   [0.0113, 0.0461, 0.0846, 0.02, 0.0285, 0.0303,...               2   \n",
       "6   [0.0344, 0.0226, 0.0265, 0.1124, 0.0307, 0.024...               3   \n",
       "7   [0.031, 0.0261, 0.0391, 0.2141, 0.0234, 0.0307...               3   \n",
       "8   [0.0747, 0.0314, 0.0612, 0.3006, 0.0314, 0.043...               3   \n",
       "9   [0.039, 0.0561, 0.0193, 0.0436, 0.0585, 0.0599...               4   \n",
       "10  [0.0342, 0.095, 0.0383, 0.0251, 0.0621, 0.0647...               4   \n",
       "11  [0.054, 0.0592, 0.0299, 0.0319, 0.0315, 0.1112...               5   \n",
       "12  [0.0323, 0.063, 0.0324, 0.0195, 0.0156, 0.0509...               6   \n",
       "13  [0.0565, 0.028, 0.0335, 0.023, 0.0129, 0.0364,...               7   \n",
       "14  [0.0306, 0.0728, 0.0146, 0.0193, 0.0326, 0.031...               8   \n",
       "15  [0.0461, 0.0276, 0.0139, 0.0673, 0.0291, 0.022...               8   \n",
       "16  [0.0459, 0.0198, 0.0576, 0.0719, 0.0128, 0.013...               9   \n",
       "17  [0.0312, 0.0283, 0.054, 0.0422, 0.0139, 0.0288...               9   \n",
       "18  [0.0405, 0.0381, 0.0547, 0.0233, 0.0529, 0.042...              10   \n",
       "19  [0.0389, 0.0397, 0.0447, 0.0205, 0.0515, 0.044...              10   \n",
       "20  [0.0471, 0.0406, 0.0305, 0.0236, 0.0223, 0.029...              11   \n",
       "21  [0.0423, 0.0492, 0.0525, 0.0479, 0.0537, 0.036...              11   \n",
       "22  [0.02, 0.0471, 0.0253, 0.0326, 0.0219, 0.023, ...              12   \n",
       "23  [0.0223, 0.0411, 0.0293, 0.0725, 0.0536, 0.053...              13   \n",
       "24  [0.0142, 0.0385, 0.0383, 0.066, 0.0425, 0.0559...              13   \n",
       "25  [0.0305, 0.0342, 0.0363, 0.0658, 0.0413, 0.028...              14   \n",
       "26  [0.0252, 0.0234, 0.0306, 0.0625, 0.0379, 0.018...              14   \n",
       "27  [0.016, 0.0487, 0.0242, 0.0254, 0.0366, 0.0355...              15   \n",
       "28  [0.0089, 0.1056, 0.0464, 0.0728, 0.0545, 0.048...              15   \n",
       "29  [0.0157, 0.0629, 0.0269, 0.0472, 0.0453, 0.029...              15   \n",
       "30  [0.1523, 0.0419, 0.028, 0.0327, 0.0409, 0.0615...              16   \n",
       "31  [0.0333, 0.0417, 0.0521, 0.0662, 0.0278, 0.035...              17   \n",
       "32  [0.0289, 0.0312, 0.0589, 0.0764, 0.0363, 0.027...              17   \n",
       "33  [0.0383, 0.0252, 0.0293, 0.0223, 0.0379, 0.022...              18   \n",
       "34  [0.0321, 0.0611, 0.0238, 0.0468, 0.0388, 0.056...              19   \n",
       "35  [0.0252, 0.0252, 0.0267, 0.0187, 0.019, 0.0186...              20   \n",
       "36  [0.0344, 0.038, 0.0169, 0.0352, 0.0132, 0.0262...              21   \n",
       "37  [0.0359, 0.0247, 0.0142, 0.0364, 0.0185, 0.017...              21   \n",
       "38  [0.0224, 0.0385, 0.0254, 0.0356, 0.0155, 0.041...              22   \n",
       "39  [0.0249, 0.026, 0.0241, 0.0302, 0.0113, 0.0196...              22   \n",
       "40  [0.0219, 0.0229, 0.0214, 0.0788, 0.0081, 0.017...              22   \n",
       "41  [0.024, 0.0269, 0.0237, 0.0473, 0.0163, 0.0207...              22   \n",
       "42  [0.0371, 0.0283, 0.021, 0.036, 0.0183, 0.018, ...              23   \n",
       "43  [0.0557, 0.0485, 0.0268, 0.018, 0.0611, 0.0339...              23   \n",
       "44  [0.0307, 0.0358, 0.0441, 0.0327, 0.0228, 0.015...              23   \n",
       "45  [0.0971, 0.0436, 0.0477, 0.1181, 0.0699, 0.051...              23   \n",
       "46  [0.0116, 0.0452, 0.0207, 0.0365, 0.0274, 0.027...              24   \n",
       "47  [0.0232, 0.0338, 0.0243, 0.0353, 0.0276, 0.04,...              24   \n",
       "48  [0.0307, 0.0714, 0.0268, 0.0301, 0.0286, 0.047...              25   \n",
       "49  [0.0251, 0.0743, 0.0206, 0.0315, 0.0222, 0.053...              25   \n",
       "50  [0.1791, 0.0194, 0.0265, 0.0393, 0.0203, 0.025...              26   \n",
       "51  [0.0199, 0.0235, 0.0254, 0.0286, 0.0433, 0.012...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.673077  0.113318  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                23       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                 3       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                25       NaN       NaN  \n",
       "32                24       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                 8       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1301 : Training: loss:  0.100524224\n",
      "1302 : Training: loss:  0.12929395\n",
      "1303 : Training: loss:  0.13228762\n",
      "1304 : Training: loss:  0.10754286\n",
      "1305 : Training: loss:  0.074100606\n",
      "1306 : Training: loss:  0.12369629\n",
      "1307 : Training: loss:  0.109052986\n",
      "1308 : Training: loss:  0.100123316\n",
      "1309 : Training: loss:  0.09799127\n",
      "1310 : Training: loss:  0.11567852\n",
      "1311 : Training: loss:  0.09842016\n",
      "1312 : Training: loss:  0.1082403\n",
      "1313 : Training: loss:  0.09925569\n",
      "1314 : Training: loss:  0.10138771\n",
      "1315 : Training: loss:  0.12034582\n",
      "1316 : Training: loss:  0.10719082\n",
      "1317 : Training: loss:  0.10309731\n",
      "1318 : Training: loss:  0.12201136\n",
      "1319 : Training: loss:  0.10139346\n",
      "1320 : Training: loss:  0.11368598\n",
      "Validation: Loss:  0.112445176  Accuracy:  0.6730769\n",
      "1321 : Training: loss:  0.092752784\n",
      "1322 : Training: loss:  0.11549744\n",
      "1323 : Training: loss:  0.09321667\n",
      "1324 : Training: loss:  0.13308677\n",
      "1325 : Training: loss:  0.10697116\n",
      "1326 : Training: loss:  0.09947593\n",
      "1327 : Training: loss:  0.09414035\n",
      "1328 : Training: loss:  0.09317278\n",
      "1329 : Training: loss:  0.08728145\n",
      "1330 : Training: loss:  0.11164521\n",
      "1331 : Training: loss:  0.08826571\n",
      "1332 : Training: loss:  0.10088628\n",
      "1333 : Training: loss:  0.10066299\n",
      "1334 : Training: loss:  0.102693014\n",
      "1335 : Training: loss:  0.11685339\n",
      "1336 : Training: loss:  0.12411715\n",
      "1337 : Training: loss:  0.11356045\n",
      "1338 : Training: loss:  0.11816059\n",
      "1339 : Training: loss:  0.12218485\n",
      "1340 : Training: loss:  0.12177985\n",
      "Validation: Loss:  0.11152376  Accuracy:  0.61538464\n",
      "1341 : Training: loss:  0.091623366\n",
      "1342 : Training: loss:  0.09294401\n",
      "1343 : Training: loss:  0.090967625\n",
      "1344 : Training: loss:  0.10347277\n",
      "1345 : Training: loss:  0.08504218\n",
      "1346 : Training: loss:  0.1173939\n",
      "1347 : Training: loss:  0.08466859\n",
      "1348 : Training: loss:  0.11782297\n",
      "1349 : Training: loss:  0.08953658\n",
      "1350 : Training: loss:  0.11941453\n",
      "1351 : Training: loss:  0.10341727\n",
      "1352 : Training: loss:  0.086301625\n",
      "1353 : Training: loss:  0.07296487\n",
      "1354 : Training: loss:  0.11730793\n",
      "1355 : Training: loss:  0.11298788\n",
      "1356 : Training: loss:  0.09969738\n",
      "1357 : Training: loss:  0.11055989\n",
      "1358 : Training: loss:  0.10164566\n",
      "1359 : Training: loss:  0.14045306\n",
      "1360 : Training: loss:  0.10980588\n",
      "Validation: Loss:  0.110422686  Accuracy:  0.6730769\n",
      "1361 : Training: loss:  0.10131178\n",
      "1362 : Training: loss:  0.12589759\n",
      "1363 : Training: loss:  0.08210474\n",
      "1364 : Training: loss:  0.10006701\n",
      "1365 : Training: loss:  0.11512256\n",
      "1366 : Training: loss:  0.10016936\n",
      "1367 : Training: loss:  0.08735925\n",
      "1368 : Training: loss:  0.08354206\n",
      "1369 : Training: loss:  0.08235076\n",
      "1370 : Training: loss:  0.107709445\n",
      "1371 : Training: loss:  0.08835856\n",
      "1372 : Training: loss:  0.09267077\n",
      "1373 : Training: loss:  0.10553985\n",
      "1374 : Training: loss:  0.112704545\n",
      "1375 : Training: loss:  0.089723736\n",
      "1376 : Training: loss:  0.09710836\n",
      "1377 : Training: loss:  0.12525383\n",
      "1378 : Training: loss:  0.12024621\n",
      "1379 : Training: loss:  0.11993759\n",
      "1380 : Training: loss:  0.07720224\n",
      "Validation: Loss:  0.109168716  Accuracy:  0.6730769\n",
      "1381 : Training: loss:  0.08005194\n",
      "1382 : Training: loss:  0.10428049\n",
      "1383 : Training: loss:  0.09878093\n",
      "1384 : Training: loss:  0.11250132\n",
      "1385 : Training: loss:  0.106923595\n",
      "1386 : Training: loss:  0.10125194\n",
      "1387 : Training: loss:  0.12725879\n",
      "1388 : Training: loss:  0.10169635\n",
      "1389 : Training: loss:  0.096850865\n",
      "1390 : Training: loss:  0.08877912\n",
      "1391 : Training: loss:  0.07787163\n",
      "1392 : Training: loss:  0.10515764\n",
      "1393 : Training: loss:  0.099615164\n",
      "1394 : Training: loss:  0.09835134\n",
      "1395 : Training: loss:  0.09673626\n",
      "1396 : Training: loss:  0.10717553\n",
      "1397 : Training: loss:  0.096116364\n",
      "1398 : Training: loss:  0.09176601\n",
      "1399 : Training: loss:  0.120591395\n",
      "1400 : Training: loss:  0.091686554\n",
      "Validation: Loss:  0.10814473  Accuracy:  0.71153843\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1798, 0.0176, 0.026, 0.0364, 0.0103, 0.0302...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.108145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1511, 0.0157, 0.0232, 0.032, 0.0132, 0.0141...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1679, 0.043, 0.027, 0.0489, 0.0159, 0.0782,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0762, 0.0838, 0.0229, 0.0255, 0.0304, 0.040...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0279, 0.1054, 0.0396, 0.0182, 0.0247, 0.038...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0104, 0.0474, 0.0971, 0.0172, 0.0292, 0.030...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0329, 0.0214, 0.024, 0.1204, 0.0305, 0.023,...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0286, 0.0236, 0.0366, 0.2319, 0.0222, 0.028...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0712, 0.0279, 0.0563, 0.3202, 0.0268, 0.038...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0418, 0.063, 0.017, 0.0403, 0.0648, 0.0665,...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0343, 0.1051, 0.0355, 0.0213, 0.0661, 0.065...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0542, 0.062, 0.025, 0.0261, 0.0311, 0.1149,...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0328, 0.0676, 0.0327, 0.016, 0.0146, 0.0498...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0641, 0.0283, 0.0332, 0.0211, 0.0126, 0.037...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0323, 0.0828, 0.0125, 0.0161, 0.0363, 0.031...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.049, 0.0273, 0.0112, 0.0618, 0.0306, 0.0211...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0456, 0.0193, 0.0572, 0.0693, 0.0116, 0.011...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0308, 0.0286, 0.055, 0.0389, 0.0132, 0.0273...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0402, 0.0385, 0.0538, 0.0188, 0.0542, 0.04,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0383, 0.0409, 0.0427, 0.0164, 0.0511, 0.042...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0486, 0.0402, 0.0276, 0.0204, 0.0229, 0.026...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.041, 0.0488, 0.047, 0.0438, 0.0541, 0.033, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0209, 0.054, 0.0253, 0.0306, 0.0239, 0.0232...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0197, 0.0377, 0.0279, 0.0656, 0.0526, 0.051...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0123, 0.0369, 0.0389, 0.0606, 0.0435, 0.055...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0296, 0.0334, 0.0342, 0.0642, 0.0418, 0.025...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.023, 0.0216, 0.028, 0.0583, 0.0377, 0.0166,...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0147, 0.055, 0.0227, 0.0221, 0.0399, 0.0362...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0077, 0.1221, 0.0485, 0.0686, 0.0625, 0.052...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0145, 0.0685, 0.0245, 0.0424, 0.0502, 0.028...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1792, 0.0434, 0.0254, 0.0292, 0.0408, 0.058...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0347, 0.0464, 0.0537, 0.0661, 0.0292, 0.036...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0309, 0.0318, 0.0656, 0.0801, 0.0388, 0.027...</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0388, 0.0247, 0.0276, 0.0192, 0.0389, 0.019...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0318, 0.0625, 0.0211, 0.0434, 0.0403, 0.057...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0258, 0.0251, 0.027, 0.0162, 0.018, 0.018, ...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0328, 0.0399, 0.0151, 0.0302, 0.0118, 0.024...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0344, 0.0243, 0.0125, 0.0326, 0.0164, 0.014...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0206, 0.0379, 0.0255, 0.032, 0.0137, 0.0412...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0246, 0.0278, 0.0232, 0.0281, 0.0104, 0.019...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0206, 0.0224, 0.0203, 0.0768, 0.0068, 0.017...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0224, 0.0272, 0.0232, 0.0451, 0.015, 0.0197...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0318, 0.0259, 0.0184, 0.0305, 0.0156, 0.014...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0508, 0.0434, 0.0225, 0.0137, 0.0571, 0.026...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0296, 0.0366, 0.0423, 0.0286, 0.0217, 0.012...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.0997, 0.0429, 0.0447, 0.1176, 0.0677, 0.044...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0104, 0.0457, 0.0205, 0.0338, 0.0272, 0.027...</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0227, 0.0332, 0.0234, 0.034, 0.0269, 0.0412...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.033, 0.0912, 0.0255, 0.0272, 0.033, 0.0519,...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0262, 0.0936, 0.019, 0.0286, 0.0249, 0.0605...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.2036, 0.0182, 0.0232, 0.0345, 0.0182, 0.022...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0204, 0.0253, 0.0243, 0.0264, 0.0492, 0.012...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.1798, 0.0176, 0.026, 0.0364, 0.0103, 0.0302...               0   \n",
       "1   [0.1511, 0.0157, 0.0232, 0.032, 0.0132, 0.0141...               0   \n",
       "2   [0.1679, 0.043, 0.027, 0.0489, 0.0159, 0.0782,...               0   \n",
       "3   [0.0762, 0.0838, 0.0229, 0.0255, 0.0304, 0.040...               1   \n",
       "4   [0.0279, 0.1054, 0.0396, 0.0182, 0.0247, 0.038...               1   \n",
       "5   [0.0104, 0.0474, 0.0971, 0.0172, 0.0292, 0.030...               2   \n",
       "6   [0.0329, 0.0214, 0.024, 0.1204, 0.0305, 0.023,...               3   \n",
       "7   [0.0286, 0.0236, 0.0366, 0.2319, 0.0222, 0.028...               3   \n",
       "8   [0.0712, 0.0279, 0.0563, 0.3202, 0.0268, 0.038...               3   \n",
       "9   [0.0418, 0.063, 0.017, 0.0403, 0.0648, 0.0665,...               4   \n",
       "10  [0.0343, 0.1051, 0.0355, 0.0213, 0.0661, 0.065...               4   \n",
       "11  [0.0542, 0.062, 0.025, 0.0261, 0.0311, 0.1149,...               5   \n",
       "12  [0.0328, 0.0676, 0.0327, 0.016, 0.0146, 0.0498...               6   \n",
       "13  [0.0641, 0.0283, 0.0332, 0.0211, 0.0126, 0.037...               7   \n",
       "14  [0.0323, 0.0828, 0.0125, 0.0161, 0.0363, 0.031...               8   \n",
       "15  [0.049, 0.0273, 0.0112, 0.0618, 0.0306, 0.0211...               8   \n",
       "16  [0.0456, 0.0193, 0.0572, 0.0693, 0.0116, 0.011...               9   \n",
       "17  [0.0308, 0.0286, 0.055, 0.0389, 0.0132, 0.0273...               9   \n",
       "18  [0.0402, 0.0385, 0.0538, 0.0188, 0.0542, 0.04,...              10   \n",
       "19  [0.0383, 0.0409, 0.0427, 0.0164, 0.0511, 0.042...              10   \n",
       "20  [0.0486, 0.0402, 0.0276, 0.0204, 0.0229, 0.026...              11   \n",
       "21  [0.041, 0.0488, 0.047, 0.0438, 0.0541, 0.033, ...              11   \n",
       "22  [0.0209, 0.054, 0.0253, 0.0306, 0.0239, 0.0232...              12   \n",
       "23  [0.0197, 0.0377, 0.0279, 0.0656, 0.0526, 0.051...              13   \n",
       "24  [0.0123, 0.0369, 0.0389, 0.0606, 0.0435, 0.055...              13   \n",
       "25  [0.0296, 0.0334, 0.0342, 0.0642, 0.0418, 0.025...              14   \n",
       "26  [0.023, 0.0216, 0.028, 0.0583, 0.0377, 0.0166,...              14   \n",
       "27  [0.0147, 0.055, 0.0227, 0.0221, 0.0399, 0.0362...              15   \n",
       "28  [0.0077, 0.1221, 0.0485, 0.0686, 0.0625, 0.052...              15   \n",
       "29  [0.0145, 0.0685, 0.0245, 0.0424, 0.0502, 0.028...              15   \n",
       "30  [0.1792, 0.0434, 0.0254, 0.0292, 0.0408, 0.058...              16   \n",
       "31  [0.0347, 0.0464, 0.0537, 0.0661, 0.0292, 0.036...              17   \n",
       "32  [0.0309, 0.0318, 0.0656, 0.0801, 0.0388, 0.027...              17   \n",
       "33  [0.0388, 0.0247, 0.0276, 0.0192, 0.0389, 0.019...              18   \n",
       "34  [0.0318, 0.0625, 0.0211, 0.0434, 0.0403, 0.057...              19   \n",
       "35  [0.0258, 0.0251, 0.027, 0.0162, 0.018, 0.018, ...              20   \n",
       "36  [0.0328, 0.0399, 0.0151, 0.0302, 0.0118, 0.024...              21   \n",
       "37  [0.0344, 0.0243, 0.0125, 0.0326, 0.0164, 0.014...              21   \n",
       "38  [0.0206, 0.0379, 0.0255, 0.032, 0.0137, 0.0412...              22   \n",
       "39  [0.0246, 0.0278, 0.0232, 0.0281, 0.0104, 0.019...              22   \n",
       "40  [0.0206, 0.0224, 0.0203, 0.0768, 0.0068, 0.017...              22   \n",
       "41  [0.0224, 0.0272, 0.0232, 0.0451, 0.015, 0.0197...              22   \n",
       "42  [0.0318, 0.0259, 0.0184, 0.0305, 0.0156, 0.014...              23   \n",
       "43  [0.0508, 0.0434, 0.0225, 0.0137, 0.0571, 0.026...              23   \n",
       "44  [0.0296, 0.0366, 0.0423, 0.0286, 0.0217, 0.012...              23   \n",
       "45  [0.0997, 0.0429, 0.0447, 0.1176, 0.0677, 0.044...              23   \n",
       "46  [0.0104, 0.0457, 0.0205, 0.0338, 0.0272, 0.027...              24   \n",
       "47  [0.0227, 0.0332, 0.0234, 0.034, 0.0269, 0.0412...              24   \n",
       "48  [0.033, 0.0912, 0.0255, 0.0272, 0.033, 0.0519,...              25   \n",
       "49  [0.0262, 0.0936, 0.019, 0.0286, 0.0249, 0.0605...              25   \n",
       "50  [0.2036, 0.0182, 0.0232, 0.0345, 0.0182, 0.022...              26   \n",
       "51  [0.0204, 0.0253, 0.0243, 0.0264, 0.0492, 0.012...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.711538  0.108145  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 8       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                13       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                10       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401 : Training: loss:  0.09054032\n",
      "1402 : Training: loss:  0.103560075\n",
      "1403 : Training: loss:  0.08507243\n",
      "1404 : Training: loss:  0.10965238\n",
      "1405 : Training: loss:  0.11109342\n",
      "1406 : Training: loss:  0.104753435\n",
      "1407 : Training: loss:  0.09847389\n",
      "1408 : Training: loss:  0.12367923\n",
      "1409 : Training: loss:  0.0959566\n",
      "1410 : Training: loss:  0.111451164\n",
      "1411 : Training: loss:  0.10759167\n",
      "1412 : Training: loss:  0.10258195\n",
      "1413 : Training: loss:  0.119578786\n",
      "1414 : Training: loss:  0.10959787\n",
      "1415 : Training: loss:  0.08468403\n",
      "1416 : Training: loss:  0.10421075\n",
      "1417 : Training: loss:  0.112541094\n",
      "1418 : Training: loss:  0.0943499\n",
      "1419 : Training: loss:  0.103344455\n",
      "1420 : Training: loss:  0.07559785\n",
      "Validation: Loss:  0.10720732  Accuracy:  0.71153843\n",
      "1421 : Training: loss:  0.11125924\n",
      "1422 : Training: loss:  0.10768746\n",
      "1423 : Training: loss:  0.11096826\n",
      "1424 : Training: loss:  0.102494866\n",
      "1425 : Training: loss:  0.11353454\n",
      "1426 : Training: loss:  0.116429046\n",
      "1427 : Training: loss:  0.079173714\n",
      "1428 : Training: loss:  0.078814216\n",
      "1429 : Training: loss:  0.097530656\n",
      "1430 : Training: loss:  0.118904285\n",
      "1431 : Training: loss:  0.10087385\n",
      "1432 : Training: loss:  0.09118275\n",
      "1433 : Training: loss:  0.12207393\n",
      "1434 : Training: loss:  0.09984375\n",
      "1435 : Training: loss:  0.10346025\n",
      "1436 : Training: loss:  0.09323145\n",
      "1437 : Training: loss:  0.07471046\n",
      "1438 : Training: loss:  0.10356962\n",
      "1439 : Training: loss:  0.075389184\n",
      "1440 : Training: loss:  0.114621066\n",
      "Validation: Loss:  0.10627121  Accuracy:  0.7307692\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.191, 0.0163, 0.0236, 0.0357, 0.0099, 0.0282...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.106271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1623, 0.0146, 0.021, 0.0311, 0.0126, 0.013,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1771, 0.0412, 0.0244, 0.0477, 0.0151, 0.076...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0807, 0.0828, 0.0204, 0.024, 0.0296, 0.0389...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0287, 0.1069, 0.0362, 0.0173, 0.0242, 0.038...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.01, 0.0455, 0.0943, 0.0161, 0.0289, 0.0298,...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0322, 0.0202, 0.0221, 0.1273, 0.0301, 0.021...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0269, 0.0225, 0.0339, 0.2474, 0.0219, 0.027...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.068, 0.0258, 0.0503, 0.3318, 0.0248, 0.0352...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0425, 0.0598, 0.0149, 0.0387, 0.064, 0.0656...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0356, 0.1058, 0.0327, 0.0206, 0.0664, 0.066...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0526, 0.0569, 0.0211, 0.0238, 0.0288, 0.110...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0331, 0.0653, 0.0306, 0.0145, 0.014, 0.0496...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0667, 0.0278, 0.031, 0.0207, 0.0124, 0.0364...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0337, 0.0842, 0.0114, 0.0155, 0.0376, 0.031...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0496, 0.0256, 0.0098, 0.0618, 0.0308, 0.019...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0461, 0.0184, 0.0533, 0.0708, 0.011, 0.0107...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0303, 0.0273, 0.0504, 0.0382, 0.0125, 0.026...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0401, 0.0352, 0.049, 0.0172, 0.0525, 0.0377...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0386, 0.038, 0.0388, 0.015, 0.0491, 0.0406,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0492, 0.0387, 0.0257, 0.0193, 0.0229, 0.025...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0415, 0.0453, 0.0422, 0.0428, 0.0537, 0.031...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0208, 0.0545, 0.0238, 0.0298, 0.0243, 0.023...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0186, 0.0354, 0.0255, 0.0636, 0.0514, 0.050...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0114, 0.0346, 0.0365, 0.0592, 0.0433, 0.055...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0296, 0.0315, 0.0316, 0.065, 0.0419, 0.0245...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0224, 0.0199, 0.026, 0.0571, 0.0375, 0.0156...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0142, 0.0537, 0.0207, 0.0209, 0.0397, 0.035...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0071, 0.1227, 0.0459, 0.0676, 0.0642, 0.054...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0141, 0.0667, 0.0221, 0.041, 0.0509, 0.028,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.1945, 0.0406, 0.0231, 0.0284, 0.0399, 0.055...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0347, 0.0449, 0.0504, 0.0656, 0.0288, 0.036...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0311, 0.0303, 0.0633, 0.0811, 0.0394, 0.027...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0397, 0.0237, 0.0262, 0.0185, 0.0391, 0.018...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0317, 0.0598, 0.019, 0.0431, 0.0404, 0.056,...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0261, 0.0244, 0.0255, 0.0152, 0.0175, 0.017...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0328, 0.0392, 0.0138, 0.0286, 0.0112, 0.023...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0345, 0.0238, 0.0116, 0.0321, 0.0158, 0.013...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0196, 0.0356, 0.0234, 0.0297, 0.0127, 0.039...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0244, 0.0268, 0.0209, 0.0271, 0.0098, 0.018...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0199, 0.0213, 0.0183, 0.076, 0.0063, 0.0167...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0214, 0.0258, 0.021, 0.0429, 0.014, 0.0182,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0308, 0.0246, 0.0168, 0.0293, 0.0145, 0.012...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0512, 0.0408, 0.0209, 0.0126, 0.0563, 0.024...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.03, 0.0346, 0.0387, 0.0274, 0.0209, 0.0119,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1027, 0.0404, 0.0416, 0.1206, 0.0662, 0.042...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0098, 0.0439, 0.019, 0.0329, 0.0266, 0.0269...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0222, 0.0315, 0.0217, 0.0333, 0.0263, 0.040...</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0336, 0.0899, 0.0231, 0.0259, 0.0333, 0.052...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0256, 0.0916, 0.0169, 0.0273, 0.0246, 0.060...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.2162, 0.0173, 0.0211, 0.034, 0.0174, 0.0205...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0211, 0.0247, 0.0228, 0.0268, 0.0515, 0.012...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.191, 0.0163, 0.0236, 0.0357, 0.0099, 0.0282...               0   \n",
       "1   [0.1623, 0.0146, 0.021, 0.0311, 0.0126, 0.013,...               0   \n",
       "2   [0.1771, 0.0412, 0.0244, 0.0477, 0.0151, 0.076...               0   \n",
       "3   [0.0807, 0.0828, 0.0204, 0.024, 0.0296, 0.0389...               1   \n",
       "4   [0.0287, 0.1069, 0.0362, 0.0173, 0.0242, 0.038...               1   \n",
       "5   [0.01, 0.0455, 0.0943, 0.0161, 0.0289, 0.0298,...               2   \n",
       "6   [0.0322, 0.0202, 0.0221, 0.1273, 0.0301, 0.021...               3   \n",
       "7   [0.0269, 0.0225, 0.0339, 0.2474, 0.0219, 0.027...               3   \n",
       "8   [0.068, 0.0258, 0.0503, 0.3318, 0.0248, 0.0352...               3   \n",
       "9   [0.0425, 0.0598, 0.0149, 0.0387, 0.064, 0.0656...               4   \n",
       "10  [0.0356, 0.1058, 0.0327, 0.0206, 0.0664, 0.066...               4   \n",
       "11  [0.0526, 0.0569, 0.0211, 0.0238, 0.0288, 0.110...               5   \n",
       "12  [0.0331, 0.0653, 0.0306, 0.0145, 0.014, 0.0496...               6   \n",
       "13  [0.0667, 0.0278, 0.031, 0.0207, 0.0124, 0.0364...               7   \n",
       "14  [0.0337, 0.0842, 0.0114, 0.0155, 0.0376, 0.031...               8   \n",
       "15  [0.0496, 0.0256, 0.0098, 0.0618, 0.0308, 0.019...               8   \n",
       "16  [0.0461, 0.0184, 0.0533, 0.0708, 0.011, 0.0107...               9   \n",
       "17  [0.0303, 0.0273, 0.0504, 0.0382, 0.0125, 0.026...               9   \n",
       "18  [0.0401, 0.0352, 0.049, 0.0172, 0.0525, 0.0377...              10   \n",
       "19  [0.0386, 0.038, 0.0388, 0.015, 0.0491, 0.0406,...              10   \n",
       "20  [0.0492, 0.0387, 0.0257, 0.0193, 0.0229, 0.025...              11   \n",
       "21  [0.0415, 0.0453, 0.0422, 0.0428, 0.0537, 0.031...              11   \n",
       "22  [0.0208, 0.0545, 0.0238, 0.0298, 0.0243, 0.023...              12   \n",
       "23  [0.0186, 0.0354, 0.0255, 0.0636, 0.0514, 0.050...              13   \n",
       "24  [0.0114, 0.0346, 0.0365, 0.0592, 0.0433, 0.055...              13   \n",
       "25  [0.0296, 0.0315, 0.0316, 0.065, 0.0419, 0.0245...              14   \n",
       "26  [0.0224, 0.0199, 0.026, 0.0571, 0.0375, 0.0156...              14   \n",
       "27  [0.0142, 0.0537, 0.0207, 0.0209, 0.0397, 0.035...              15   \n",
       "28  [0.0071, 0.1227, 0.0459, 0.0676, 0.0642, 0.054...              15   \n",
       "29  [0.0141, 0.0667, 0.0221, 0.041, 0.0509, 0.028,...              15   \n",
       "30  [0.1945, 0.0406, 0.0231, 0.0284, 0.0399, 0.055...              16   \n",
       "31  [0.0347, 0.0449, 0.0504, 0.0656, 0.0288, 0.036...              17   \n",
       "32  [0.0311, 0.0303, 0.0633, 0.0811, 0.0394, 0.027...              17   \n",
       "33  [0.0397, 0.0237, 0.0262, 0.0185, 0.0391, 0.018...              18   \n",
       "34  [0.0317, 0.0598, 0.019, 0.0431, 0.0404, 0.056,...              19   \n",
       "35  [0.0261, 0.0244, 0.0255, 0.0152, 0.0175, 0.017...              20   \n",
       "36  [0.0328, 0.0392, 0.0138, 0.0286, 0.0112, 0.023...              21   \n",
       "37  [0.0345, 0.0238, 0.0116, 0.0321, 0.0158, 0.013...              21   \n",
       "38  [0.0196, 0.0356, 0.0234, 0.0297, 0.0127, 0.039...              22   \n",
       "39  [0.0244, 0.0268, 0.0209, 0.0271, 0.0098, 0.018...              22   \n",
       "40  [0.0199, 0.0213, 0.0183, 0.076, 0.0063, 0.0167...              22   \n",
       "41  [0.0214, 0.0258, 0.021, 0.0429, 0.014, 0.0182,...              22   \n",
       "42  [0.0308, 0.0246, 0.0168, 0.0293, 0.0145, 0.012...              23   \n",
       "43  [0.0512, 0.0408, 0.0209, 0.0126, 0.0563, 0.024...              23   \n",
       "44  [0.03, 0.0346, 0.0387, 0.0274, 0.0209, 0.0119,...              23   \n",
       "45  [0.1027, 0.0404, 0.0416, 0.1206, 0.0662, 0.042...              23   \n",
       "46  [0.0098, 0.0439, 0.019, 0.0329, 0.0266, 0.0269...              24   \n",
       "47  [0.0222, 0.0315, 0.0217, 0.0333, 0.0263, 0.040...              24   \n",
       "48  [0.0336, 0.0899, 0.0231, 0.0259, 0.0333, 0.052...              25   \n",
       "49  [0.0256, 0.0916, 0.0169, 0.0273, 0.0246, 0.060...              25   \n",
       "50  [0.2162, 0.0173, 0.0211, 0.034, 0.0174, 0.0205...              26   \n",
       "51  [0.0211, 0.0247, 0.0228, 0.0268, 0.0515, 0.012...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.730769  0.106271  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 8       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                22       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1441 : Training: loss:  0.086473696\n",
      "1442 : Training: loss:  0.10343857\n",
      "1443 : Training: loss:  0.10902764\n",
      "1444 : Training: loss:  0.10540914\n",
      "1445 : Training: loss:  0.10761307\n",
      "1446 : Training: loss:  0.09810355\n",
      "1447 : Training: loss:  0.0720376\n",
      "1448 : Training: loss:  0.10400012\n",
      "1449 : Training: loss:  0.10937537\n",
      "1450 : Training: loss:  0.11116382\n",
      "1451 : Training: loss:  0.08267187\n",
      "1452 : Training: loss:  0.10167461\n",
      "1453 : Training: loss:  0.10312948\n",
      "1454 : Training: loss:  0.094481744\n",
      "1455 : Training: loss:  0.091638856\n",
      "1456 : Training: loss:  0.115474336\n",
      "1457 : Training: loss:  0.0866072\n",
      "1458 : Training: loss:  0.094552666\n",
      "1459 : Training: loss:  0.09922557\n",
      "1460 : Training: loss:  0.1105907\n",
      "Validation: Loss:  0.10529525  Accuracy:  0.7307692\n",
      "1461 : Training: loss:  0.09277756\n",
      "1462 : Training: loss:  0.08290679\n",
      "1463 : Training: loss:  0.0941438\n",
      "1464 : Training: loss:  0.11211322\n",
      "1465 : Training: loss:  0.0861278\n",
      "1466 : Training: loss:  0.101004735\n",
      "1467 : Training: loss:  0.1065673\n",
      "1468 : Training: loss:  0.09707238\n",
      "1469 : Training: loss:  0.08025384\n",
      "1470 : Training: loss:  0.1198587\n",
      "1471 : Training: loss:  0.11117941\n",
      "1472 : Training: loss:  0.1082041\n",
      "1473 : Training: loss:  0.109340325\n",
      "1474 : Training: loss:  0.10627365\n",
      "1475 : Training: loss:  0.085705854\n",
      "1476 : Training: loss:  0.09399971\n",
      "1477 : Training: loss:  0.08944424\n",
      "1478 : Training: loss:  0.11014683\n",
      "1479 : Training: loss:  0.10190598\n",
      "1480 : Training: loss:  0.09213845\n",
      "Validation: Loss:  0.10417162  Accuracy:  0.7307692\n",
      "1481 : Training: loss:  0.10661691\n",
      "1482 : Training: loss:  0.11755868\n",
      "1483 : Training: loss:  0.09914377\n",
      "1484 : Training: loss:  0.08381636\n",
      "1485 : Training: loss:  0.092083834\n",
      "1486 : Training: loss:  0.1045915\n",
      "1487 : Training: loss:  0.09871398\n",
      "1488 : Training: loss:  0.075058654\n",
      "1489 : Training: loss:  0.0851416\n",
      "1490 : Training: loss:  0.08614813\n",
      "1491 : Training: loss:  0.077398606\n",
      "1492 : Training: loss:  0.09415892\n",
      "1493 : Training: loss:  0.09576043\n",
      "1494 : Training: loss:  0.1101395\n",
      "1495 : Training: loss:  0.103214316\n",
      "1496 : Training: loss:  0.10738004\n",
      "1497 : Training: loss:  0.07897979\n",
      "1498 : Training: loss:  0.091561586\n",
      "1499 : Training: loss:  0.10306794\n",
      "1500 : Training: loss:  0.10141362\n",
      "Validation: Loss:  0.10311703  Accuracy:  0.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.2086, 0.0145, 0.0208, 0.0333, 0.0095, 0.026...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.103117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1784, 0.0133, 0.019, 0.0297, 0.0126, 0.0121...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1979, 0.0395, 0.0221, 0.0462, 0.0144, 0.078...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0845, 0.0834, 0.0181, 0.0219, 0.0309, 0.038...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0298, 0.1136, 0.0355, 0.0163, 0.0274, 0.040...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0095, 0.0444, 0.1019, 0.0151, 0.0316, 0.029...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0324, 0.0192, 0.021, 0.1442, 0.0328, 0.0214...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0259, 0.0213, 0.0326, 0.2754, 0.0228, 0.025...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.067, 0.0242, 0.047, 0.3534, 0.0237, 0.0321,...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.042, 0.0562, 0.0127, 0.0368, 0.0687, 0.0657...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0371, 0.1088, 0.0313, 0.0197, 0.0786, 0.069...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.052, 0.0545, 0.0182, 0.021, 0.0296, 0.1138,...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0338, 0.0638, 0.0304, 0.0135, 0.0136, 0.051...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0721, 0.0269, 0.0302, 0.0198, 0.0131, 0.037...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0345, 0.0846, 0.01, 0.0144, 0.0423, 0.0307,...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0498, 0.0233, 0.0083, 0.0611, 0.0322, 0.018...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0476, 0.0179, 0.0538, 0.0734, 0.0116, 0.010...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0305, 0.0267, 0.051, 0.0376, 0.0134, 0.0263...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.038, 0.0313, 0.0459, 0.015, 0.0565, 0.0351,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0372, 0.0342, 0.0363, 0.0134, 0.0528, 0.038...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0485, 0.0353, 0.023, 0.0175, 0.0225, 0.0233...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0408, 0.0416, 0.0385, 0.0424, 0.0578, 0.029...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0203, 0.0539, 0.0226, 0.0286, 0.0254, 0.022...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0168, 0.0319, 0.0237, 0.0627, 0.0538, 0.048...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0102, 0.0321, 0.0356, 0.0582, 0.0465, 0.054...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.029, 0.0284, 0.0297, 0.0685, 0.0454, 0.0229...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0206, 0.0174, 0.024, 0.0567, 0.0381, 0.0141...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0129, 0.0524, 0.0188, 0.019, 0.0423, 0.0348...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0064, 0.1273, 0.0458, 0.0673, 0.074, 0.0553...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.013, 0.0643, 0.0199, 0.0396, 0.0557, 0.0268...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.2118, 0.0371, 0.0207, 0.0273, 0.0406, 0.054...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0347, 0.0433, 0.0486, 0.0638, 0.0297, 0.034...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0317, 0.0281, 0.0636, 0.0846, 0.0421, 0.026...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0394, 0.0211, 0.0247, 0.0174, 0.0416, 0.017...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0306, 0.0564, 0.0169, 0.0431, 0.0431, 0.054...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0256, 0.023, 0.0251, 0.014, 0.0177, 0.0168,...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0333, 0.0392, 0.013, 0.0272, 0.0108, 0.0233...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0346, 0.0229, 0.0108, 0.0314, 0.0153, 0.013...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0187, 0.0345, 0.023, 0.0283, 0.0121, 0.04, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0236, 0.0264, 0.0196, 0.0258, 0.0096, 0.018...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0196, 0.021, 0.0178, 0.0786, 0.0061, 0.0166...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0201, 0.0246, 0.0199, 0.0416, 0.0134, 0.017...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0293, 0.0233, 0.016, 0.0285, 0.0144, 0.0122...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0484, 0.0359, 0.0188, 0.0112, 0.0559, 0.021...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0298, 0.0336, 0.038, 0.0266, 0.0225, 0.0113...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1053, 0.0376, 0.0395, 0.1278, 0.0699, 0.040...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0091, 0.0435, 0.0186, 0.0333, 0.0288, 0.027...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0217, 0.0301, 0.021, 0.0338, 0.0275, 0.0408...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0344, 0.091, 0.0212, 0.0242, 0.0364, 0.0541...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0257, 0.0953, 0.0154, 0.0255, 0.0267, 0.064...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.2303, 0.0155, 0.0188, 0.0316, 0.0172, 0.018...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0208, 0.0229, 0.0213, 0.0269, 0.0608, 0.011...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.2086, 0.0145, 0.0208, 0.0333, 0.0095, 0.026...               0   \n",
       "1   [0.1784, 0.0133, 0.019, 0.0297, 0.0126, 0.0121...               0   \n",
       "2   [0.1979, 0.0395, 0.0221, 0.0462, 0.0144, 0.078...               0   \n",
       "3   [0.0845, 0.0834, 0.0181, 0.0219, 0.0309, 0.038...               1   \n",
       "4   [0.0298, 0.1136, 0.0355, 0.0163, 0.0274, 0.040...               1   \n",
       "5   [0.0095, 0.0444, 0.1019, 0.0151, 0.0316, 0.029...               2   \n",
       "6   [0.0324, 0.0192, 0.021, 0.1442, 0.0328, 0.0214...               3   \n",
       "7   [0.0259, 0.0213, 0.0326, 0.2754, 0.0228, 0.025...               3   \n",
       "8   [0.067, 0.0242, 0.047, 0.3534, 0.0237, 0.0321,...               3   \n",
       "9   [0.042, 0.0562, 0.0127, 0.0368, 0.0687, 0.0657...               4   \n",
       "10  [0.0371, 0.1088, 0.0313, 0.0197, 0.0786, 0.069...               4   \n",
       "11  [0.052, 0.0545, 0.0182, 0.021, 0.0296, 0.1138,...               5   \n",
       "12  [0.0338, 0.0638, 0.0304, 0.0135, 0.0136, 0.051...               6   \n",
       "13  [0.0721, 0.0269, 0.0302, 0.0198, 0.0131, 0.037...               7   \n",
       "14  [0.0345, 0.0846, 0.01, 0.0144, 0.0423, 0.0307,...               8   \n",
       "15  [0.0498, 0.0233, 0.0083, 0.0611, 0.0322, 0.018...               8   \n",
       "16  [0.0476, 0.0179, 0.0538, 0.0734, 0.0116, 0.010...               9   \n",
       "17  [0.0305, 0.0267, 0.051, 0.0376, 0.0134, 0.0263...               9   \n",
       "18  [0.038, 0.0313, 0.0459, 0.015, 0.0565, 0.0351,...              10   \n",
       "19  [0.0372, 0.0342, 0.0363, 0.0134, 0.0528, 0.038...              10   \n",
       "20  [0.0485, 0.0353, 0.023, 0.0175, 0.0225, 0.0233...              11   \n",
       "21  [0.0408, 0.0416, 0.0385, 0.0424, 0.0578, 0.029...              11   \n",
       "22  [0.0203, 0.0539, 0.0226, 0.0286, 0.0254, 0.022...              12   \n",
       "23  [0.0168, 0.0319, 0.0237, 0.0627, 0.0538, 0.048...              13   \n",
       "24  [0.0102, 0.0321, 0.0356, 0.0582, 0.0465, 0.054...              13   \n",
       "25  [0.029, 0.0284, 0.0297, 0.0685, 0.0454, 0.0229...              14   \n",
       "26  [0.0206, 0.0174, 0.024, 0.0567, 0.0381, 0.0141...              14   \n",
       "27  [0.0129, 0.0524, 0.0188, 0.019, 0.0423, 0.0348...              15   \n",
       "28  [0.0064, 0.1273, 0.0458, 0.0673, 0.074, 0.0553...              15   \n",
       "29  [0.013, 0.0643, 0.0199, 0.0396, 0.0557, 0.0268...              15   \n",
       "30  [0.2118, 0.0371, 0.0207, 0.0273, 0.0406, 0.054...              16   \n",
       "31  [0.0347, 0.0433, 0.0486, 0.0638, 0.0297, 0.034...              17   \n",
       "32  [0.0317, 0.0281, 0.0636, 0.0846, 0.0421, 0.026...              17   \n",
       "33  [0.0394, 0.0211, 0.0247, 0.0174, 0.0416, 0.017...              18   \n",
       "34  [0.0306, 0.0564, 0.0169, 0.0431, 0.0431, 0.054...              19   \n",
       "35  [0.0256, 0.023, 0.0251, 0.014, 0.0177, 0.0168,...              20   \n",
       "36  [0.0333, 0.0392, 0.013, 0.0272, 0.0108, 0.0233...              21   \n",
       "37  [0.0346, 0.0229, 0.0108, 0.0314, 0.0153, 0.013...              21   \n",
       "38  [0.0187, 0.0345, 0.023, 0.0283, 0.0121, 0.04, ...              22   \n",
       "39  [0.0236, 0.0264, 0.0196, 0.0258, 0.0096, 0.018...              22   \n",
       "40  [0.0196, 0.021, 0.0178, 0.0786, 0.0061, 0.0166...              22   \n",
       "41  [0.0201, 0.0246, 0.0199, 0.0416, 0.0134, 0.017...              22   \n",
       "42  [0.0293, 0.0233, 0.016, 0.0285, 0.0144, 0.0122...              23   \n",
       "43  [0.0484, 0.0359, 0.0188, 0.0112, 0.0559, 0.021...              23   \n",
       "44  [0.0298, 0.0336, 0.038, 0.0266, 0.0225, 0.0113...              23   \n",
       "45  [0.1053, 0.0376, 0.0395, 0.1278, 0.0699, 0.040...              23   \n",
       "46  [0.0091, 0.0435, 0.0186, 0.0333, 0.0288, 0.027...              24   \n",
       "47  [0.0217, 0.0301, 0.021, 0.0338, 0.0275, 0.0408...              24   \n",
       "48  [0.0344, 0.091, 0.0212, 0.0242, 0.0364, 0.0541...              25   \n",
       "49  [0.0257, 0.0953, 0.0154, 0.0255, 0.0267, 0.064...              25   \n",
       "50  [0.2303, 0.0155, 0.0188, 0.0316, 0.0172, 0.018...              26   \n",
       "51  [0.0208, 0.0229, 0.0213, 0.0269, 0.0608, 0.011...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0      0.75  0.103117  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                 23       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 8       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501 : Training: loss:  0.09654362\n",
      "1502 : Training: loss:  0.09382896\n",
      "1503 : Training: loss:  0.09872351\n",
      "1504 : Training: loss:  0.0923316\n",
      "1505 : Training: loss:  0.08389156\n",
      "1506 : Training: loss:  0.0818822\n",
      "1507 : Training: loss:  0.09792591\n",
      "1508 : Training: loss:  0.096354835\n",
      "1509 : Training: loss:  0.10536119\n",
      "1510 : Training: loss:  0.101187535\n",
      "1511 : Training: loss:  0.06533459\n",
      "1512 : Training: loss:  0.085128166\n",
      "1513 : Training: loss:  0.10686153\n",
      "1514 : Training: loss:  0.07884672\n",
      "1515 : Training: loss:  0.09685571\n",
      "1516 : Training: loss:  0.079116\n",
      "1517 : Training: loss:  0.08192894\n",
      "1518 : Training: loss:  0.09928904\n",
      "1519 : Training: loss:  0.09732667\n",
      "1520 : Training: loss:  0.09808493\n",
      "Validation: Loss:  0.10198017  Accuracy:  0.75\n",
      "1521 : Training: loss:  0.1021532\n",
      "1522 : Training: loss:  0.088410996\n",
      "1523 : Training: loss:  0.08776988\n",
      "1524 : Training: loss:  0.099565975\n",
      "1525 : Training: loss:  0.0955799\n",
      "1526 : Training: loss:  0.10031128\n",
      "1527 : Training: loss:  0.09182309\n",
      "1528 : Training: loss:  0.10313405\n",
      "1529 : Training: loss:  0.099006794\n",
      "1530 : Training: loss:  0.09465991\n",
      "1531 : Training: loss:  0.10745034\n",
      "1532 : Training: loss:  0.092946224\n",
      "1533 : Training: loss:  0.076855846\n",
      "1534 : Training: loss:  0.09051071\n",
      "1535 : Training: loss:  0.08564552\n",
      "1536 : Training: loss:  0.081095085\n",
      "1537 : Training: loss:  0.106034726\n",
      "1538 : Training: loss:  0.084229596\n",
      "1539 : Training: loss:  0.097482026\n",
      "1540 : Training: loss:  0.07771062\n",
      "Validation: Loss:  0.100966595  Accuracy:  0.7692308\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.2318, 0.0149, 0.0191, 0.0332, 0.0087, 0.024...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.100967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1972, 0.0138, 0.0175, 0.0303, 0.012, 0.0112...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.2177, 0.0401, 0.02, 0.0476, 0.0132, 0.0738,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0874, 0.1005, 0.0171, 0.022, 0.0311, 0.0391...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0298, 0.1339, 0.0343, 0.0167, 0.0276, 0.040...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0089, 0.0451, 0.0984, 0.0147, 0.03, 0.0284,...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0341, 0.0192, 0.0196, 0.1708, 0.032, 0.0203...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0267, 0.0202, 0.0299, 0.3173, 0.0219, 0.023...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0674, 0.0233, 0.0425, 0.395, 0.022, 0.029, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0425, 0.0629, 0.0117, 0.0379, 0.0691, 0.066...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0377, 0.1227, 0.0296, 0.0202, 0.08, 0.0707,...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0536, 0.0591, 0.0166, 0.0206, 0.0287, 0.114...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0337, 0.0676, 0.0284, 0.013, 0.0123, 0.049,...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0781, 0.0279, 0.0286, 0.0202, 0.0124, 0.035...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0356, 0.0971, 0.0093, 0.0146, 0.0428, 0.030...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0529, 0.024, 0.0073, 0.066, 0.0315, 0.0168,...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0485, 0.0184, 0.0509, 0.0803, 0.011, 0.0096...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0301, 0.027, 0.0471, 0.0377, 0.0126, 0.0248...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0364, 0.0329, 0.0433, 0.0142, 0.0557, 0.033...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.036, 0.0369, 0.0346, 0.0129, 0.0522, 0.0377...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0488, 0.0356, 0.0206, 0.0169, 0.0206, 0.021...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0396, 0.0437, 0.0355, 0.0441, 0.0565, 0.028...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0201, 0.0569, 0.0205, 0.0293, 0.0238, 0.020...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0158, 0.0303, 0.0214, 0.0659, 0.0507, 0.045...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0094, 0.0312, 0.0329, 0.0597, 0.0448, 0.051...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0289, 0.0288, 0.0276, 0.0736, 0.0441, 0.021...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0196, 0.0169, 0.0218, 0.0579, 0.0356, 0.012...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0121, 0.0569, 0.0172, 0.0185, 0.0409, 0.033...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0059, 0.1389, 0.0436, 0.0706, 0.0749, 0.055...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0125, 0.0677, 0.0178, 0.0396, 0.0541, 0.025...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.2296, 0.0394, 0.0193, 0.0276, 0.0392, 0.053...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0336, 0.0465, 0.0454, 0.0663, 0.0283, 0.032...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0318, 0.0281, 0.06, 0.0929, 0.0401, 0.0249,...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0399, 0.0212, 0.0229, 0.0171, 0.0396, 0.015...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0303, 0.0602, 0.0157, 0.0451, 0.0425, 0.052...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0251, 0.0235, 0.0236, 0.0137, 0.0167, 0.015...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0346, 0.043, 0.0121, 0.0278, 0.0101, 0.0227...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0358, 0.0231, 0.0097, 0.0335, 0.014, 0.012,...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0178, 0.0342, 0.0213, 0.0288, 0.0111, 0.037...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.023, 0.0294, 0.0186, 0.0266, 0.0093, 0.0177...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0192, 0.0218, 0.0166, 0.0843, 0.0058, 0.016...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0194, 0.0254, 0.0184, 0.0425, 0.0124, 0.016...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0282, 0.0236, 0.0146, 0.0288, 0.0134, 0.011...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0476, 0.0346, 0.0168, 0.0103, 0.0513, 0.019...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0291, 0.0354, 0.0353, 0.0274, 0.0217, 0.010...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1094, 0.0378, 0.0367, 0.1398, 0.0673, 0.037...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0084, 0.0441, 0.0171, 0.0357, 0.0275, 0.025...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0216, 0.0303, 0.0196, 0.0365, 0.0262, 0.039...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0355, 0.1065, 0.0199, 0.0245, 0.0363, 0.055...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0259, 0.1103, 0.0143, 0.0259, 0.0266, 0.065...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.2436, 0.0155, 0.0169, 0.0316, 0.0161, 0.016...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0205, 0.0248, 0.0202, 0.029, 0.0629, 0.0105...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.2318, 0.0149, 0.0191, 0.0332, 0.0087, 0.024...               0   \n",
       "1   [0.1972, 0.0138, 0.0175, 0.0303, 0.012, 0.0112...               0   \n",
       "2   [0.2177, 0.0401, 0.02, 0.0476, 0.0132, 0.0738,...               0   \n",
       "3   [0.0874, 0.1005, 0.0171, 0.022, 0.0311, 0.0391...               1   \n",
       "4   [0.0298, 0.1339, 0.0343, 0.0167, 0.0276, 0.040...               1   \n",
       "5   [0.0089, 0.0451, 0.0984, 0.0147, 0.03, 0.0284,...               2   \n",
       "6   [0.0341, 0.0192, 0.0196, 0.1708, 0.032, 0.0203...               3   \n",
       "7   [0.0267, 0.0202, 0.0299, 0.3173, 0.0219, 0.023...               3   \n",
       "8   [0.0674, 0.0233, 0.0425, 0.395, 0.022, 0.029, ...               3   \n",
       "9   [0.0425, 0.0629, 0.0117, 0.0379, 0.0691, 0.066...               4   \n",
       "10  [0.0377, 0.1227, 0.0296, 0.0202, 0.08, 0.0707,...               4   \n",
       "11  [0.0536, 0.0591, 0.0166, 0.0206, 0.0287, 0.114...               5   \n",
       "12  [0.0337, 0.0676, 0.0284, 0.013, 0.0123, 0.049,...               6   \n",
       "13  [0.0781, 0.0279, 0.0286, 0.0202, 0.0124, 0.035...               7   \n",
       "14  [0.0356, 0.0971, 0.0093, 0.0146, 0.0428, 0.030...               8   \n",
       "15  [0.0529, 0.024, 0.0073, 0.066, 0.0315, 0.0168,...               8   \n",
       "16  [0.0485, 0.0184, 0.0509, 0.0803, 0.011, 0.0096...               9   \n",
       "17  [0.0301, 0.027, 0.0471, 0.0377, 0.0126, 0.0248...               9   \n",
       "18  [0.0364, 0.0329, 0.0433, 0.0142, 0.0557, 0.033...              10   \n",
       "19  [0.036, 0.0369, 0.0346, 0.0129, 0.0522, 0.0377...              10   \n",
       "20  [0.0488, 0.0356, 0.0206, 0.0169, 0.0206, 0.021...              11   \n",
       "21  [0.0396, 0.0437, 0.0355, 0.0441, 0.0565, 0.028...              11   \n",
       "22  [0.0201, 0.0569, 0.0205, 0.0293, 0.0238, 0.020...              12   \n",
       "23  [0.0158, 0.0303, 0.0214, 0.0659, 0.0507, 0.045...              13   \n",
       "24  [0.0094, 0.0312, 0.0329, 0.0597, 0.0448, 0.051...              13   \n",
       "25  [0.0289, 0.0288, 0.0276, 0.0736, 0.0441, 0.021...              14   \n",
       "26  [0.0196, 0.0169, 0.0218, 0.0579, 0.0356, 0.012...              14   \n",
       "27  [0.0121, 0.0569, 0.0172, 0.0185, 0.0409, 0.033...              15   \n",
       "28  [0.0059, 0.1389, 0.0436, 0.0706, 0.0749, 0.055...              15   \n",
       "29  [0.0125, 0.0677, 0.0178, 0.0396, 0.0541, 0.025...              15   \n",
       "30  [0.2296, 0.0394, 0.0193, 0.0276, 0.0392, 0.053...              16   \n",
       "31  [0.0336, 0.0465, 0.0454, 0.0663, 0.0283, 0.032...              17   \n",
       "32  [0.0318, 0.0281, 0.06, 0.0929, 0.0401, 0.0249,...              17   \n",
       "33  [0.0399, 0.0212, 0.0229, 0.0171, 0.0396, 0.015...              18   \n",
       "34  [0.0303, 0.0602, 0.0157, 0.0451, 0.0425, 0.052...              19   \n",
       "35  [0.0251, 0.0235, 0.0236, 0.0137, 0.0167, 0.015...              20   \n",
       "36  [0.0346, 0.043, 0.0121, 0.0278, 0.0101, 0.0227...              21   \n",
       "37  [0.0358, 0.0231, 0.0097, 0.0335, 0.014, 0.012,...              21   \n",
       "38  [0.0178, 0.0342, 0.0213, 0.0288, 0.0111, 0.037...              22   \n",
       "39  [0.023, 0.0294, 0.0186, 0.0266, 0.0093, 0.0177...              22   \n",
       "40  [0.0192, 0.0218, 0.0166, 0.0843, 0.0058, 0.016...              22   \n",
       "41  [0.0194, 0.0254, 0.0184, 0.0425, 0.0124, 0.016...              22   \n",
       "42  [0.0282, 0.0236, 0.0146, 0.0288, 0.0134, 0.011...              23   \n",
       "43  [0.0476, 0.0346, 0.0168, 0.0103, 0.0513, 0.019...              23   \n",
       "44  [0.0291, 0.0354, 0.0353, 0.0274, 0.0217, 0.010...              23   \n",
       "45  [0.1094, 0.0378, 0.0367, 0.1398, 0.0673, 0.037...              23   \n",
       "46  [0.0084, 0.0441, 0.0171, 0.0357, 0.0275, 0.025...              24   \n",
       "47  [0.0216, 0.0303, 0.0196, 0.0365, 0.0262, 0.039...              24   \n",
       "48  [0.0355, 0.1065, 0.0199, 0.0245, 0.0363, 0.055...              25   \n",
       "49  [0.0259, 0.1103, 0.0143, 0.0259, 0.0266, 0.065...              25   \n",
       "50  [0.2436, 0.0155, 0.0169, 0.0316, 0.0161, 0.016...              26   \n",
       "51  [0.0205, 0.0248, 0.0202, 0.029, 0.0629, 0.0105...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.769231  0.100967  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                  1       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                 10       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 8       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1541 : Training: loss:  0.083412\n",
      "1542 : Training: loss:  0.08858972\n",
      "1543 : Training: loss:  0.071662515\n",
      "1544 : Training: loss:  0.091726474\n",
      "1545 : Training: loss:  0.08463014\n",
      "1546 : Training: loss:  0.08040935\n",
      "1547 : Training: loss:  0.09489169\n",
      "1548 : Training: loss:  0.10828335\n",
      "1549 : Training: loss:  0.120437816\n",
      "1550 : Training: loss:  0.07698181\n",
      "1551 : Training: loss:  0.09791238\n",
      "1552 : Training: loss:  0.10350238\n",
      "1553 : Training: loss:  0.067977935\n",
      "1554 : Training: loss:  0.09558334\n",
      "1555 : Training: loss:  0.079008214\n",
      "1556 : Training: loss:  0.07485812\n",
      "1557 : Training: loss:  0.0829722\n",
      "1558 : Training: loss:  0.09436623\n",
      "1559 : Training: loss:  0.092761226\n",
      "1560 : Training: loss:  0.088622004\n",
      "Validation: Loss:  0.09989456  Accuracy:  0.75\n",
      "1561 : Training: loss:  0.069166854\n",
      "1562 : Training: loss:  0.0804089\n",
      "1563 : Training: loss:  0.085771546\n",
      "1564 : Training: loss:  0.078674935\n",
      "1565 : Training: loss:  0.0749867\n",
      "1566 : Training: loss:  0.109667934\n",
      "1567 : Training: loss:  0.082460985\n",
      "1568 : Training: loss:  0.080634594\n",
      "1569 : Training: loss:  0.09053399\n",
      "1570 : Training: loss:  0.08430437\n",
      "1571 : Training: loss:  0.10950076\n",
      "1572 : Training: loss:  0.092123926\n",
      "1573 : Training: loss:  0.1008059\n",
      "1574 : Training: loss:  0.1158775\n",
      "1575 : Training: loss:  0.06985898\n",
      "1576 : Training: loss:  0.10137708\n",
      "1577 : Training: loss:  0.0933235\n",
      "1578 : Training: loss:  0.08220787\n",
      "1579 : Training: loss:  0.08991534\n",
      "1580 : Training: loss:  0.08732665\n",
      "Validation: Loss:  0.09892321  Accuracy:  0.75\n",
      "1581 : Training: loss:  0.088624135\n",
      "1582 : Training: loss:  0.093277015\n",
      "1583 : Training: loss:  0.069257386\n",
      "1584 : Training: loss:  0.060729913\n",
      "1585 : Training: loss:  0.07462148\n",
      "1586 : Training: loss:  0.096949436\n",
      "1587 : Training: loss:  0.08400918\n",
      "1588 : Training: loss:  0.06733717\n",
      "1589 : Training: loss:  0.07601174\n",
      "1590 : Training: loss:  0.09214358\n",
      "1591 : Training: loss:  0.11105692\n",
      "1592 : Training: loss:  0.08929118\n",
      "1593 : Training: loss:  0.098370746\n",
      "1594 : Training: loss:  0.065818235\n",
      "1595 : Training: loss:  0.0758023\n",
      "1596 : Training: loss:  0.086182505\n",
      "1597 : Training: loss:  0.08932093\n",
      "1598 : Training: loss:  0.087336734\n",
      "1599 : Training: loss:  0.07878984\n",
      "1600 : Training: loss:  0.10412108\n",
      "Validation: Loss:  0.09794373  Accuracy:  0.7307692\n",
      "1601 : Training: loss:  0.08580361\n",
      "1602 : Training: loss:  0.07432166\n",
      "1603 : Training: loss:  0.10107169\n",
      "1604 : Training: loss:  0.09606043\n",
      "1605 : Training: loss:  0.091578156\n",
      "1606 : Training: loss:  0.08472318\n",
      "1607 : Training: loss:  0.07876673\n",
      "1608 : Training: loss:  0.095427595\n",
      "1609 : Training: loss:  0.08145317\n",
      "1610 : Training: loss:  0.08084004\n",
      "1611 : Training: loss:  0.10341304\n",
      "1612 : Training: loss:  0.09473453\n",
      "1613 : Training: loss:  0.09619254\n",
      "1614 : Training: loss:  0.073997594\n",
      "1615 : Training: loss:  0.07383475\n",
      "1616 : Training: loss:  0.085021876\n",
      "1617 : Training: loss:  0.08836848\n",
      "1618 : Training: loss:  0.096319206\n",
      "1619 : Training: loss:  0.061394073\n",
      "1620 : Training: loss:  0.094237946\n",
      "Validation: Loss:  0.097029075  Accuracy:  0.7307692\n",
      "1621 : Training: loss:  0.09686284\n",
      "1622 : Training: loss:  0.10446385\n",
      "1623 : Training: loss:  0.09960001\n",
      "1624 : Training: loss:  0.07192935\n",
      "1625 : Training: loss:  0.12345012\n",
      "1626 : Training: loss:  0.065781966\n",
      "1627 : Training: loss:  0.09011086\n",
      "1628 : Training: loss:  0.10290794\n",
      "1629 : Training: loss:  0.09495315\n",
      "1630 : Training: loss:  0.08812457\n",
      "1631 : Training: loss:  0.07935377\n",
      "1632 : Training: loss:  0.10058484\n",
      "1633 : Training: loss:  0.09576434\n",
      "1634 : Training: loss:  0.07891982\n",
      "1635 : Training: loss:  0.08656686\n",
      "1636 : Training: loss:  0.08139115\n",
      "1637 : Training: loss:  0.099595845\n",
      "1638 : Training: loss:  0.06690366\n",
      "1639 : Training: loss:  0.08753568\n",
      "1640 : Training: loss:  0.07525511\n",
      "Validation: Loss:  0.096037276  Accuracy:  0.75\n",
      "1641 : Training: loss:  0.088472806\n",
      "1642 : Training: loss:  0.086073056\n",
      "1643 : Training: loss:  0.076330565\n",
      "1644 : Training: loss:  0.06548876\n",
      "1645 : Training: loss:  0.09152333\n",
      "1646 : Training: loss:  0.123136766\n",
      "1647 : Training: loss:  0.06146527\n",
      "1648 : Training: loss:  0.08841175\n",
      "1649 : Training: loss:  0.09387178\n",
      "1650 : Training: loss:  0.07429662\n",
      "1651 : Training: loss:  0.07494922\n",
      "1652 : Training: loss:  0.09868969\n",
      "1653 : Training: loss:  0.08635039\n",
      "1654 : Training: loss:  0.11135619\n",
      "1655 : Training: loss:  0.093267255\n",
      "1656 : Training: loss:  0.069102496\n",
      "1657 : Training: loss:  0.07370278\n",
      "1658 : Training: loss:  0.084114015\n",
      "1659 : Training: loss:  0.10647942\n",
      "1660 : Training: loss:  0.10004744\n",
      "Validation: Loss:  0.09510436  Accuracy:  0.7692308\n",
      "1661 : Training: loss:  0.0988325\n",
      "1662 : Training: loss:  0.07770657\n",
      "1663 : Training: loss:  0.08122582\n",
      "1664 : Training: loss:  0.09321019\n",
      "1665 : Training: loss:  0.07795766\n",
      "1666 : Training: loss:  0.08079528\n",
      "1667 : Training: loss:  0.09605208\n",
      "1668 : Training: loss:  0.07969152\n",
      "1669 : Training: loss:  0.088232934\n",
      "1670 : Training: loss:  0.08869111\n",
      "1671 : Training: loss:  0.0719519\n",
      "1672 : Training: loss:  0.10942322\n",
      "1673 : Training: loss:  0.09333921\n",
      "1674 : Training: loss:  0.06831142\n",
      "1675 : Training: loss:  0.06341093\n",
      "1676 : Training: loss:  0.08641392\n",
      "1677 : Training: loss:  0.09035487\n",
      "1678 : Training: loss:  0.07965741\n",
      "1679 : Training: loss:  0.07801315\n",
      "1680 : Training: loss:  0.0892498\n",
      "Validation: Loss:  0.094126165  Accuracy:  0.78846157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.2777, 0.0125, 0.0166, 0.0271, 0.0068, 0.020...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.094126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.2402, 0.0117, 0.0154, 0.0248, 0.01, 0.0091,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.2796, 0.0397, 0.0181, 0.0415, 0.0109, 0.072...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0962, 0.1172, 0.0152, 0.0173, 0.0294, 0.037...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0312, 0.1696, 0.0386, 0.0133, 0.0289, 0.040...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0072, 0.0465, 0.1593, 0.012, 0.0311, 0.0276...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0314, 0.016, 0.019, 0.189, 0.0311, 0.0177, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0233, 0.0154, 0.029, 0.3448, 0.02, 0.0182, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0658, 0.0178, 0.0399, 0.4294, 0.0181, 0.020...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0403, 0.0647, 0.0096, 0.0318, 0.0705, 0.067...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0384, 0.1472, 0.0321, 0.0166, 0.093, 0.0768...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0508, 0.0574, 0.0137, 0.0148, 0.0261, 0.116...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.032, 0.0703, 0.0345, 0.0097, 0.0101, 0.0471...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0895, 0.027, 0.0323, 0.0165, 0.0112, 0.033,...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0349, 0.1113, 0.0079, 0.0112, 0.0441, 0.027...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0523, 0.0205, 0.0053, 0.0565, 0.0294, 0.012...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0484, 0.0161, 0.0575, 0.0719, 0.0093, 0.007...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0284, 0.024, 0.0555, 0.0306, 0.0112, 0.0211...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0328, 0.0296, 0.0488, 0.0103, 0.0569, 0.028...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0328, 0.0332, 0.0375, 0.0093, 0.0521, 0.033...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0467, 0.0336, 0.0197, 0.0132, 0.0171, 0.016...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0338, 0.0404, 0.035, 0.0384, 0.055, 0.0227,...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0187, 0.0593, 0.0213, 0.0262, 0.0223, 0.016...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0122, 0.0244, 0.0226, 0.0567, 0.0486, 0.039...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0066, 0.0265, 0.0386, 0.0505, 0.0443, 0.045...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0262, 0.0234, 0.0275, 0.0711, 0.0425, 0.016...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0158, 0.0132, 0.0214, 0.0521, 0.0315, 0.009...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0093, 0.057, 0.0168, 0.0137, 0.0376, 0.0299...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0042, 0.1522, 0.0504, 0.0619, 0.0812, 0.051...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0101, 0.066, 0.0165, 0.0322, 0.0532, 0.0213...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.2784, 0.0372, 0.0184, 0.0232, 0.0377, 0.050...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0312, 0.0461, 0.0493, 0.0624, 0.0255, 0.027...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0305, 0.0266, 0.0773, 0.0956, 0.0408, 0.021...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0396, 0.0173, 0.023, 0.0133, 0.0351, 0.012,...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.026, 0.0581, 0.0136, 0.0374, 0.0398, 0.0469...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0251, 0.0208, 0.0284, 0.011, 0.0147, 0.0134...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0336, 0.0437, 0.0119, 0.0226, 0.0082, 0.021...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0362, 0.0204, 0.0097, 0.0305, 0.0113, 0.009...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0155, 0.0321, 0.0273, 0.0257, 0.0096, 0.036...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0216, 0.0282, 0.0196, 0.0233, 0.0078, 0.014...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0176, 0.0191, 0.0178, 0.0764, 0.0048, 0.014...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0173, 0.0235, 0.0206, 0.0393, 0.0105, 0.013...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0255, 0.0198, 0.0146, 0.0241, 0.0109, 0.008...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0447, 0.0298, 0.0165, 0.0077, 0.0471, 0.015...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0271, 0.0324, 0.04, 0.0231, 0.0208, 0.0084,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.1122, 0.0312, 0.0347, 0.136, 0.0625, 0.0313...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0065, 0.0415, 0.0203, 0.0327, 0.0276, 0.024...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0189, 0.026, 0.0212, 0.0335, 0.0247, 0.0372...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0331, 0.1197, 0.0187, 0.0199, 0.036, 0.0552...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0231, 0.1253, 0.0132, 0.0209, 0.0265, 0.066...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.2834, 0.0122, 0.014, 0.0243, 0.013, 0.0116,...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0179, 0.0223, 0.0197, 0.0249, 0.0683, 0.008...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.2777, 0.0125, 0.0166, 0.0271, 0.0068, 0.020...               0   \n",
       "1   [0.2402, 0.0117, 0.0154, 0.0248, 0.01, 0.0091,...               0   \n",
       "2   [0.2796, 0.0397, 0.0181, 0.0415, 0.0109, 0.072...               0   \n",
       "3   [0.0962, 0.1172, 0.0152, 0.0173, 0.0294, 0.037...               1   \n",
       "4   [0.0312, 0.1696, 0.0386, 0.0133, 0.0289, 0.040...               1   \n",
       "5   [0.0072, 0.0465, 0.1593, 0.012, 0.0311, 0.0276...               2   \n",
       "6   [0.0314, 0.016, 0.019, 0.189, 0.0311, 0.0177, ...               3   \n",
       "7   [0.0233, 0.0154, 0.029, 0.3448, 0.02, 0.0182, ...               3   \n",
       "8   [0.0658, 0.0178, 0.0399, 0.4294, 0.0181, 0.020...               3   \n",
       "9   [0.0403, 0.0647, 0.0096, 0.0318, 0.0705, 0.067...               4   \n",
       "10  [0.0384, 0.1472, 0.0321, 0.0166, 0.093, 0.0768...               4   \n",
       "11  [0.0508, 0.0574, 0.0137, 0.0148, 0.0261, 0.116...               5   \n",
       "12  [0.032, 0.0703, 0.0345, 0.0097, 0.0101, 0.0471...               6   \n",
       "13  [0.0895, 0.027, 0.0323, 0.0165, 0.0112, 0.033,...               7   \n",
       "14  [0.0349, 0.1113, 0.0079, 0.0112, 0.0441, 0.027...               8   \n",
       "15  [0.0523, 0.0205, 0.0053, 0.0565, 0.0294, 0.012...               8   \n",
       "16  [0.0484, 0.0161, 0.0575, 0.0719, 0.0093, 0.007...               9   \n",
       "17  [0.0284, 0.024, 0.0555, 0.0306, 0.0112, 0.0211...               9   \n",
       "18  [0.0328, 0.0296, 0.0488, 0.0103, 0.0569, 0.028...              10   \n",
       "19  [0.0328, 0.0332, 0.0375, 0.0093, 0.0521, 0.033...              10   \n",
       "20  [0.0467, 0.0336, 0.0197, 0.0132, 0.0171, 0.016...              11   \n",
       "21  [0.0338, 0.0404, 0.035, 0.0384, 0.055, 0.0227,...              11   \n",
       "22  [0.0187, 0.0593, 0.0213, 0.0262, 0.0223, 0.016...              12   \n",
       "23  [0.0122, 0.0244, 0.0226, 0.0567, 0.0486, 0.039...              13   \n",
       "24  [0.0066, 0.0265, 0.0386, 0.0505, 0.0443, 0.045...              13   \n",
       "25  [0.0262, 0.0234, 0.0275, 0.0711, 0.0425, 0.016...              14   \n",
       "26  [0.0158, 0.0132, 0.0214, 0.0521, 0.0315, 0.009...              14   \n",
       "27  [0.0093, 0.057, 0.0168, 0.0137, 0.0376, 0.0299...              15   \n",
       "28  [0.0042, 0.1522, 0.0504, 0.0619, 0.0812, 0.051...              15   \n",
       "29  [0.0101, 0.066, 0.0165, 0.0322, 0.0532, 0.0213...              15   \n",
       "30  [0.2784, 0.0372, 0.0184, 0.0232, 0.0377, 0.050...              16   \n",
       "31  [0.0312, 0.0461, 0.0493, 0.0624, 0.0255, 0.027...              17   \n",
       "32  [0.0305, 0.0266, 0.0773, 0.0956, 0.0408, 0.021...              17   \n",
       "33  [0.0396, 0.0173, 0.023, 0.0133, 0.0351, 0.012,...              18   \n",
       "34  [0.026, 0.0581, 0.0136, 0.0374, 0.0398, 0.0469...              19   \n",
       "35  [0.0251, 0.0208, 0.0284, 0.011, 0.0147, 0.0134...              20   \n",
       "36  [0.0336, 0.0437, 0.0119, 0.0226, 0.0082, 0.021...              21   \n",
       "37  [0.0362, 0.0204, 0.0097, 0.0305, 0.0113, 0.009...              21   \n",
       "38  [0.0155, 0.0321, 0.0273, 0.0257, 0.0096, 0.036...              22   \n",
       "39  [0.0216, 0.0282, 0.0196, 0.0233, 0.0078, 0.014...              22   \n",
       "40  [0.0176, 0.0191, 0.0178, 0.0764, 0.0048, 0.014...              22   \n",
       "41  [0.0173, 0.0235, 0.0206, 0.0393, 0.0105, 0.013...              22   \n",
       "42  [0.0255, 0.0198, 0.0146, 0.0241, 0.0109, 0.008...              23   \n",
       "43  [0.0447, 0.0298, 0.0165, 0.0077, 0.0471, 0.015...              23   \n",
       "44  [0.0271, 0.0324, 0.04, 0.0231, 0.0208, 0.0084,...              23   \n",
       "45  [0.1122, 0.0312, 0.0347, 0.136, 0.0625, 0.0313...              23   \n",
       "46  [0.0065, 0.0415, 0.0203, 0.0327, 0.0276, 0.024...              24   \n",
       "47  [0.0189, 0.026, 0.0212, 0.0335, 0.0247, 0.0372...              24   \n",
       "48  [0.0331, 0.1197, 0.0187, 0.0199, 0.036, 0.0552...              25   \n",
       "49  [0.0231, 0.1253, 0.0132, 0.0209, 0.0265, 0.066...              25   \n",
       "50  [0.2834, 0.0122, 0.014, 0.0243, 0.013, 0.0116,...              26   \n",
       "51  [0.0179, 0.0223, 0.0197, 0.0249, 0.0683, 0.008...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.788462  0.094126  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                  1       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                  2       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  8       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 8       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                 0       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                22       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1681 : Training: loss:  0.0737822\n",
      "1682 : Training: loss:  0.059066623\n",
      "1683 : Training: loss:  0.10223508\n",
      "1684 : Training: loss:  0.08174945\n",
      "1685 : Training: loss:  0.07876434\n",
      "1686 : Training: loss:  0.097827636\n",
      "1687 : Training: loss:  0.06408809\n",
      "1688 : Training: loss:  0.08820195\n",
      "1689 : Training: loss:  0.06358009\n",
      "1690 : Training: loss:  0.07755605\n",
      "1691 : Training: loss:  0.09143404\n",
      "1692 : Training: loss:  0.11021342\n",
      "1693 : Training: loss:  0.07966895\n",
      "1694 : Training: loss:  0.09522582\n",
      "1695 : Training: loss:  0.106133975\n",
      "1696 : Training: loss:  0.08811078\n",
      "1697 : Training: loss:  0.08432773\n",
      "1698 : Training: loss:  0.08295422\n",
      "1699 : Training: loss:  0.06830413\n",
      "1700 : Training: loss:  0.095899016\n",
      "Validation: Loss:  0.093207836  Accuracy:  0.78846157\n",
      "1701 : Training: loss:  0.08587318\n",
      "1702 : Training: loss:  0.09596836\n",
      "1703 : Training: loss:  0.07750759\n",
      "1704 : Training: loss:  0.080764584\n",
      "1705 : Training: loss:  0.08373872\n",
      "1706 : Training: loss:  0.070110165\n",
      "1707 : Training: loss:  0.075848274\n",
      "1708 : Training: loss:  0.08109651\n",
      "1709 : Training: loss:  0.076914065\n",
      "1710 : Training: loss:  0.07609755\n",
      "1711 : Training: loss:  0.08912219\n",
      "1712 : Training: loss:  0.075276375\n",
      "1713 : Training: loss:  0.09019447\n",
      "1714 : Training: loss:  0.09941069\n",
      "1715 : Training: loss:  0.08843889\n",
      "1716 : Training: loss:  0.0862357\n",
      "1717 : Training: loss:  0.09772796\n",
      "1718 : Training: loss:  0.08532867\n",
      "1719 : Training: loss:  0.07507979\n",
      "1720 : Training: loss:  0.08247686\n",
      "Validation: Loss:  0.092403986  Accuracy:  0.78846157\n",
      "1721 : Training: loss:  0.07507115\n",
      "1722 : Training: loss:  0.07537236\n",
      "1723 : Training: loss:  0.08508497\n",
      "1724 : Training: loss:  0.07784004\n",
      "1725 : Training: loss:  0.07084575\n",
      "1726 : Training: loss:  0.09747118\n",
      "1727 : Training: loss:  0.07933614\n",
      "1728 : Training: loss:  0.09150938\n",
      "1729 : Training: loss:  0.08815125\n",
      "1730 : Training: loss:  0.09798345\n",
      "1731 : Training: loss:  0.0748858\n",
      "1732 : Training: loss:  0.09435493\n",
      "1733 : Training: loss:  0.0708271\n",
      "1734 : Training: loss:  0.063992985\n",
      "1735 : Training: loss:  0.07747342\n",
      "1736 : Training: loss:  0.06994782\n",
      "1737 : Training: loss:  0.085046954\n",
      "1738 : Training: loss:  0.10568725\n",
      "1739 : Training: loss:  0.08472075\n",
      "1740 : Training: loss:  0.06807175\n",
      "Validation: Loss:  0.09154321  Accuracy:  0.78846157\n",
      "1741 : Training: loss:  0.08480789\n",
      "1742 : Training: loss:  0.057882424\n",
      "1743 : Training: loss:  0.082167864\n",
      "1744 : Training: loss:  0.08299161\n",
      "1745 : Training: loss:  0.096122585\n",
      "1746 : Training: loss:  0.084551156\n",
      "1747 : Training: loss:  0.10075918\n",
      "1748 : Training: loss:  0.073801994\n",
      "1749 : Training: loss:  0.078220025\n",
      "1750 : Training: loss:  0.0767083\n",
      "1751 : Training: loss:  0.086434826\n",
      "1752 : Training: loss:  0.06474457\n",
      "1753 : Training: loss:  0.09883916\n",
      "1754 : Training: loss:  0.0850926\n",
      "1755 : Training: loss:  0.09963182\n",
      "1756 : Training: loss:  0.09997269\n",
      "1757 : Training: loss:  0.09342936\n",
      "1758 : Training: loss:  0.09952033\n",
      "1759 : Training: loss:  0.06733156\n",
      "1760 : Training: loss:  0.08494652\n",
      "Validation: Loss:  0.09063891  Accuracy:  0.78846157\n",
      "1761 : Training: loss:  0.090661466\n",
      "1762 : Training: loss:  0.08575045\n",
      "1763 : Training: loss:  0.07837995\n",
      "1764 : Training: loss:  0.09075292\n",
      "1765 : Training: loss:  0.077113025\n",
      "1766 : Training: loss:  0.07958723\n",
      "1767 : Training: loss:  0.08644299\n",
      "1768 : Training: loss:  0.058513556\n",
      "1769 : Training: loss:  0.0860356\n",
      "1770 : Training: loss:  0.08397729\n",
      "1771 : Training: loss:  0.08471138\n",
      "1772 : Training: loss:  0.06903523\n",
      "1773 : Training: loss:  0.080282755\n",
      "1774 : Training: loss:  0.07100605\n",
      "1775 : Training: loss:  0.09730829\n",
      "1776 : Training: loss:  0.08634841\n",
      "1777 : Training: loss:  0.070227236\n",
      "1778 : Training: loss:  0.0894788\n",
      "1779 : Training: loss:  0.103107356\n",
      "1780 : Training: loss:  0.080789484\n",
      "Validation: Loss:  0.089720786  Accuracy:  0.78846157\n",
      "1781 : Training: loss:  0.07745239\n",
      "1782 : Training: loss:  0.07181155\n",
      "1783 : Training: loss:  0.08395594\n",
      "1784 : Training: loss:  0.081531666\n",
      "1785 : Training: loss:  0.08250726\n",
      "1786 : Training: loss:  0.09167086\n",
      "1787 : Training: loss:  0.07654271\n",
      "1788 : Training: loss:  0.08954854\n",
      "1789 : Training: loss:  0.077785045\n",
      "1790 : Training: loss:  0.04973896\n",
      "1791 : Training: loss:  0.071897395\n",
      "1792 : Training: loss:  0.10296625\n",
      "1793 : Training: loss:  0.059277527\n",
      "1794 : Training: loss:  0.08674649\n",
      "1795 : Training: loss:  0.08060332\n",
      "1796 : Training: loss:  0.083832085\n",
      "1797 : Training: loss:  0.09145652\n",
      "1798 : Training: loss:  0.08162225\n",
      "1799 : Training: loss:  0.0798655\n",
      "1800 : Training: loss:  0.079600476\n",
      "Validation: Loss:  0.08871479  Accuracy:  0.78846157\n",
      "1801 : Training: loss:  0.08222391\n",
      "1802 : Training: loss:  0.07674376\n",
      "1803 : Training: loss:  0.07602456\n",
      "1804 : Training: loss:  0.09854714\n",
      "1805 : Training: loss:  0.109813705\n",
      "1806 : Training: loss:  0.091888584\n",
      "1807 : Training: loss:  0.08638759\n",
      "1808 : Training: loss:  0.098486915\n",
      "1809 : Training: loss:  0.060530305\n",
      "1810 : Training: loss:  0.061301153\n",
      "1811 : Training: loss:  0.048765644\n",
      "1812 : Training: loss:  0.061134465\n",
      "1813 : Training: loss:  0.06329779\n",
      "1814 : Training: loss:  0.072574295\n",
      "1815 : Training: loss:  0.07791815\n",
      "1816 : Training: loss:  0.0817153\n",
      "1817 : Training: loss:  0.07595249\n",
      "1818 : Training: loss:  0.086477384\n",
      "1819 : Training: loss:  0.08312731\n",
      "1820 : Training: loss:  0.08503927\n",
      "Validation: Loss:  0.08783729  Accuracy:  0.78846157\n",
      "1821 : Training: loss:  0.069565\n",
      "1822 : Training: loss:  0.073862635\n",
      "1823 : Training: loss:  0.07960827\n",
      "1824 : Training: loss:  0.08797553\n",
      "1825 : Training: loss:  0.052227285\n",
      "1826 : Training: loss:  0.081525214\n",
      "1827 : Training: loss:  0.07451722\n",
      "1828 : Training: loss:  0.0702449\n",
      "1829 : Training: loss:  0.06943851\n",
      "1830 : Training: loss:  0.09205541\n",
      "1831 : Training: loss:  0.10467213\n",
      "1832 : Training: loss:  0.06814155\n",
      "1833 : Training: loss:  0.06974924\n",
      "1834 : Training: loss:  0.07177222\n",
      "1835 : Training: loss:  0.06246938\n",
      "1836 : Training: loss:  0.079934634\n",
      "1837 : Training: loss:  0.060937062\n",
      "1838 : Training: loss:  0.09208306\n",
      "1839 : Training: loss:  0.068981364\n",
      "1840 : Training: loss:  0.07632342\n",
      "Validation: Loss:  0.08708032  Accuracy:  0.78846157\n",
      "1841 : Training: loss:  0.07843319\n",
      "1842 : Training: loss:  0.062748656\n",
      "1843 : Training: loss:  0.08617154\n",
      "1844 : Training: loss:  0.09639702\n",
      "1845 : Training: loss:  0.0769941\n",
      "1846 : Training: loss:  0.07137955\n",
      "1847 : Training: loss:  0.05452626\n",
      "1848 : Training: loss:  0.07176369\n",
      "1849 : Training: loss:  0.0707834\n",
      "1850 : Training: loss:  0.0663443\n",
      "1851 : Training: loss:  0.074980035\n",
      "1852 : Training: loss:  0.08122347\n",
      "1853 : Training: loss:  0.07265433\n",
      "1854 : Training: loss:  0.072768144\n",
      "1855 : Training: loss:  0.08188429\n",
      "1856 : Training: loss:  0.07811176\n",
      "1857 : Training: loss:  0.073849715\n",
      "1858 : Training: loss:  0.060089465\n",
      "1859 : Training: loss:  0.08867897\n",
      "1860 : Training: loss:  0.05035952\n",
      "Validation: Loss:  0.08624444  Accuracy:  0.78846157\n",
      "1861 : Training: loss:  0.07774109\n",
      "1862 : Training: loss:  0.06140814\n",
      "1863 : Training: loss:  0.079197116\n",
      "1864 : Training: loss:  0.06932699\n",
      "1865 : Training: loss:  0.06916257\n",
      "1866 : Training: loss:  0.06647943\n",
      "1867 : Training: loss:  0.08636549\n",
      "1868 : Training: loss:  0.056785557\n",
      "1869 : Training: loss:  0.08979611\n",
      "1870 : Training: loss:  0.052288603\n",
      "1871 : Training: loss:  0.061552864\n",
      "1872 : Training: loss:  0.06223641\n",
      "1873 : Training: loss:  0.08265768\n",
      "1874 : Training: loss:  0.08618575\n",
      "1875 : Training: loss:  0.057479065\n",
      "1876 : Training: loss:  0.0719268\n",
      "1877 : Training: loss:  0.088624895\n",
      "1878 : Training: loss:  0.06402596\n",
      "1879 : Training: loss:  0.063875504\n",
      "1880 : Training: loss:  0.084274255\n",
      "Validation: Loss:  0.085260175  Accuracy:  0.78846157\n",
      "1881 : Training: loss:  0.070251636\n",
      "1882 : Training: loss:  0.09721493\n",
      "1883 : Training: loss:  0.060562085\n",
      "1884 : Training: loss:  0.07703415\n",
      "1885 : Training: loss:  0.07779169\n",
      "1886 : Training: loss:  0.08286654\n",
      "1887 : Training: loss:  0.06541638\n",
      "1888 : Training: loss:  0.060709756\n",
      "1889 : Training: loss:  0.07360854\n",
      "1890 : Training: loss:  0.053163264\n",
      "1891 : Training: loss:  0.0852388\n",
      "1892 : Training: loss:  0.07436386\n",
      "1893 : Training: loss:  0.08191719\n",
      "1894 : Training: loss:  0.075197026\n",
      "1895 : Training: loss:  0.073871285\n",
      "1896 : Training: loss:  0.07143514\n",
      "1897 : Training: loss:  0.09072515\n",
      "1898 : Training: loss:  0.056220535\n",
      "1899 : Training: loss:  0.09789519\n",
      "1900 : Training: loss:  0.09581243\n",
      "Validation: Loss:  0.08429251  Accuracy:  0.78846157\n",
      "1901 : Training: loss:  0.08170074\n",
      "1902 : Training: loss:  0.10602811\n",
      "1903 : Training: loss:  0.06376162\n",
      "1904 : Training: loss:  0.07126049\n",
      "1905 : Training: loss:  0.06527956\n",
      "1906 : Training: loss:  0.07046084\n",
      "1907 : Training: loss:  0.07987777\n",
      "1908 : Training: loss:  0.07896247\n",
      "1909 : Training: loss:  0.067828566\n",
      "1910 : Training: loss:  0.086339384\n",
      "1911 : Training: loss:  0.06739575\n",
      "1912 : Training: loss:  0.06760336\n",
      "1913 : Training: loss:  0.0638159\n",
      "1914 : Training: loss:  0.055178102\n",
      "1915 : Training: loss:  0.065501675\n",
      "1916 : Training: loss:  0.09200308\n",
      "1917 : Training: loss:  0.058325894\n",
      "1918 : Training: loss:  0.067927204\n",
      "1919 : Training: loss:  0.07592837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920 : Training: loss:  0.058707118\n",
      "Validation: Loss:  0.0835053  Accuracy:  0.78846157\n",
      "1921 : Training: loss:  0.07510303\n",
      "1922 : Training: loss:  0.07113792\n",
      "1923 : Training: loss:  0.07500252\n",
      "1924 : Training: loss:  0.05172297\n",
      "1925 : Training: loss:  0.061432432\n",
      "1926 : Training: loss:  0.084034\n",
      "1927 : Training: loss:  0.07043492\n",
      "1928 : Training: loss:  0.060442213\n",
      "1929 : Training: loss:  0.041586217\n",
      "1930 : Training: loss:  0.056207635\n",
      "1931 : Training: loss:  0.054038286\n",
      "1932 : Training: loss:  0.066927046\n",
      "1933 : Training: loss:  0.06310915\n",
      "1934 : Training: loss:  0.08719483\n",
      "1935 : Training: loss:  0.072772056\n",
      "1936 : Training: loss:  0.07009022\n",
      "1937 : Training: loss:  0.07173242\n",
      "1938 : Training: loss:  0.0473979\n",
      "1939 : Training: loss:  0.08021974\n",
      "1940 : Training: loss:  0.07852387\n",
      "Validation: Loss:  0.08278147  Accuracy:  0.78846157\n",
      "1941 : Training: loss:  0.07320841\n",
      "1942 : Training: loss:  0.066760145\n",
      "1943 : Training: loss:  0.07750242\n",
      "1944 : Training: loss:  0.06404365\n",
      "1945 : Training: loss:  0.06695009\n",
      "1946 : Training: loss:  0.057574067\n",
      "1947 : Training: loss:  0.059745543\n",
      "1948 : Training: loss:  0.074068606\n",
      "1949 : Training: loss:  0.0635299\n",
      "1950 : Training: loss:  0.07876851\n",
      "1951 : Training: loss:  0.0675761\n",
      "1952 : Training: loss:  0.067448266\n",
      "1953 : Training: loss:  0.067698844\n",
      "1954 : Training: loss:  0.07932819\n",
      "1955 : Training: loss:  0.06823596\n",
      "1956 : Training: loss:  0.07574777\n",
      "1957 : Training: loss:  0.082332134\n",
      "1958 : Training: loss:  0.081216946\n",
      "1959 : Training: loss:  0.08567864\n",
      "1960 : Training: loss:  0.06494356\n",
      "Validation: Loss:  0.08212875  Accuracy:  0.78846157\n",
      "1961 : Training: loss:  0.071350984\n",
      "1962 : Training: loss:  0.09137824\n",
      "1963 : Training: loss:  0.061710138\n",
      "1964 : Training: loss:  0.0675953\n",
      "1965 : Training: loss:  0.08508397\n",
      "1966 : Training: loss:  0.08057893\n",
      "1967 : Training: loss:  0.06088715\n",
      "1968 : Training: loss:  0.062936\n",
      "1969 : Training: loss:  0.053777967\n",
      "1970 : Training: loss:  0.07770525\n",
      "1971 : Training: loss:  0.09359602\n",
      "1972 : Training: loss:  0.06863349\n",
      "1973 : Training: loss:  0.08719491\n",
      "1974 : Training: loss:  0.057630453\n",
      "1975 : Training: loss:  0.057415858\n",
      "1976 : Training: loss:  0.06628639\n",
      "1977 : Training: loss:  0.065618664\n",
      "1978 : Training: loss:  0.07205508\n",
      "1979 : Training: loss:  0.08516384\n",
      "1980 : Training: loss:  0.0883511\n",
      "Validation: Loss:  0.08126384  Accuracy:  0.78846157\n",
      "1981 : Training: loss:  0.05440022\n",
      "1982 : Training: loss:  0.056678146\n",
      "1983 : Training: loss:  0.06801364\n",
      "1984 : Training: loss:  0.07240543\n",
      "1985 : Training: loss:  0.07307964\n",
      "1986 : Training: loss:  0.06335442\n",
      "1987 : Training: loss:  0.07262352\n",
      "1988 : Training: loss:  0.07505023\n",
      "1989 : Training: loss:  0.067922674\n",
      "1990 : Training: loss:  0.07688736\n",
      "1991 : Training: loss:  0.06787166\n",
      "1992 : Training: loss:  0.083818235\n",
      "1993 : Training: loss:  0.072313175\n",
      "1994 : Training: loss:  0.0586983\n",
      "1995 : Training: loss:  0.07117089\n",
      "1996 : Training: loss:  0.07804879\n",
      "1997 : Training: loss:  0.09488989\n",
      "1998 : Training: loss:  0.053888317\n",
      "1999 : Training: loss:  0.0871539\n",
      "2000 : Training: loss:  0.06430317\n",
      "Validation: Loss:  0.08038855  Accuracy:  0.78846157\n",
      "2001 : Training: loss:  0.06351891\n",
      "2002 : Training: loss:  0.07503918\n",
      "2003 : Training: loss:  0.06482277\n",
      "2004 : Training: loss:  0.07957865\n",
      "2005 : Training: loss:  0.061018802\n",
      "2006 : Training: loss:  0.07389327\n",
      "2007 : Training: loss:  0.08391\n",
      "2008 : Training: loss:  0.056034848\n",
      "2009 : Training: loss:  0.074931905\n",
      "2010 : Training: loss:  0.049942475\n",
      "2011 : Training: loss:  0.049083356\n",
      "2012 : Training: loss:  0.056860633\n",
      "2013 : Training: loss:  0.05112057\n",
      "2014 : Training: loss:  0.08129005\n",
      "2015 : Training: loss:  0.05485722\n",
      "2016 : Training: loss:  0.06110005\n",
      "2017 : Training: loss:  0.09617831\n",
      "2018 : Training: loss:  0.06330111\n",
      "2019 : Training: loss:  0.10019287\n",
      "2020 : Training: loss:  0.054928545\n",
      "Validation: Loss:  0.07965796  Accuracy:  0.78846157\n",
      "2021 : Training: loss:  0.07854981\n",
      "2022 : Training: loss:  0.06133682\n",
      "2023 : Training: loss:  0.062452063\n",
      "2024 : Training: loss:  0.07996583\n",
      "2025 : Training: loss:  0.078962736\n",
      "2026 : Training: loss:  0.064854845\n",
      "2027 : Training: loss:  0.08020603\n",
      "2028 : Training: loss:  0.058691487\n",
      "2029 : Training: loss:  0.05276186\n",
      "2030 : Training: loss:  0.05498751\n",
      "2031 : Training: loss:  0.040270027\n",
      "2032 : Training: loss:  0.082265444\n",
      "2033 : Training: loss:  0.060789436\n",
      "2034 : Training: loss:  0.067497745\n",
      "2035 : Training: loss:  0.08355229\n",
      "2036 : Training: loss:  0.072178826\n",
      "2037 : Training: loss:  0.07652955\n",
      "2038 : Training: loss:  0.06623069\n",
      "2039 : Training: loss:  0.059420094\n",
      "2040 : Training: loss:  0.09125441\n",
      "Validation: Loss:  0.07879392  Accuracy:  0.78846157\n",
      "2041 : Training: loss:  0.069558136\n",
      "2042 : Training: loss:  0.08801382\n",
      "2043 : Training: loss:  0.052971117\n",
      "2044 : Training: loss:  0.06988072\n",
      "2045 : Training: loss:  0.05890483\n",
      "2046 : Training: loss:  0.072581604\n",
      "2047 : Training: loss:  0.0608713\n",
      "2048 : Training: loss:  0.058484316\n",
      "2049 : Training: loss:  0.06894744\n",
      "2050 : Training: loss:  0.06128097\n",
      "2051 : Training: loss:  0.087324485\n",
      "2052 : Training: loss:  0.083519965\n",
      "2053 : Training: loss:  0.046698485\n",
      "2054 : Training: loss:  0.049014017\n",
      "2055 : Training: loss:  0.065277375\n",
      "2056 : Training: loss:  0.06460417\n",
      "2057 : Training: loss:  0.07561828\n",
      "2058 : Training: loss:  0.07990371\n",
      "2059 : Training: loss:  0.069095455\n",
      "2060 : Training: loss:  0.049221594\n",
      "Validation: Loss:  0.07802  Accuracy:  0.8076923\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.3359, 0.0076, 0.0093, 0.0191, 0.0042, 0.016...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.07802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.3123, 0.0082, 0.0093, 0.0179, 0.0071, 0.007...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.4299, 0.0351, 0.0106, 0.033, 0.0069, 0.1141...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1051, 0.1534, 0.0082, 0.0105, 0.0254, 0.051...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0261, 0.2287, 0.0332, 0.0073, 0.0277, 0.061...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0034, 0.0293, 0.2998, 0.0059, 0.0233, 0.026...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0198, 0.0093, 0.0125, 0.3151, 0.0322, 0.017...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0121, 0.0071, 0.0202, 0.4869, 0.0169, 0.013...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0474, 0.0085, 0.0242, 0.5536, 0.0104, 0.013...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0374, 0.0613, 0.0044, 0.0269, 0.0849, 0.131...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0335, 0.188, 0.0253, 0.0109, 0.1272, 0.151,...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0406, 0.0504, 0.007, 0.0073, 0.0223, 0.2422...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0218, 0.0494, 0.036, 0.0043, 0.005, 0.0489,...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0895, 0.023, 0.0343, 0.0115, 0.0094, 0.0441...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0273, 0.1276, 0.004, 0.0062, 0.0499, 0.0366...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0416, 0.0117, 0.0019, 0.0456, 0.0272, 0.011...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0303, 0.0102, 0.0561, 0.0636, 0.0061, 0.004...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0146, 0.0146, 0.0527, 0.0168, 0.0074, 0.018...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0193, 0.0169, 0.0471, 0.0045, 0.0505, 0.023...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0217, 0.0223, 0.0362, 0.0045, 0.0469, 0.034...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0328, 0.0203, 0.0132, 0.0079, 0.0117, 0.010...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0211, 0.0251, 0.0238, 0.0314, 0.0541, 0.016...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0122, 0.0426, 0.0144, 0.0182, 0.0164, 0.013...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0053, 0.0107, 0.018, 0.0435, 0.0389, 0.0426...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0024, 0.0104, 0.0338, 0.0333, 0.0327, 0.040...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0152, 0.0119, 0.0206, 0.0764, 0.0422, 0.011...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0075, 0.0054, 0.0158, 0.0473, 0.0257, 0.005...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0038, 0.0423, 0.0107, 0.0074, 0.0325, 0.035...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0016, 0.1177, 0.0441, 0.0439, 0.0846, 0.064...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0046, 0.0463, 0.009, 0.0197, 0.0543, 0.0216...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.357, 0.0322, 0.0132, 0.0171, 0.0347, 0.0607...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0238, 0.0289, 0.0354, 0.0594, 0.0179, 0.021...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.025, 0.0141, 0.0902, 0.1162, 0.0357, 0.0167...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0261, 0.0089, 0.0187, 0.0086, 0.0297, 0.007...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0152, 0.0438, 0.0081, 0.0309, 0.0381, 0.055...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0202, 0.0126, 0.0344, 0.0066, 0.0096, 0.011...</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0246, 0.0352, 0.0077, 0.0135, 0.0044, 0.024...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0261, 0.0126, 0.0063, 0.0266, 0.0062, 0.006...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0084, 0.0183, 0.0296, 0.0167, 0.0047, 0.039...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0145, 0.021, 0.0143, 0.0172, 0.0044, 0.0152...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0104, 0.0114, 0.0136, 0.0632, 0.0024, 0.016...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0095, 0.0141, 0.0172, 0.0316, 0.0057, 0.011...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0111, 0.0109, 0.01, 0.0159, 0.0058, 0.0049,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0256, 0.0158, 0.0124, 0.0036, 0.0344, 0.009...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.015, 0.0197, 0.0333, 0.0145, 0.0149, 0.0047...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.0868, 0.018, 0.021, 0.1549, 0.0498, 0.0217,...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0028, 0.0243, 0.0181, 0.0299, 0.022, 0.0263...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0122, 0.0152, 0.0187, 0.0318, 0.0206, 0.049...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0242, 0.1243, 0.0108, 0.0125, 0.0372, 0.080...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.015, 0.1358, 0.0073, 0.0129, 0.0267, 0.1155...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.325, 0.007, 0.007, 0.016, 0.008, 0.0069, 0....</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0113, 0.014, 0.0144, 0.024, 0.092, 0.0066, ...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.3359, 0.0076, 0.0093, 0.0191, 0.0042, 0.016...               0   \n",
       "1   [0.3123, 0.0082, 0.0093, 0.0179, 0.0071, 0.007...               0   \n",
       "2   [0.4299, 0.0351, 0.0106, 0.033, 0.0069, 0.1141...               0   \n",
       "3   [0.1051, 0.1534, 0.0082, 0.0105, 0.0254, 0.051...               1   \n",
       "4   [0.0261, 0.2287, 0.0332, 0.0073, 0.0277, 0.061...               1   \n",
       "5   [0.0034, 0.0293, 0.2998, 0.0059, 0.0233, 0.026...               2   \n",
       "6   [0.0198, 0.0093, 0.0125, 0.3151, 0.0322, 0.017...               3   \n",
       "7   [0.0121, 0.0071, 0.0202, 0.4869, 0.0169, 0.013...               3   \n",
       "8   [0.0474, 0.0085, 0.0242, 0.5536, 0.0104, 0.013...               3   \n",
       "9   [0.0374, 0.0613, 0.0044, 0.0269, 0.0849, 0.131...               4   \n",
       "10  [0.0335, 0.188, 0.0253, 0.0109, 0.1272, 0.151,...               4   \n",
       "11  [0.0406, 0.0504, 0.007, 0.0073, 0.0223, 0.2422...               5   \n",
       "12  [0.0218, 0.0494, 0.036, 0.0043, 0.005, 0.0489,...               6   \n",
       "13  [0.0895, 0.023, 0.0343, 0.0115, 0.0094, 0.0441...               7   \n",
       "14  [0.0273, 0.1276, 0.004, 0.0062, 0.0499, 0.0366...               8   \n",
       "15  [0.0416, 0.0117, 0.0019, 0.0456, 0.0272, 0.011...               8   \n",
       "16  [0.0303, 0.0102, 0.0561, 0.0636, 0.0061, 0.004...               9   \n",
       "17  [0.0146, 0.0146, 0.0527, 0.0168, 0.0074, 0.018...               9   \n",
       "18  [0.0193, 0.0169, 0.0471, 0.0045, 0.0505, 0.023...              10   \n",
       "19  [0.0217, 0.0223, 0.0362, 0.0045, 0.0469, 0.034...              10   \n",
       "20  [0.0328, 0.0203, 0.0132, 0.0079, 0.0117, 0.010...              11   \n",
       "21  [0.0211, 0.0251, 0.0238, 0.0314, 0.0541, 0.016...              11   \n",
       "22  [0.0122, 0.0426, 0.0144, 0.0182, 0.0164, 0.013...              12   \n",
       "23  [0.0053, 0.0107, 0.018, 0.0435, 0.0389, 0.0426...              13   \n",
       "24  [0.0024, 0.0104, 0.0338, 0.0333, 0.0327, 0.040...              13   \n",
       "25  [0.0152, 0.0119, 0.0206, 0.0764, 0.0422, 0.011...              14   \n",
       "26  [0.0075, 0.0054, 0.0158, 0.0473, 0.0257, 0.005...              14   \n",
       "27  [0.0038, 0.0423, 0.0107, 0.0074, 0.0325, 0.035...              15   \n",
       "28  [0.0016, 0.1177, 0.0441, 0.0439, 0.0846, 0.064...              15   \n",
       "29  [0.0046, 0.0463, 0.009, 0.0197, 0.0543, 0.0216...              15   \n",
       "30  [0.357, 0.0322, 0.0132, 0.0171, 0.0347, 0.0607...              16   \n",
       "31  [0.0238, 0.0289, 0.0354, 0.0594, 0.0179, 0.021...              17   \n",
       "32  [0.025, 0.0141, 0.0902, 0.1162, 0.0357, 0.0167...              17   \n",
       "33  [0.0261, 0.0089, 0.0187, 0.0086, 0.0297, 0.007...              18   \n",
       "34  [0.0152, 0.0438, 0.0081, 0.0309, 0.0381, 0.055...              19   \n",
       "35  [0.0202, 0.0126, 0.0344, 0.0066, 0.0096, 0.011...              20   \n",
       "36  [0.0246, 0.0352, 0.0077, 0.0135, 0.0044, 0.024...              21   \n",
       "37  [0.0261, 0.0126, 0.0063, 0.0266, 0.0062, 0.006...              21   \n",
       "38  [0.0084, 0.0183, 0.0296, 0.0167, 0.0047, 0.039...              22   \n",
       "39  [0.0145, 0.021, 0.0143, 0.0172, 0.0044, 0.0152...              22   \n",
       "40  [0.0104, 0.0114, 0.0136, 0.0632, 0.0024, 0.016...              22   \n",
       "41  [0.0095, 0.0141, 0.0172, 0.0316, 0.0057, 0.011...              22   \n",
       "42  [0.0111, 0.0109, 0.01, 0.0159, 0.0058, 0.0049,...              23   \n",
       "43  [0.0256, 0.0158, 0.0124, 0.0036, 0.0344, 0.009...              23   \n",
       "44  [0.015, 0.0197, 0.0333, 0.0145, 0.0149, 0.0047...              23   \n",
       "45  [0.0868, 0.018, 0.021, 0.1549, 0.0498, 0.0217,...              23   \n",
       "46  [0.0028, 0.0243, 0.0181, 0.0299, 0.022, 0.0263...              24   \n",
       "47  [0.0122, 0.0152, 0.0187, 0.0318, 0.0206, 0.049...              24   \n",
       "48  [0.0242, 0.1243, 0.0108, 0.0125, 0.0372, 0.080...              25   \n",
       "49  [0.015, 0.1358, 0.0073, 0.0129, 0.0267, 0.1155...              25   \n",
       "50  [0.325, 0.007, 0.007, 0.016, 0.008, 0.0069, 0....              26   \n",
       "51  [0.0113, 0.014, 0.0144, 0.024, 0.092, 0.0066, ...              26   \n",
       "\n",
       "    Predicted labels  Accuracy     Loss  \n",
       "0                  0  0.807692  0.07802  \n",
       "1                  0       NaN      NaN  \n",
       "2                  0       NaN      NaN  \n",
       "3                  1       NaN      NaN  \n",
       "4                  1       NaN      NaN  \n",
       "5                  2       NaN      NaN  \n",
       "6                  3       NaN      NaN  \n",
       "7                  3       NaN      NaN  \n",
       "8                  3       NaN      NaN  \n",
       "9                 25       NaN      NaN  \n",
       "10                 1       NaN      NaN  \n",
       "11                 5       NaN      NaN  \n",
       "12                 6       NaN      NaN  \n",
       "13                 9       NaN      NaN  \n",
       "14                 8       NaN      NaN  \n",
       "15                 8       NaN      NaN  \n",
       "16                 9       NaN      NaN  \n",
       "17                 9       NaN      NaN  \n",
       "18                10       NaN      NaN  \n",
       "19                10       NaN      NaN  \n",
       "20                 8       NaN      NaN  \n",
       "21                 8       NaN      NaN  \n",
       "22                12       NaN      NaN  \n",
       "23                13       NaN      NaN  \n",
       "24                13       NaN      NaN  \n",
       "25                14       NaN      NaN  \n",
       "26                14       NaN      NaN  \n",
       "27                15       NaN      NaN  \n",
       "28                15       NaN      NaN  \n",
       "29                15       NaN      NaN  \n",
       "30                16       NaN      NaN  \n",
       "31                17       NaN      NaN  \n",
       "32                17       NaN      NaN  \n",
       "33                18       NaN      NaN  \n",
       "34                19       NaN      NaN  \n",
       "35                22       NaN      NaN  \n",
       "36                22       NaN      NaN  \n",
       "37                22       NaN      NaN  \n",
       "38                22       NaN      NaN  \n",
       "39                22       NaN      NaN  \n",
       "40                22       NaN      NaN  \n",
       "41                22       NaN      NaN  \n",
       "42                23       NaN      NaN  \n",
       "43                 8       NaN      NaN  \n",
       "44                23       NaN      NaN  \n",
       "45                23       NaN      NaN  \n",
       "46                24       NaN      NaN  \n",
       "47                24       NaN      NaN  \n",
       "48                25       NaN      NaN  \n",
       "49                25       NaN      NaN  \n",
       "50                 0       NaN      NaN  \n",
       "51                26       NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2061 : Training: loss:  0.07365544\n",
      "2062 : Training: loss:  0.042344384\n",
      "2063 : Training: loss:  0.06205394\n",
      "2064 : Training: loss:  0.071217075\n",
      "2065 : Training: loss:  0.090179764\n",
      "2066 : Training: loss:  0.039167862\n",
      "2067 : Training: loss:  0.046500262\n",
      "2068 : Training: loss:  0.06266416\n",
      "2069 : Training: loss:  0.06919453\n",
      "2070 : Training: loss:  0.101006374\n",
      "2071 : Training: loss:  0.06536962\n",
      "2072 : Training: loss:  0.042703345\n",
      "2073 : Training: loss:  0.061082624\n",
      "2074 : Training: loss:  0.09953552\n",
      "2075 : Training: loss:  0.072613224\n",
      "2076 : Training: loss:  0.053896405\n",
      "2077 : Training: loss:  0.075838216\n",
      "2078 : Training: loss:  0.06021789\n",
      "2079 : Training: loss:  0.06432293\n",
      "2080 : Training: loss:  0.06960558\n",
      "Validation: Loss:  0.07716868  Accuracy:  0.8076923\n",
      "2081 : Training: loss:  0.06360584\n",
      "2082 : Training: loss:  0.053280685\n",
      "2083 : Training: loss:  0.05031139\n",
      "2084 : Training: loss:  0.062392756\n",
      "2085 : Training: loss:  0.068193704\n",
      "2086 : Training: loss:  0.08092627\n",
      "2087 : Training: loss:  0.09414982\n",
      "2088 : Training: loss:  0.071900785\n",
      "2089 : Training: loss:  0.06828623\n",
      "2090 : Training: loss:  0.04985354\n",
      "2091 : Training: loss:  0.05021097\n",
      "2092 : Training: loss:  0.06427647\n",
      "2093 : Training: loss:  0.05370608\n",
      "2094 : Training: loss:  0.068430275\n",
      "2095 : Training: loss:  0.060124565\n",
      "2096 : Training: loss:  0.047407523\n",
      "2097 : Training: loss:  0.049020782\n",
      "2098 : Training: loss:  0.072758995\n",
      "2099 : Training: loss:  0.04982769\n",
      "2100 : Training: loss:  0.057294223\n",
      "Validation: Loss:  0.076468155  Accuracy:  0.8076923\n",
      "2101 : Training: loss:  0.0553475\n",
      "2102 : Training: loss:  0.06798768\n",
      "2103 : Training: loss:  0.07806844\n",
      "2104 : Training: loss:  0.054744776\n",
      "2105 : Training: loss:  0.07346445\n",
      "2106 : Training: loss:  0.04127652\n",
      "2107 : Training: loss:  0.0994536\n",
      "2108 : Training: loss:  0.05804221\n",
      "2109 : Training: loss:  0.061003525\n",
      "2110 : Training: loss:  0.068639\n",
      "2111 : Training: loss:  0.059602745\n",
      "2112 : Training: loss:  0.07007843\n",
      "2113 : Training: loss:  0.06336309\n",
      "2114 : Training: loss:  0.08056744\n",
      "2115 : Training: loss:  0.074574605\n",
      "2116 : Training: loss:  0.0843859\n",
      "2117 : Training: loss:  0.06504039\n",
      "2118 : Training: loss:  0.090293\n",
      "2119 : Training: loss:  0.06941036\n",
      "2120 : Training: loss:  0.05693111\n",
      "Validation: Loss:  0.07573612  Accuracy:  0.8076923\n",
      "2121 : Training: loss:  0.050553925\n",
      "2122 : Training: loss:  0.053474355\n",
      "2123 : Training: loss:  0.057924166\n",
      "2124 : Training: loss:  0.0728963\n",
      "2125 : Training: loss:  0.06318477\n",
      "2126 : Training: loss:  0.07179707\n",
      "2127 : Training: loss:  0.08144068\n",
      "2128 : Training: loss:  0.06427239\n",
      "2129 : Training: loss:  0.06308354\n",
      "2130 : Training: loss:  0.052205548\n",
      "2131 : Training: loss:  0.06471855\n",
      "2132 : Training: loss:  0.072906986\n",
      "2133 : Training: loss:  0.054113336\n",
      "2134 : Training: loss:  0.077407934\n",
      "2135 : Training: loss:  0.07847455\n",
      "2136 : Training: loss:  0.077678725\n",
      "2137 : Training: loss:  0.05785129\n",
      "2138 : Training: loss:  0.06388354\n",
      "2139 : Training: loss:  0.07711328\n",
      "2140 : Training: loss:  0.0769234\n",
      "Validation: Loss:  0.07507548  Accuracy:  0.8269231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.3677, 0.0067, 0.0078, 0.0174, 0.004, 0.0145...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.075075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.3481, 0.0074, 0.0079, 0.0169, 0.0073, 0.006...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.4708, 0.0325, 0.0088, 0.0317, 0.0067, 0.111...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1125, 0.1523, 0.0068, 0.0092, 0.0279, 0.047...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0258, 0.2205, 0.0288, 0.0063, 0.0326, 0.056...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0031, 0.0275, 0.3138, 0.0052, 0.025, 0.0253...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0185, 0.0083, 0.0108, 0.346, 0.0379, 0.0154...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0105, 0.006, 0.0172, 0.5093, 0.0185, 0.0114...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0454, 0.0072, 0.0206, 0.5778, 0.0103, 0.011...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0358, 0.0574, 0.0035, 0.0255, 0.1044, 0.125...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0332, 0.1782, 0.0215, 0.0095, 0.1639, 0.144...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0375, 0.047, 0.0055, 0.0061, 0.0252, 0.2442...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0214, 0.0444, 0.0334, 0.0037, 0.0046, 0.045...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0949, 0.0215, 0.0318, 0.0105, 0.0101, 0.042...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0272, 0.117, 0.0031, 0.0054, 0.0592, 0.0315...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0395, 0.0101, 0.0015, 0.0424, 0.031, 0.0092...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0307, 0.0093, 0.0526, 0.0627, 0.0064, 0.003...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0143, 0.0137, 0.051, 0.0151, 0.0083, 0.0167...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0177, 0.0145, 0.042, 0.0037, 0.057, 0.0201,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0199, 0.0194, 0.0318, 0.0036, 0.0525, 0.030...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0345, 0.0182, 0.0119, 0.0074, 0.0115, 0.009...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0208, 0.0223, 0.0201, 0.0309, 0.0639, 0.014...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0122, 0.0405, 0.0128, 0.0175, 0.018, 0.0123...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0047, 0.0094, 0.0161, 0.0439, 0.0452, 0.039...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.002, 0.0089, 0.0307, 0.0316, 0.0368, 0.0377...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0138, 0.01, 0.0179, 0.0762, 0.0499, 0.0091,...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0068, 0.0047, 0.0143, 0.0471, 0.0274, 0.004...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0034, 0.042, 0.0094, 0.0064, 0.0371, 0.0331...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0013, 0.1135, 0.0403, 0.0402, 0.1037, 0.060...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.004, 0.043, 0.0075, 0.0176, 0.0665, 0.019, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.3691, 0.0291, 0.0111, 0.0158, 0.0366, 0.056...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.026, 0.0274, 0.0325, 0.0625, 0.0194, 0.0199...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.026, 0.0121, 0.0836, 0.1258, 0.0394, 0.0145...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0258, 0.0078, 0.0174, 0.0078, 0.0322, 0.006...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.013, 0.0369, 0.0065, 0.0283, 0.0428, 0.0453...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.02, 0.0115, 0.0328, 0.0058, 0.0093, 0.0111,...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0237, 0.0317, 0.0065, 0.0117, 0.0042, 0.023...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0268, 0.0113, 0.0054, 0.0256, 0.0059, 0.006...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0078, 0.0169, 0.0282, 0.0158, 0.0045, 0.039...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.014, 0.0196, 0.0125, 0.0154, 0.0044, 0.0142...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0095, 0.0104, 0.0121, 0.0591, 0.0024, 0.015...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0086, 0.0126, 0.0154, 0.0292, 0.0054, 0.010...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.01, 0.0096, 0.009, 0.0146, 0.0055, 0.0043, ...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0242, 0.0134, 0.0112, 0.0031, 0.034, 0.0079...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0142, 0.0177, 0.0296, 0.0133, 0.0164, 0.004...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.0876, 0.0165, 0.0184, 0.1639, 0.0545, 0.019...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0024, 0.0218, 0.0164, 0.0308, 0.025, 0.0248...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0114, 0.0135, 0.0166, 0.0319, 0.0223, 0.048...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0228, 0.1193, 0.0089, 0.0109, 0.0433, 0.075...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0133, 0.13, 0.0059, 0.0111, 0.0312, 0.1107,...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.3614, 0.0061, 0.0058, 0.0147, 0.0081, 0.005...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0113, 0.0126, 0.0125, 0.0238, 0.1206, 0.005...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.3677, 0.0067, 0.0078, 0.0174, 0.004, 0.0145...               0   \n",
       "1   [0.3481, 0.0074, 0.0079, 0.0169, 0.0073, 0.006...               0   \n",
       "2   [0.4708, 0.0325, 0.0088, 0.0317, 0.0067, 0.111...               0   \n",
       "3   [0.1125, 0.1523, 0.0068, 0.0092, 0.0279, 0.047...               1   \n",
       "4   [0.0258, 0.2205, 0.0288, 0.0063, 0.0326, 0.056...               1   \n",
       "5   [0.0031, 0.0275, 0.3138, 0.0052, 0.025, 0.0253...               2   \n",
       "6   [0.0185, 0.0083, 0.0108, 0.346, 0.0379, 0.0154...               3   \n",
       "7   [0.0105, 0.006, 0.0172, 0.5093, 0.0185, 0.0114...               3   \n",
       "8   [0.0454, 0.0072, 0.0206, 0.5778, 0.0103, 0.011...               3   \n",
       "9   [0.0358, 0.0574, 0.0035, 0.0255, 0.1044, 0.125...               4   \n",
       "10  [0.0332, 0.1782, 0.0215, 0.0095, 0.1639, 0.144...               4   \n",
       "11  [0.0375, 0.047, 0.0055, 0.0061, 0.0252, 0.2442...               5   \n",
       "12  [0.0214, 0.0444, 0.0334, 0.0037, 0.0046, 0.045...               6   \n",
       "13  [0.0949, 0.0215, 0.0318, 0.0105, 0.0101, 0.042...               7   \n",
       "14  [0.0272, 0.117, 0.0031, 0.0054, 0.0592, 0.0315...               8   \n",
       "15  [0.0395, 0.0101, 0.0015, 0.0424, 0.031, 0.0092...               8   \n",
       "16  [0.0307, 0.0093, 0.0526, 0.0627, 0.0064, 0.003...               9   \n",
       "17  [0.0143, 0.0137, 0.051, 0.0151, 0.0083, 0.0167...               9   \n",
       "18  [0.0177, 0.0145, 0.042, 0.0037, 0.057, 0.0201,...              10   \n",
       "19  [0.0199, 0.0194, 0.0318, 0.0036, 0.0525, 0.030...              10   \n",
       "20  [0.0345, 0.0182, 0.0119, 0.0074, 0.0115, 0.009...              11   \n",
       "21  [0.0208, 0.0223, 0.0201, 0.0309, 0.0639, 0.014...              11   \n",
       "22  [0.0122, 0.0405, 0.0128, 0.0175, 0.018, 0.0123...              12   \n",
       "23  [0.0047, 0.0094, 0.0161, 0.0439, 0.0452, 0.039...              13   \n",
       "24  [0.002, 0.0089, 0.0307, 0.0316, 0.0368, 0.0377...              13   \n",
       "25  [0.0138, 0.01, 0.0179, 0.0762, 0.0499, 0.0091,...              14   \n",
       "26  [0.0068, 0.0047, 0.0143, 0.0471, 0.0274, 0.004...              14   \n",
       "27  [0.0034, 0.042, 0.0094, 0.0064, 0.0371, 0.0331...              15   \n",
       "28  [0.0013, 0.1135, 0.0403, 0.0402, 0.1037, 0.060...              15   \n",
       "29  [0.004, 0.043, 0.0075, 0.0176, 0.0665, 0.019, ...              15   \n",
       "30  [0.3691, 0.0291, 0.0111, 0.0158, 0.0366, 0.056...              16   \n",
       "31  [0.026, 0.0274, 0.0325, 0.0625, 0.0194, 0.0199...              17   \n",
       "32  [0.026, 0.0121, 0.0836, 0.1258, 0.0394, 0.0145...              17   \n",
       "33  [0.0258, 0.0078, 0.0174, 0.0078, 0.0322, 0.006...              18   \n",
       "34  [0.013, 0.0369, 0.0065, 0.0283, 0.0428, 0.0453...              19   \n",
       "35  [0.02, 0.0115, 0.0328, 0.0058, 0.0093, 0.0111,...              20   \n",
       "36  [0.0237, 0.0317, 0.0065, 0.0117, 0.0042, 0.023...              21   \n",
       "37  [0.0268, 0.0113, 0.0054, 0.0256, 0.0059, 0.006...              21   \n",
       "38  [0.0078, 0.0169, 0.0282, 0.0158, 0.0045, 0.039...              22   \n",
       "39  [0.014, 0.0196, 0.0125, 0.0154, 0.0044, 0.0142...              22   \n",
       "40  [0.0095, 0.0104, 0.0121, 0.0591, 0.0024, 0.015...              22   \n",
       "41  [0.0086, 0.0126, 0.0154, 0.0292, 0.0054, 0.010...              22   \n",
       "42  [0.01, 0.0096, 0.009, 0.0146, 0.0055, 0.0043, ...              23   \n",
       "43  [0.0242, 0.0134, 0.0112, 0.0031, 0.034, 0.0079...              23   \n",
       "44  [0.0142, 0.0177, 0.0296, 0.0133, 0.0164, 0.004...              23   \n",
       "45  [0.0876, 0.0165, 0.0184, 0.1639, 0.0545, 0.019...              23   \n",
       "46  [0.0024, 0.0218, 0.0164, 0.0308, 0.025, 0.0248...              24   \n",
       "47  [0.0114, 0.0135, 0.0166, 0.0319, 0.0223, 0.048...              24   \n",
       "48  [0.0228, 0.1193, 0.0089, 0.0109, 0.0433, 0.075...              25   \n",
       "49  [0.0133, 0.13, 0.0059, 0.0111, 0.0312, 0.1107,...              25   \n",
       "50  [0.3614, 0.0061, 0.0058, 0.0147, 0.0081, 0.005...              26   \n",
       "51  [0.0113, 0.0126, 0.0125, 0.0238, 0.1206, 0.005...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.826923  0.075075  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                  1       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                  2       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                 25       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 8       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                16       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                20       NaN       NaN  \n",
       "36                22       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2141 : Training: loss:  0.057894967\n",
      "2142 : Training: loss:  0.0576977\n",
      "2143 : Training: loss:  0.079774104\n",
      "2144 : Training: loss:  0.08131119\n",
      "2145 : Training: loss:  0.050671242\n",
      "2146 : Training: loss:  0.087830275\n",
      "2147 : Training: loss:  0.047147565\n",
      "2148 : Training: loss:  0.050317112\n",
      "2149 : Training: loss:  0.05544514\n",
      "2150 : Training: loss:  0.06766272\n",
      "2151 : Training: loss:  0.07367924\n",
      "2152 : Training: loss:  0.08863945\n",
      "2153 : Training: loss:  0.052020147\n",
      "2154 : Training: loss:  0.06726853\n",
      "2155 : Training: loss:  0.049528334\n",
      "2156 : Training: loss:  0.056865815\n",
      "2157 : Training: loss:  0.080082655\n",
      "2158 : Training: loss:  0.058287796\n",
      "2159 : Training: loss:  0.06368173\n",
      "2160 : Training: loss:  0.0631949\n",
      "Validation: Loss:  0.074367456  Accuracy:  0.8269231\n",
      "2161 : Training: loss:  0.05049102\n",
      "2162 : Training: loss:  0.058542013\n",
      "2163 : Training: loss:  0.07769238\n",
      "2164 : Training: loss:  0.055634014\n",
      "2165 : Training: loss:  0.05966219\n",
      "2166 : Training: loss:  0.07332116\n",
      "2167 : Training: loss:  0.060817964\n",
      "2168 : Training: loss:  0.059046652\n",
      "2169 : Training: loss:  0.073201\n",
      "2170 : Training: loss:  0.06890538\n",
      "2171 : Training: loss:  0.07464782\n",
      "2172 : Training: loss:  0.06804713\n",
      "2173 : Training: loss:  0.04907251\n",
      "2174 : Training: loss:  0.056371577\n",
      "2175 : Training: loss:  0.071125686\n",
      "2176 : Training: loss:  0.06826714\n",
      "2177 : Training: loss:  0.052696437\n",
      "2178 : Training: loss:  0.07510746\n",
      "2179 : Training: loss:  0.055618532\n",
      "2180 : Training: loss:  0.044818692\n",
      "Validation: Loss:  0.073706865  Accuracy:  0.8269231\n",
      "2181 : Training: loss:  0.07632395\n",
      "2182 : Training: loss:  0.06260111\n",
      "2183 : Training: loss:  0.061679274\n",
      "2184 : Training: loss:  0.04742034\n",
      "2185 : Training: loss:  0.056466486\n",
      "2186 : Training: loss:  0.05342006\n",
      "2187 : Training: loss:  0.058701772\n",
      "2188 : Training: loss:  0.07892143\n",
      "2189 : Training: loss:  0.05357222\n",
      "2190 : Training: loss:  0.052611597\n",
      "2191 : Training: loss:  0.075998224\n",
      "2192 : Training: loss:  0.05691703\n",
      "2193 : Training: loss:  0.04599933\n",
      "2194 : Training: loss:  0.05653943\n",
      "2195 : Training: loss:  0.06026658\n",
      "2196 : Training: loss:  0.05588076\n",
      "2197 : Training: loss:  0.055064913\n",
      "2198 : Training: loss:  0.063695416\n",
      "2199 : Training: loss:  0.047964707\n",
      "2200 : Training: loss:  0.055412944\n",
      "Validation: Loss:  0.0730237  Accuracy:  0.8269231\n",
      "2201 : Training: loss:  0.038421914\n",
      "2202 : Training: loss:  0.049484495\n",
      "2203 : Training: loss:  0.063233815\n",
      "2204 : Training: loss:  0.057744667\n",
      "2205 : Training: loss:  0.049512926\n",
      "2206 : Training: loss:  0.04746649\n",
      "2207 : Training: loss:  0.08490822\n",
      "2208 : Training: loss:  0.063761644\n",
      "2209 : Training: loss:  0.04868795\n",
      "2210 : Training: loss:  0.072541796\n",
      "2211 : Training: loss:  0.077532105\n",
      "2212 : Training: loss:  0.045666266\n",
      "2213 : Training: loss:  0.050805546\n",
      "2214 : Training: loss:  0.07672488\n",
      "2215 : Training: loss:  0.068180546\n",
      "2216 : Training: loss:  0.060989212\n",
      "2217 : Training: loss:  0.05787185\n",
      "2218 : Training: loss:  0.057382878\n",
      "2219 : Training: loss:  0.065273315\n",
      "2220 : Training: loss:  0.06609162\n",
      "Validation: Loss:  0.07235333  Accuracy:  0.8269231\n",
      "2221 : Training: loss:  0.06125493\n",
      "2222 : Training: loss:  0.053310014\n",
      "2223 : Training: loss:  0.0620454\n",
      "2224 : Training: loss:  0.075448476\n",
      "2225 : Training: loss:  0.04984873\n",
      "2226 : Training: loss:  0.057848264\n",
      "2227 : Training: loss:  0.04928601\n",
      "2228 : Training: loss:  0.06183679\n",
      "2229 : Training: loss:  0.05443321\n",
      "2230 : Training: loss:  0.059639405\n",
      "2231 : Training: loss:  0.08141342\n",
      "2232 : Training: loss:  0.034774907\n",
      "2233 : Training: loss:  0.049488932\n",
      "2234 : Training: loss:  0.055506963\n",
      "2235 : Training: loss:  0.07619749\n",
      "2236 : Training: loss:  0.07475298\n",
      "2237 : Training: loss:  0.070110716\n",
      "2238 : Training: loss:  0.051729113\n",
      "2239 : Training: loss:  0.050409414\n",
      "2240 : Training: loss:  0.06822567\n",
      "Validation: Loss:  0.071630225  Accuracy:  0.8269231\n",
      "2241 : Training: loss:  0.054864917\n",
      "2242 : Training: loss:  0.07996664\n",
      "2243 : Training: loss:  0.056151867\n",
      "2244 : Training: loss:  0.06063113\n",
      "2245 : Training: loss:  0.05321723\n",
      "2246 : Training: loss:  0.06452567\n",
      "2247 : Training: loss:  0.06672528\n",
      "2248 : Training: loss:  0.06769235\n",
      "2249 : Training: loss:  0.08259014\n",
      "2250 : Training: loss:  0.054157633\n",
      "2251 : Training: loss:  0.048142638\n",
      "2252 : Training: loss:  0.06138177\n",
      "2253 : Training: loss:  0.04931562\n",
      "2254 : Training: loss:  0.075925246\n",
      "2255 : Training: loss:  0.056666467\n",
      "2256 : Training: loss:  0.07773186\n",
      "2257 : Training: loss:  0.061150316\n",
      "2258 : Training: loss:  0.045724414\n",
      "2259 : Training: loss:  0.05017293\n",
      "2260 : Training: loss:  0.04453067\n",
      "Validation: Loss:  0.070865825  Accuracy:  0.8269231\n",
      "2261 : Training: loss:  0.05992349\n",
      "2262 : Training: loss:  0.06669004\n",
      "2263 : Training: loss:  0.05465243\n",
      "2264 : Training: loss:  0.060132343\n",
      "2265 : Training: loss:  0.07785518\n",
      "2266 : Training: loss:  0.040711436\n",
      "2267 : Training: loss:  0.05547099\n",
      "2268 : Training: loss:  0.078786954\n",
      "2269 : Training: loss:  0.07437142\n",
      "2270 : Training: loss:  0.054972548\n",
      "2271 : Training: loss:  0.03880489\n",
      "2272 : Training: loss:  0.06525932\n",
      "2273 : Training: loss:  0.056738425\n",
      "2274 : Training: loss:  0.06484197\n",
      "2275 : Training: loss:  0.049819686\n",
      "2276 : Training: loss:  0.05952932\n",
      "2277 : Training: loss:  0.070402324\n",
      "2278 : Training: loss:  0.055261355\n",
      "2279 : Training: loss:  0.07405362\n",
      "2280 : Training: loss:  0.05086269\n",
      "Validation: Loss:  0.07041497  Accuracy:  0.84615386\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.3848, 0.0065, 0.006, 0.0136, 0.003, 0.0111,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.070415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.3766, 0.0078, 0.0065, 0.0129, 0.0056, 0.005...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.512, 0.036, 0.0065, 0.0251, 0.0051, 0.1091,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1162, 0.2176, 0.0058, 0.0074, 0.0253, 0.046...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.024, 0.2852, 0.0248, 0.0046, 0.0281, 0.0545...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0025, 0.0287, 0.3887, 0.0037, 0.0209, 0.023...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0151, 0.0079, 0.0087, 0.3605, 0.0347, 0.013...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.008, 0.0054, 0.0149, 0.5213, 0.0163, 0.0091...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0406, 0.0071, 0.0176, 0.596, 0.0082, 0.0089...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0334, 0.069, 0.0025, 0.022, 0.0972, 0.1327,...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0333, 0.2382, 0.0181, 0.0076, 0.1587, 0.156...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0335, 0.0516, 0.0041, 0.0044, 0.0214, 0.256...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0188, 0.0492, 0.037, 0.0027, 0.0036, 0.0445...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0915, 0.0215, 0.0284, 0.0079, 0.0078, 0.036...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0238, 0.1365, 0.0023, 0.0041, 0.0536, 0.026...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0336, 0.0099, 0.001, 0.0341, 0.0276, 0.0071...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0251, 0.0096, 0.0525, 0.0488, 0.005, 0.003,...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0111, 0.0139, 0.0516, 0.0103, 0.0066, 0.014...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0147, 0.0139, 0.0427, 0.0026, 0.0482, 0.016...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0167, 0.0196, 0.0312, 0.0025, 0.0432, 0.025...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0296, 0.0176, 0.0103, 0.006, 0.0094, 0.0068...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0176, 0.0252, 0.0196, 0.0288, 0.0649, 0.012...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0102, 0.0469, 0.0112, 0.014, 0.0146, 0.0103...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0036, 0.0085, 0.0151, 0.0367, 0.0387, 0.037...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0015, 0.0081, 0.0328, 0.0276, 0.0324, 0.036...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0108, 0.0094, 0.0164, 0.0726, 0.047, 0.0071...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0051, 0.0042, 0.0131, 0.0428, 0.0247, 0.003...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0025, 0.0491, 0.0083, 0.0049, 0.0329, 0.03,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0009, 0.1352, 0.0402, 0.0342, 0.1033, 0.06,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0031, 0.051, 0.0065, 0.014, 0.0655, 0.0173,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.391, 0.0316, 0.0098, 0.0134, 0.0326, 0.0498...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0221, 0.0291, 0.0294, 0.0572, 0.0157, 0.016...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0238, 0.0125, 0.09, 0.1239, 0.0352, 0.0128,...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0207, 0.0066, 0.015, 0.0059, 0.0251, 0.0041...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0097, 0.0369, 0.0052, 0.0242, 0.0375, 0.038...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0188, 0.0114, 0.0364, 0.0044, 0.0069, 0.009...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0232, 0.0385, 0.006, 0.0094, 0.0033, 0.0228...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0268, 0.0123, 0.0053, 0.0237, 0.0047, 0.004...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0068, 0.0176, 0.0331, 0.0135, 0.0034, 0.04,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0128, 0.0237, 0.0127, 0.0132, 0.0035, 0.013...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0086, 0.0115, 0.0121, 0.0486, 0.0018, 0.014...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0075, 0.0141, 0.016, 0.0252, 0.0042, 0.0096...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0079, 0.009, 0.0083, 0.0115, 0.0041, 0.0032...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0225, 0.0129, 0.0115, 0.0025, 0.0309, 0.006...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0125, 0.0207, 0.0345, 0.0112, 0.0149, 0.003...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.0851, 0.0172, 0.0162, 0.169, 0.0507, 0.0171...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0018, 0.022, 0.0172, 0.0283, 0.0211, 0.0238...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0099, 0.0133, 0.016, 0.029, 0.0193, 0.049, ...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0189, 0.1426, 0.0074, 0.009, 0.0397, 0.0707...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0102, 0.1457, 0.0047, 0.0087, 0.0271, 0.103...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.3808, 0.0058, 0.0046, 0.0112, 0.0059, 0.004...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0092, 0.0131, 0.011, 0.0202, 0.1138, 0.0044...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.3848, 0.0065, 0.006, 0.0136, 0.003, 0.0111,...               0   \n",
       "1   [0.3766, 0.0078, 0.0065, 0.0129, 0.0056, 0.005...               0   \n",
       "2   [0.512, 0.036, 0.0065, 0.0251, 0.0051, 0.1091,...               0   \n",
       "3   [0.1162, 0.2176, 0.0058, 0.0074, 0.0253, 0.046...               1   \n",
       "4   [0.024, 0.2852, 0.0248, 0.0046, 0.0281, 0.0545...               1   \n",
       "5   [0.0025, 0.0287, 0.3887, 0.0037, 0.0209, 0.023...               2   \n",
       "6   [0.0151, 0.0079, 0.0087, 0.3605, 0.0347, 0.013...               3   \n",
       "7   [0.008, 0.0054, 0.0149, 0.5213, 0.0163, 0.0091...               3   \n",
       "8   [0.0406, 0.0071, 0.0176, 0.596, 0.0082, 0.0089...               3   \n",
       "9   [0.0334, 0.069, 0.0025, 0.022, 0.0972, 0.1327,...               4   \n",
       "10  [0.0333, 0.2382, 0.0181, 0.0076, 0.1587, 0.156...               4   \n",
       "11  [0.0335, 0.0516, 0.0041, 0.0044, 0.0214, 0.256...               5   \n",
       "12  [0.0188, 0.0492, 0.037, 0.0027, 0.0036, 0.0445...               6   \n",
       "13  [0.0915, 0.0215, 0.0284, 0.0079, 0.0078, 0.036...               7   \n",
       "14  [0.0238, 0.1365, 0.0023, 0.0041, 0.0536, 0.026...               8   \n",
       "15  [0.0336, 0.0099, 0.001, 0.0341, 0.0276, 0.0071...               8   \n",
       "16  [0.0251, 0.0096, 0.0525, 0.0488, 0.005, 0.003,...               9   \n",
       "17  [0.0111, 0.0139, 0.0516, 0.0103, 0.0066, 0.014...               9   \n",
       "18  [0.0147, 0.0139, 0.0427, 0.0026, 0.0482, 0.016...              10   \n",
       "19  [0.0167, 0.0196, 0.0312, 0.0025, 0.0432, 0.025...              10   \n",
       "20  [0.0296, 0.0176, 0.0103, 0.006, 0.0094, 0.0068...              11   \n",
       "21  [0.0176, 0.0252, 0.0196, 0.0288, 0.0649, 0.012...              11   \n",
       "22  [0.0102, 0.0469, 0.0112, 0.014, 0.0146, 0.0103...              12   \n",
       "23  [0.0036, 0.0085, 0.0151, 0.0367, 0.0387, 0.037...              13   \n",
       "24  [0.0015, 0.0081, 0.0328, 0.0276, 0.0324, 0.036...              13   \n",
       "25  [0.0108, 0.0094, 0.0164, 0.0726, 0.047, 0.0071...              14   \n",
       "26  [0.0051, 0.0042, 0.0131, 0.0428, 0.0247, 0.003...              14   \n",
       "27  [0.0025, 0.0491, 0.0083, 0.0049, 0.0329, 0.03,...              15   \n",
       "28  [0.0009, 0.1352, 0.0402, 0.0342, 0.1033, 0.06,...              15   \n",
       "29  [0.0031, 0.051, 0.0065, 0.014, 0.0655, 0.0173,...              15   \n",
       "30  [0.391, 0.0316, 0.0098, 0.0134, 0.0326, 0.0498...              16   \n",
       "31  [0.0221, 0.0291, 0.0294, 0.0572, 0.0157, 0.016...              17   \n",
       "32  [0.0238, 0.0125, 0.09, 0.1239, 0.0352, 0.0128,...              17   \n",
       "33  [0.0207, 0.0066, 0.015, 0.0059, 0.0251, 0.0041...              18   \n",
       "34  [0.0097, 0.0369, 0.0052, 0.0242, 0.0375, 0.038...              19   \n",
       "35  [0.0188, 0.0114, 0.0364, 0.0044, 0.0069, 0.009...              20   \n",
       "36  [0.0232, 0.0385, 0.006, 0.0094, 0.0033, 0.0228...              21   \n",
       "37  [0.0268, 0.0123, 0.0053, 0.0237, 0.0047, 0.004...              21   \n",
       "38  [0.0068, 0.0176, 0.0331, 0.0135, 0.0034, 0.04,...              22   \n",
       "39  [0.0128, 0.0237, 0.0127, 0.0132, 0.0035, 0.013...              22   \n",
       "40  [0.0086, 0.0115, 0.0121, 0.0486, 0.0018, 0.014...              22   \n",
       "41  [0.0075, 0.0141, 0.016, 0.0252, 0.0042, 0.0096...              22   \n",
       "42  [0.0079, 0.009, 0.0083, 0.0115, 0.0041, 0.0032...              23   \n",
       "43  [0.0225, 0.0129, 0.0115, 0.0025, 0.0309, 0.006...              23   \n",
       "44  [0.0125, 0.0207, 0.0345, 0.0112, 0.0149, 0.003...              23   \n",
       "45  [0.0851, 0.0172, 0.0162, 0.169, 0.0507, 0.0171...              23   \n",
       "46  [0.0018, 0.022, 0.0172, 0.0283, 0.0211, 0.0238...              24   \n",
       "47  [0.0099, 0.0133, 0.016, 0.029, 0.0193, 0.049, ...              24   \n",
       "48  [0.0189, 0.1426, 0.0074, 0.009, 0.0397, 0.0707...              25   \n",
       "49  [0.0102, 0.1457, 0.0047, 0.0087, 0.0271, 0.103...              25   \n",
       "50  [0.3808, 0.0058, 0.0046, 0.0112, 0.0059, 0.004...              26   \n",
       "51  [0.0092, 0.0131, 0.011, 0.0202, 0.1138, 0.0044...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.846154  0.070415  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                  1       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                  2       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                 25       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                 8       NaN       NaN  \n",
       "21                 8       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                16       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                20       NaN       NaN  \n",
       "36                21       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2281 : Training: loss:  0.07481104\n",
      "2282 : Training: loss:  0.0672401\n",
      "2283 : Training: loss:  0.055418227\n",
      "2284 : Training: loss:  0.040699925\n",
      "2285 : Training: loss:  0.066167384\n",
      "2286 : Training: loss:  0.06783523\n",
      "2287 : Training: loss:  0.088143885\n",
      "2288 : Training: loss:  0.051645212\n",
      "2289 : Training: loss:  0.068776734\n",
      "2290 : Training: loss:  0.057887204\n",
      "2291 : Training: loss:  0.05214583\n",
      "2292 : Training: loss:  0.06150654\n",
      "2293 : Training: loss:  0.060102083\n",
      "2294 : Training: loss:  0.065811515\n",
      "2295 : Training: loss:  0.057082172\n",
      "2296 : Training: loss:  0.07791734\n",
      "2297 : Training: loss:  0.058307525\n",
      "2298 : Training: loss:  0.0644382\n",
      "2299 : Training: loss:  0.05708337\n",
      "2300 : Training: loss:  0.05730242\n",
      "Validation: Loss:  0.06965871  Accuracy:  0.86538464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.3895, 0.0065, 0.0057, 0.0135, 0.0031, 0.011...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.069659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.3816, 0.0078, 0.0062, 0.0126, 0.0061, 0.005...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.5222, 0.0365, 0.0062, 0.0252, 0.0054, 0.111...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1177, 0.225, 0.0056, 0.0073, 0.028, 0.0475,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.024, 0.2934, 0.0238, 0.0045, 0.0322, 0.0551...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0024, 0.0275, 0.375, 0.0035, 0.0222, 0.0233...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.015, 0.0078, 0.0084, 0.3718, 0.041, 0.0133,...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0078, 0.0052, 0.0142, 0.5298, 0.0185, 0.008...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0399, 0.0067, 0.0165, 0.6017, 0.0087, 0.008...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0333, 0.0706, 0.0024, 0.0224, 0.1167, 0.136...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0334, 0.244, 0.0175, 0.0075, 0.1937, 0.1598...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0333, 0.0523, 0.004, 0.0043, 0.0247, 0.2654...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0187, 0.0494, 0.0357, 0.0026, 0.0036, 0.044...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0915, 0.0216, 0.0274, 0.0077, 0.0088, 0.037...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0233, 0.1397, 0.0022, 0.004, 0.061, 0.0262,...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0326, 0.0097, 0.001, 0.0335, 0.0304, 0.0069...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0247, 0.0095, 0.0501, 0.0472, 0.0055, 0.002...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0108, 0.0137, 0.0491, 0.0098, 0.0075, 0.014...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0141, 0.0135, 0.0403, 0.0025, 0.0543, 0.015...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0161, 0.0191, 0.0296, 0.0025, 0.0492, 0.025...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.029, 0.0175, 0.0097, 0.0059, 0.0096, 0.0065...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0171, 0.0244, 0.0181, 0.0276, 0.0703, 0.012...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0099, 0.0464, 0.0106, 0.0139, 0.0155, 0.01,...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0035, 0.0082, 0.0145, 0.0371, 0.0457, 0.037...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0015, 0.0077, 0.031, 0.0271, 0.0366, 0.0357...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0104, 0.0091, 0.0154, 0.0728, 0.0524, 0.006...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0049, 0.004, 0.0123, 0.0425, 0.0261, 0.0032...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0024, 0.0492, 0.0079, 0.0048, 0.0378, 0.030...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0009, 0.1357, 0.0388, 0.0342, 0.1195, 0.060...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0029, 0.0508, 0.0061, 0.0138, 0.076, 0.0171...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.3928, 0.0319, 0.0095, 0.0132, 0.0359, 0.050...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0219, 0.0285, 0.0275, 0.0566, 0.0162, 0.016...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0232, 0.0121, 0.0844, 0.1236, 0.0379, 0.012...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.02, 0.0065, 0.0143, 0.0059, 0.028, 0.004, 0...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0094, 0.0369, 0.005, 0.0244, 0.0429, 0.0389...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0184, 0.011, 0.0349, 0.0042, 0.0073, 0.0091...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.023, 0.0388, 0.0057, 0.009, 0.0035, 0.0232,...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0263, 0.0121, 0.0051, 0.0233, 0.0049, 0.004...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0067, 0.0173, 0.0323, 0.0134, 0.0036, 0.041...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0126, 0.0234, 0.012, 0.0128, 0.0037, 0.0135...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0085, 0.0112, 0.0117, 0.0478, 0.002, 0.015,...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0073, 0.0138, 0.0153, 0.0249, 0.0045, 0.009...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0077, 0.0089, 0.008, 0.0112, 0.0044, 0.0032...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0216, 0.0126, 0.0109, 0.0024, 0.0317, 0.006...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0122, 0.0202, 0.0329, 0.0108, 0.0161, 0.003...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.084, 0.0168, 0.0154, 0.1693, 0.0564, 0.0166...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0017, 0.0218, 0.0167, 0.0289, 0.0249, 0.024...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0096, 0.0129, 0.0151, 0.0285, 0.0212, 0.049...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.019, 0.1468, 0.0072, 0.009, 0.0448, 0.0721,...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.01, 0.1495, 0.0046, 0.0087, 0.0306, 0.1068,...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.3803, 0.0057, 0.0043, 0.0109, 0.0064, 0.003...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.009, 0.0127, 0.0103, 0.0202, 0.1342, 0.0042...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.3895, 0.0065, 0.0057, 0.0135, 0.0031, 0.011...               0   \n",
       "1   [0.3816, 0.0078, 0.0062, 0.0126, 0.0061, 0.005...               0   \n",
       "2   [0.5222, 0.0365, 0.0062, 0.0252, 0.0054, 0.111...               0   \n",
       "3   [0.1177, 0.225, 0.0056, 0.0073, 0.028, 0.0475,...               1   \n",
       "4   [0.024, 0.2934, 0.0238, 0.0045, 0.0322, 0.0551...               1   \n",
       "5   [0.0024, 0.0275, 0.375, 0.0035, 0.0222, 0.0233...               2   \n",
       "6   [0.015, 0.0078, 0.0084, 0.3718, 0.041, 0.0133,...               3   \n",
       "7   [0.0078, 0.0052, 0.0142, 0.5298, 0.0185, 0.008...               3   \n",
       "8   [0.0399, 0.0067, 0.0165, 0.6017, 0.0087, 0.008...               3   \n",
       "9   [0.0333, 0.0706, 0.0024, 0.0224, 0.1167, 0.136...               4   \n",
       "10  [0.0334, 0.244, 0.0175, 0.0075, 0.1937, 0.1598...               4   \n",
       "11  [0.0333, 0.0523, 0.004, 0.0043, 0.0247, 0.2654...               5   \n",
       "12  [0.0187, 0.0494, 0.0357, 0.0026, 0.0036, 0.044...               6   \n",
       "13  [0.0915, 0.0216, 0.0274, 0.0077, 0.0088, 0.037...               7   \n",
       "14  [0.0233, 0.1397, 0.0022, 0.004, 0.061, 0.0262,...               8   \n",
       "15  [0.0326, 0.0097, 0.001, 0.0335, 0.0304, 0.0069...               8   \n",
       "16  [0.0247, 0.0095, 0.0501, 0.0472, 0.0055, 0.002...               9   \n",
       "17  [0.0108, 0.0137, 0.0491, 0.0098, 0.0075, 0.014...               9   \n",
       "18  [0.0141, 0.0135, 0.0403, 0.0025, 0.0543, 0.015...              10   \n",
       "19  [0.0161, 0.0191, 0.0296, 0.0025, 0.0492, 0.025...              10   \n",
       "20  [0.029, 0.0175, 0.0097, 0.0059, 0.0096, 0.0065...              11   \n",
       "21  [0.0171, 0.0244, 0.0181, 0.0276, 0.0703, 0.012...              11   \n",
       "22  [0.0099, 0.0464, 0.0106, 0.0139, 0.0155, 0.01,...              12   \n",
       "23  [0.0035, 0.0082, 0.0145, 0.0371, 0.0457, 0.037...              13   \n",
       "24  [0.0015, 0.0077, 0.031, 0.0271, 0.0366, 0.0357...              13   \n",
       "25  [0.0104, 0.0091, 0.0154, 0.0728, 0.0524, 0.006...              14   \n",
       "26  [0.0049, 0.004, 0.0123, 0.0425, 0.0261, 0.0032...              14   \n",
       "27  [0.0024, 0.0492, 0.0079, 0.0048, 0.0378, 0.030...              15   \n",
       "28  [0.0009, 0.1357, 0.0388, 0.0342, 0.1195, 0.060...              15   \n",
       "29  [0.0029, 0.0508, 0.0061, 0.0138, 0.076, 0.0171...              15   \n",
       "30  [0.3928, 0.0319, 0.0095, 0.0132, 0.0359, 0.050...              16   \n",
       "31  [0.0219, 0.0285, 0.0275, 0.0566, 0.0162, 0.016...              17   \n",
       "32  [0.0232, 0.0121, 0.0844, 0.1236, 0.0379, 0.012...              17   \n",
       "33  [0.02, 0.0065, 0.0143, 0.0059, 0.028, 0.004, 0...              18   \n",
       "34  [0.0094, 0.0369, 0.005, 0.0244, 0.0429, 0.0389...              19   \n",
       "35  [0.0184, 0.011, 0.0349, 0.0042, 0.0073, 0.0091...              20   \n",
       "36  [0.023, 0.0388, 0.0057, 0.009, 0.0035, 0.0232,...              21   \n",
       "37  [0.0263, 0.0121, 0.0051, 0.0233, 0.0049, 0.004...              21   \n",
       "38  [0.0067, 0.0173, 0.0323, 0.0134, 0.0036, 0.041...              22   \n",
       "39  [0.0126, 0.0234, 0.012, 0.0128, 0.0037, 0.0135...              22   \n",
       "40  [0.0085, 0.0112, 0.0117, 0.0478, 0.002, 0.015,...              22   \n",
       "41  [0.0073, 0.0138, 0.0153, 0.0249, 0.0045, 0.009...              22   \n",
       "42  [0.0077, 0.0089, 0.008, 0.0112, 0.0044, 0.0032...              23   \n",
       "43  [0.0216, 0.0126, 0.0109, 0.0024, 0.0317, 0.006...              23   \n",
       "44  [0.0122, 0.0202, 0.0329, 0.0108, 0.0161, 0.003...              23   \n",
       "45  [0.084, 0.0168, 0.0154, 0.1693, 0.0564, 0.0166...              23   \n",
       "46  [0.0017, 0.0218, 0.0167, 0.0289, 0.0249, 0.024...              24   \n",
       "47  [0.0096, 0.0129, 0.0151, 0.0285, 0.0212, 0.049...              24   \n",
       "48  [0.019, 0.1468, 0.0072, 0.009, 0.0448, 0.0721,...              25   \n",
       "49  [0.01, 0.1495, 0.0046, 0.0087, 0.0306, 0.1068,...              25   \n",
       "50  [0.3803, 0.0057, 0.0043, 0.0109, 0.0064, 0.003...              26   \n",
       "51  [0.009, 0.0127, 0.0103, 0.0202, 0.1342, 0.0042...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.865385  0.069659  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                  1       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                  2       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                 25       NaN       NaN  \n",
       "10                 1       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                11       NaN       NaN  \n",
       "21                 8       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                16       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                20       NaN       NaN  \n",
       "36                21       NaN       NaN  \n",
       "37                22       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2301 : Training: loss:  0.044951573\n",
      "2302 : Training: loss:  0.06859701\n",
      "2303 : Training: loss:  0.05802171\n",
      "2304 : Training: loss:  0.06946722\n",
      "2305 : Training: loss:  0.05694399\n",
      "2306 : Training: loss:  0.08652943\n",
      "2307 : Training: loss:  0.051278017\n",
      "2308 : Training: loss:  0.0667488\n",
      "2309 : Training: loss:  0.060229845\n",
      "2310 : Training: loss:  0.0667346\n",
      "2311 : Training: loss:  0.06083703\n",
      "2312 : Training: loss:  0.06712559\n",
      "2313 : Training: loss:  0.060220752\n",
      "2314 : Training: loss:  0.06876237\n",
      "2315 : Training: loss:  0.054656833\n",
      "2316 : Training: loss:  0.06623597\n",
      "2317 : Training: loss:  0.04812916\n",
      "2318 : Training: loss:  0.06822308\n",
      "2319 : Training: loss:  0.047227178\n",
      "2320 : Training: loss:  0.07094555\n",
      "Validation: Loss:  0.068990216  Accuracy:  0.86538464\n",
      "2321 : Training: loss:  0.05698283\n",
      "2322 : Training: loss:  0.057663817\n",
      "2323 : Training: loss:  0.0654415\n",
      "2324 : Training: loss:  0.059514254\n",
      "2325 : Training: loss:  0.050463386\n",
      "2326 : Training: loss:  0.056541283\n",
      "2327 : Training: loss:  0.061263755\n",
      "2328 : Training: loss:  0.053883225\n",
      "2329 : Training: loss:  0.07787815\n",
      "2330 : Training: loss:  0.040019393\n",
      "2331 : Training: loss:  0.05424366\n",
      "2332 : Training: loss:  0.05106888\n",
      "2333 : Training: loss:  0.044923782\n",
      "2334 : Training: loss:  0.055172317\n",
      "2335 : Training: loss:  0.055936553\n",
      "2336 : Training: loss:  0.052022718\n",
      "2337 : Training: loss:  0.048185594\n",
      "2338 : Training: loss:  0.043597743\n",
      "2339 : Training: loss:  0.049420252\n",
      "2340 : Training: loss:  0.063173465\n",
      "Validation: Loss:  0.0683357  Accuracy:  0.86538464\n",
      "2341 : Training: loss:  0.053658295\n",
      "2342 : Training: loss:  0.048390027\n",
      "2343 : Training: loss:  0.057289414\n",
      "2344 : Training: loss:  0.07060641\n",
      "2345 : Training: loss:  0.06932444\n",
      "2346 : Training: loss:  0.053967778\n",
      "2347 : Training: loss:  0.05134143\n",
      "2348 : Training: loss:  0.048889473\n",
      "2349 : Training: loss:  0.06101554\n",
      "2350 : Training: loss:  0.054929707\n",
      "2351 : Training: loss:  0.054319408\n",
      "2352 : Training: loss:  0.062159166\n",
      "2353 : Training: loss:  0.045639668\n",
      "2354 : Training: loss:  0.055138327\n",
      "2355 : Training: loss:  0.06441558\n",
      "2356 : Training: loss:  0.0516927\n",
      "2357 : Training: loss:  0.041334476\n",
      "2358 : Training: loss:  0.070539586\n",
      "2359 : Training: loss:  0.057621475\n",
      "2360 : Training: loss:  0.049527373\n",
      "Validation: Loss:  0.0677421  Accuracy:  0.86538464\n",
      "2361 : Training: loss:  0.05372141\n",
      "2362 : Training: loss:  0.037260767\n",
      "2363 : Training: loss:  0.0496919\n",
      "2364 : Training: loss:  0.062898405\n",
      "2365 : Training: loss:  0.05338176\n",
      "2366 : Training: loss:  0.03470606\n",
      "2367 : Training: loss:  0.04835132\n",
      "2368 : Training: loss:  0.05249644\n",
      "2369 : Training: loss:  0.06451427\n",
      "2370 : Training: loss:  0.0640055\n",
      "2371 : Training: loss:  0.058768306\n",
      "2372 : Training: loss:  0.07136195\n",
      "2373 : Training: loss:  0.052713037\n",
      "2374 : Training: loss:  0.054039065\n",
      "2375 : Training: loss:  0.045845535\n",
      "2376 : Training: loss:  0.042950872\n",
      "2377 : Training: loss:  0.07268262\n",
      "2378 : Training: loss:  0.046956856\n",
      "2379 : Training: loss:  0.055682402\n",
      "2380 : Training: loss:  0.054551344\n",
      "Validation: Loss:  0.06716386  Accuracy:  0.86538464\n",
      "2381 : Training: loss:  0.055178527\n",
      "2382 : Training: loss:  0.062272955\n",
      "2383 : Training: loss:  0.068039745\n",
      "2384 : Training: loss:  0.06850923\n",
      "2385 : Training: loss:  0.070524305\n",
      "2386 : Training: loss:  0.0664173\n",
      "2387 : Training: loss:  0.03906518\n",
      "2388 : Training: loss:  0.044197664\n",
      "2389 : Training: loss:  0.06378182\n",
      "2390 : Training: loss:  0.05806194\n",
      "2391 : Training: loss:  0.053826705\n",
      "2392 : Training: loss:  0.062464576\n",
      "2393 : Training: loss:  0.053746898\n",
      "2394 : Training: loss:  0.04222076\n",
      "2395 : Training: loss:  0.065470405\n",
      "2396 : Training: loss:  0.04481957\n",
      "2397 : Training: loss:  0.06501526\n",
      "2398 : Training: loss:  0.0653347\n",
      "2399 : Training: loss:  0.062084552\n",
      "2400 : Training: loss:  0.057424825\n",
      "Validation: Loss:  0.066535376  Accuracy:  0.86538464\n",
      "2401 : Training: loss:  0.051585086\n",
      "2402 : Training: loss:  0.07899527\n",
      "2403 : Training: loss:  0.06619585\n",
      "2404 : Training: loss:  0.052445244\n",
      "2405 : Training: loss:  0.045986917\n",
      "2406 : Training: loss:  0.053282022\n",
      "2407 : Training: loss:  0.045848556\n",
      "2408 : Training: loss:  0.0671804\n",
      "2409 : Training: loss:  0.05382069\n",
      "2410 : Training: loss:  0.05900795\n",
      "2411 : Training: loss:  0.04600581\n",
      "2412 : Training: loss:  0.04713767\n",
      "2413 : Training: loss:  0.05228149\n",
      "2414 : Training: loss:  0.049317524\n",
      "2415 : Training: loss:  0.04883749\n",
      "2416 : Training: loss:  0.04450454\n",
      "2417 : Training: loss:  0.040238574\n",
      "2418 : Training: loss:  0.043697946\n",
      "2419 : Training: loss:  0.0360308\n",
      "2420 : Training: loss:  0.06016498\n",
      "Validation: Loss:  0.0659295  Accuracy:  0.86538464\n",
      "2421 : Training: loss:  0.056791924\n",
      "2422 : Training: loss:  0.054418735\n",
      "2423 : Training: loss:  0.062529646\n",
      "2424 : Training: loss:  0.052664492\n",
      "2425 : Training: loss:  0.061353497\n",
      "2426 : Training: loss:  0.055058736\n",
      "2427 : Training: loss:  0.04971633\n",
      "2428 : Training: loss:  0.041478757\n",
      "2429 : Training: loss:  0.035090253\n",
      "2430 : Training: loss:  0.047584675\n",
      "2431 : Training: loss:  0.05338838\n",
      "2432 : Training: loss:  0.051596228\n",
      "2433 : Training: loss:  0.046307847\n",
      "2434 : Training: loss:  0.056240898\n",
      "2435 : Training: loss:  0.051808234\n",
      "2436 : Training: loss:  0.03474268\n",
      "2437 : Training: loss:  0.043872204\n",
      "2438 : Training: loss:  0.07128328\n",
      "2439 : Training: loss:  0.058179274\n",
      "2440 : Training: loss:  0.059414085\n",
      "Validation: Loss:  0.06537472  Accuracy:  0.86538464\n",
      "2441 : Training: loss:  0.059733525\n",
      "2442 : Training: loss:  0.043137267\n",
      "2443 : Training: loss:  0.051207516\n",
      "2444 : Training: loss:  0.06064916\n",
      "2445 : Training: loss:  0.05893001\n",
      "2446 : Training: loss:  0.04884663\n",
      "2447 : Training: loss:  0.04503885\n",
      "2448 : Training: loss:  0.05132143\n",
      "2449 : Training: loss:  0.040008575\n",
      "2450 : Training: loss:  0.03871445\n",
      "2451 : Training: loss:  0.03811968\n",
      "2452 : Training: loss:  0.05573254\n",
      "2453 : Training: loss:  0.07370621\n",
      "2454 : Training: loss:  0.054840606\n",
      "2455 : Training: loss:  0.052857783\n",
      "2456 : Training: loss:  0.054965734\n",
      "2457 : Training: loss:  0.058621984\n",
      "2458 : Training: loss:  0.044680573\n",
      "2459 : Training: loss:  0.043330602\n",
      "2460 : Training: loss:  0.056291815\n",
      "Validation: Loss:  0.064686395  Accuracy:  0.86538464\n",
      "2461 : Training: loss:  0.04232547\n",
      "2462 : Training: loss:  0.06312696\n",
      "2463 : Training: loss:  0.064789444\n",
      "2464 : Training: loss:  0.04432934\n",
      "2465 : Training: loss:  0.0677821\n",
      "2466 : Training: loss:  0.038700018\n",
      "2467 : Training: loss:  0.05751\n",
      "2468 : Training: loss:  0.042102806\n",
      "2469 : Training: loss:  0.04272704\n",
      "2470 : Training: loss:  0.057006836\n",
      "2471 : Training: loss:  0.05925956\n",
      "2472 : Training: loss:  0.037413135\n",
      "2473 : Training: loss:  0.055623338\n",
      "2474 : Training: loss:  0.042786725\n",
      "2475 : Training: loss:  0.06491503\n",
      "2476 : Training: loss:  0.059913747\n",
      "2477 : Training: loss:  0.054287788\n",
      "2478 : Training: loss:  0.05608098\n",
      "2479 : Training: loss:  0.055289406\n",
      "2480 : Training: loss:  0.045534104\n",
      "Validation: Loss:  0.0641064  Accuracy:  0.86538464\n",
      "2481 : Training: loss:  0.04287445\n",
      "2482 : Training: loss:  0.060027834\n",
      "2483 : Training: loss:  0.040614825\n",
      "2484 : Training: loss:  0.05582964\n",
      "2485 : Training: loss:  0.06650629\n",
      "2486 : Training: loss:  0.057072286\n",
      "2487 : Training: loss:  0.055649288\n",
      "2488 : Training: loss:  0.052166063\n",
      "2489 : Training: loss:  0.05910325\n",
      "2490 : Training: loss:  0.04157829\n",
      "2491 : Training: loss:  0.04728737\n",
      "2492 : Training: loss:  0.056922883\n",
      "2493 : Training: loss:  0.054952707\n",
      "2494 : Training: loss:  0.07119291\n",
      "2495 : Training: loss:  0.036744636\n",
      "2496 : Training: loss:  0.05852024\n",
      "2497 : Training: loss:  0.05846497\n",
      "2498 : Training: loss:  0.06306403\n",
      "2499 : Training: loss:  0.03634521\n",
      "2500 : Training: loss:  0.041785456\n",
      "Validation: Loss:  0.06355939  Accuracy:  0.86538464\n",
      "2501 : Training: loss:  0.055042807\n",
      "2502 : Training: loss:  0.046431754\n",
      "2503 : Training: loss:  0.041675903\n",
      "2504 : Training: loss:  0.04537584\n",
      "2505 : Training: loss:  0.054782834\n",
      "2506 : Training: loss:  0.048545312\n",
      "2507 : Training: loss:  0.0542576\n",
      "2508 : Training: loss:  0.037421152\n",
      "2509 : Training: loss:  0.037585203\n",
      "2510 : Training: loss:  0.02904053\n",
      "2511 : Training: loss:  0.036969025\n",
      "2512 : Training: loss:  0.04977027\n",
      "2513 : Training: loss:  0.04162555\n",
      "2514 : Training: loss:  0.05048894\n",
      "2515 : Training: loss:  0.044447962\n",
      "2516 : Training: loss:  0.055643912\n",
      "2517 : Training: loss:  0.042538162\n",
      "2518 : Training: loss:  0.052317373\n",
      "2519 : Training: loss:  0.050787814\n",
      "2520 : Training: loss:  0.04089497\n",
      "Validation: Loss:  0.06308208  Accuracy:  0.86538464\n",
      "2521 : Training: loss:  0.06436804\n",
      "2522 : Training: loss:  0.05620106\n",
      "2523 : Training: loss:  0.037760314\n",
      "2524 : Training: loss:  0.0424301\n",
      "2525 : Training: loss:  0.03353025\n",
      "2526 : Training: loss:  0.055415317\n",
      "2527 : Training: loss:  0.034315433\n",
      "2528 : Training: loss:  0.049319163\n",
      "2529 : Training: loss:  0.043444708\n",
      "2530 : Training: loss:  0.049944296\n",
      "2531 : Training: loss:  0.0488236\n",
      "2532 : Training: loss:  0.043023676\n",
      "2533 : Training: loss:  0.071733944\n",
      "2534 : Training: loss:  0.047214944\n",
      "2535 : Training: loss:  0.05313718\n",
      "2536 : Training: loss:  0.077793635\n",
      "2537 : Training: loss:  0.027919075\n",
      "2538 : Training: loss:  0.048089843\n",
      "2539 : Training: loss:  0.053385146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540 : Training: loss:  0.0380749\n",
      "Validation: Loss:  0.06262891  Accuracy:  0.84615386\n",
      "2541 : Training: loss:  0.0423397\n",
      "2542 : Training: loss:  0.041457675\n",
      "2543 : Training: loss:  0.05839484\n",
      "2544 : Training: loss:  0.04942858\n",
      "2545 : Training: loss:  0.049371604\n",
      "2546 : Training: loss:  0.040664464\n",
      "2547 : Training: loss:  0.05424337\n",
      "2548 : Training: loss:  0.05274936\n",
      "2549 : Training: loss:  0.05076225\n",
      "2550 : Training: loss:  0.04818579\n",
      "2551 : Training: loss:  0.06548414\n",
      "2552 : Training: loss:  0.034236107\n",
      "2553 : Training: loss:  0.038868457\n",
      "2554 : Training: loss:  0.056059342\n",
      "2555 : Training: loss:  0.054185934\n",
      "2556 : Training: loss:  0.046213116\n",
      "2557 : Training: loss:  0.054047868\n",
      "2558 : Training: loss:  0.037341658\n",
      "2559 : Training: loss:  0.061228804\n",
      "2560 : Training: loss:  0.04562168\n",
      "Validation: Loss:  0.062287357  Accuracy:  0.84615386\n",
      "2561 : Training: loss:  0.037954118\n",
      "2562 : Training: loss:  0.03706455\n",
      "2563 : Training: loss:  0.039098006\n",
      "2564 : Training: loss:  0.03924498\n",
      "2565 : Training: loss:  0.05344273\n",
      "2566 : Training: loss:  0.052281182\n",
      "2567 : Training: loss:  0.03868034\n",
      "2568 : Training: loss:  0.045342714\n",
      "2569 : Training: loss:  0.066246495\n",
      "2570 : Training: loss:  0.054204352\n",
      "2571 : Training: loss:  0.05888373\n",
      "2572 : Training: loss:  0.054315858\n",
      "2573 : Training: loss:  0.06070974\n",
      "2574 : Training: loss:  0.045197137\n",
      "2575 : Training: loss:  0.03220059\n",
      "2576 : Training: loss:  0.050314356\n",
      "2577 : Training: loss:  0.04376545\n",
      "2578 : Training: loss:  0.046815325\n",
      "2579 : Training: loss:  0.043713003\n",
      "2580 : Training: loss:  0.049475625\n",
      "Validation: Loss:  0.061809473  Accuracy:  0.84615386\n",
      "2581 : Training: loss:  0.05804135\n",
      "2582 : Training: loss:  0.065265946\n",
      "2583 : Training: loss:  0.05314383\n",
      "2584 : Training: loss:  0.050008655\n",
      "2585 : Training: loss:  0.05349948\n",
      "2586 : Training: loss:  0.049790356\n",
      "2587 : Training: loss:  0.0621413\n",
      "2588 : Training: loss:  0.063624896\n",
      "2589 : Training: loss:  0.06199548\n",
      "2590 : Training: loss:  0.052770145\n",
      "2591 : Training: loss:  0.03848299\n",
      "2592 : Training: loss:  0.04723938\n",
      "2593 : Training: loss:  0.055125933\n",
      "2594 : Training: loss:  0.056485824\n",
      "2595 : Training: loss:  0.048114385\n",
      "2596 : Training: loss:  0.07307457\n",
      "2597 : Training: loss:  0.03958538\n",
      "2598 : Training: loss:  0.04436875\n",
      "2599 : Training: loss:  0.046475742\n",
      "2600 : Training: loss:  0.05018018\n",
      "Validation: Loss:  0.061181083  Accuracy:  0.84615386\n",
      "2601 : Training: loss:  0.0488233\n",
      "2602 : Training: loss:  0.06568698\n",
      "2603 : Training: loss:  0.038025755\n",
      "2604 : Training: loss:  0.035307553\n",
      "2605 : Training: loss:  0.033863865\n",
      "2606 : Training: loss:  0.030518593\n",
      "2607 : Training: loss:  0.04653654\n",
      "2608 : Training: loss:  0.06321381\n",
      "2609 : Training: loss:  0.038925506\n",
      "2610 : Training: loss:  0.05563343\n",
      "2611 : Training: loss:  0.05521086\n",
      "2612 : Training: loss:  0.045476273\n",
      "2613 : Training: loss:  0.043572158\n",
      "2614 : Training: loss:  0.038437765\n",
      "2615 : Training: loss:  0.04645602\n",
      "2616 : Training: loss:  0.038315877\n",
      "2617 : Training: loss:  0.042877987\n",
      "2618 : Training: loss:  0.03787836\n",
      "2619 : Training: loss:  0.037249893\n",
      "2620 : Training: loss:  0.046838067\n",
      "Validation: Loss:  0.060626175  Accuracy:  0.84615386\n",
      "2621 : Training: loss:  0.054468527\n",
      "2622 : Training: loss:  0.054304793\n",
      "2623 : Training: loss:  0.056813363\n",
      "2624 : Training: loss:  0.030923167\n",
      "2625 : Training: loss:  0.038026128\n",
      "2626 : Training: loss:  0.051364735\n",
      "2627 : Training: loss:  0.039096214\n",
      "2628 : Training: loss:  0.045392938\n",
      "2629 : Training: loss:  0.059246548\n",
      "2630 : Training: loss:  0.06659504\n",
      "2631 : Training: loss:  0.041261178\n",
      "2632 : Training: loss:  0.06534223\n",
      "2633 : Training: loss:  0.046319768\n",
      "2634 : Training: loss:  0.05149906\n",
      "2635 : Training: loss:  0.038137082\n",
      "2636 : Training: loss:  0.038492765\n",
      "2637 : Training: loss:  0.053499613\n",
      "2638 : Training: loss:  0.05169416\n",
      "2639 : Training: loss:  0.039603002\n",
      "2640 : Training: loss:  0.047365945\n",
      "Validation: Loss:  0.06033798  Accuracy:  0.8076923\n",
      "2641 : Training: loss:  0.03575386\n",
      "2642 : Training: loss:  0.047111556\n",
      "2643 : Training: loss:  0.042167738\n",
      "2644 : Training: loss:  0.05388558\n",
      "2645 : Training: loss:  0.05332348\n",
      "2646 : Training: loss:  0.043282013\n",
      "2647 : Training: loss:  0.04340412\n",
      "2648 : Training: loss:  0.039132245\n",
      "2649 : Training: loss:  0.037571475\n",
      "2650 : Training: loss:  0.055496845\n",
      "2651 : Training: loss:  0.0630774\n",
      "2652 : Training: loss:  0.049096603\n",
      "2653 : Training: loss:  0.056424145\n",
      "2654 : Training: loss:  0.05129514\n",
      "2655 : Training: loss:  0.041152958\n",
      "2656 : Training: loss:  0.03810336\n",
      "2657 : Training: loss:  0.046053555\n",
      "2658 : Training: loss:  0.03347689\n",
      "2659 : Training: loss:  0.044347197\n",
      "2660 : Training: loss:  0.06231708\n",
      "Validation: Loss:  0.0597596  Accuracy:  0.8269231\n",
      "2661 : Training: loss:  0.046275396\n",
      "2662 : Training: loss:  0.05101727\n",
      "2663 : Training: loss:  0.06113317\n",
      "2664 : Training: loss:  0.051211763\n",
      "2665 : Training: loss:  0.0623056\n",
      "2666 : Training: loss:  0.03722532\n",
      "2667 : Training: loss:  0.045270205\n",
      "2668 : Training: loss:  0.05853143\n",
      "2669 : Training: loss:  0.042692453\n",
      "2670 : Training: loss:  0.040675562\n",
      "2671 : Training: loss:  0.04798581\n",
      "2672 : Training: loss:  0.0593005\n",
      "2673 : Training: loss:  0.0481633\n",
      "2674 : Training: loss:  0.050142862\n",
      "2675 : Training: loss:  0.042803198\n",
      "2676 : Training: loss:  0.03931052\n",
      "2677 : Training: loss:  0.053423196\n",
      "2678 : Training: loss:  0.042996187\n",
      "2679 : Training: loss:  0.04928659\n",
      "2680 : Training: loss:  0.043854125\n",
      "Validation: Loss:  0.059118908  Accuracy:  0.86538464\n",
      "2681 : Training: loss:  0.045742102\n",
      "2682 : Training: loss:  0.052078288\n",
      "2683 : Training: loss:  0.07063352\n",
      "2684 : Training: loss:  0.058093697\n",
      "2685 : Training: loss:  0.028827794\n",
      "2686 : Training: loss:  0.043894902\n",
      "2687 : Training: loss:  0.047186635\n",
      "2688 : Training: loss:  0.06462872\n",
      "2689 : Training: loss:  0.044797126\n",
      "2690 : Training: loss:  0.04971001\n",
      "2691 : Training: loss:  0.0545749\n",
      "2692 : Training: loss:  0.05218552\n",
      "2693 : Training: loss:  0.038376853\n",
      "2694 : Training: loss:  0.059419204\n",
      "2695 : Training: loss:  0.039295368\n",
      "2696 : Training: loss:  0.030820737\n",
      "2697 : Training: loss:  0.03642404\n",
      "2698 : Training: loss:  0.032532997\n",
      "2699 : Training: loss:  0.05922199\n",
      "2700 : Training: loss:  0.046107516\n",
      "Validation: Loss:  0.058637884  Accuracy:  0.90384614\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.4182, 0.0047, 0.0036, 0.0095, 0.0017, 0.006...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.058638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.4079, 0.0064, 0.004, 0.0085, 0.0042, 0.0038...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.6211, 0.0378, 0.0034, 0.0166, 0.0036, 0.148...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1091, 0.3111, 0.0039, 0.0048, 0.026, 0.0472...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0163, 0.358, 0.0206, 0.0023, 0.0332, 0.0491...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0014, 0.0185, 0.6593, 0.0017, 0.0153, 0.016...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0083, 0.0045, 0.0047, 0.4932, 0.0505, 0.008...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0035, 0.0023, 0.0095, 0.5996, 0.0175, 0.004...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0222, 0.0033, 0.0092, 0.6629, 0.0054, 0.004...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0222, 0.0637, 0.0009, 0.0176, 0.1599, 0.166...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0263, 0.2899, 0.0136, 0.0047, 0.3024, 0.221...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0209, 0.044, 0.0019, 0.0022, 0.0283, 0.4023...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.012, 0.0304, 0.0484, 0.001, 0.0017, 0.0317,...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0814, 0.0194, 0.0363, 0.0047, 0.007, 0.0336...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0168, 0.1536, 0.0012, 0.0022, 0.0755, 0.020...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0197, 0.0062, 0.0004, 0.0227, 0.0307, 0.004...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0141, 0.0069, 0.0645, 0.0382, 0.004, 0.0013...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0058, 0.0102, 0.0841, 0.005, 0.0073, 0.0107...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0079, 0.0085, 0.0532, 0.0012, 0.0513, 0.009...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0088, 0.0123, 0.0348, 0.0012, 0.0474, 0.016...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0189, 0.0121, 0.0085, 0.0031, 0.0053, 0.003...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0086, 0.0163, 0.0158, 0.0225, 0.0729, 0.006...</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0061, 0.0336, 0.0072, 0.008, 0.01, 0.0062, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0017, 0.0045, 0.0147, 0.0273, 0.0484, 0.036...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0007, 0.0037, 0.0416, 0.0207, 0.0351, 0.030...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0041, 0.004, 0.012, 0.0613, 0.0532, 0.0027,...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0021, 0.0018, 0.0104, 0.0358, 0.0218, 0.001...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0009, 0.0408, 0.0067, 0.0025, 0.0378, 0.025...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0003, 0.113, 0.0414, 0.0213, 0.1465, 0.0512...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0012, 0.035, 0.0038, 0.007, 0.0882, 0.0122,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.3928, 0.0268, 0.0075, 0.01, 0.0307, 0.0416,...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.017, 0.0203, 0.0241, 0.058, 0.0119, 0.0095,...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.018, 0.0073, 0.1076, 0.1276, 0.0284, 0.0066...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0111, 0.0033, 0.0149, 0.0035, 0.0219, 0.001...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0043, 0.0239, 0.0033, 0.0206, 0.0464, 0.021...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.013, 0.0069, 0.056, 0.0021, 0.0039, 0.0058,...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0169, 0.0274, 0.0038, 0.0054, 0.0021, 0.021...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0219, 0.0082, 0.0038, 0.0176, 0.0028, 0.003...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.004, 0.01, 0.0427, 0.0085, 0.0019, 0.0357, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0071, 0.0156, 0.0098, 0.0088, 0.0021, 0.009...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0051, 0.0073, 0.0114, 0.0373, 0.0014, 0.011...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0038, 0.0078, 0.0137, 0.0167, 0.0024, 0.006...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0038, 0.0052, 0.007, 0.0077, 0.0026, 0.0017...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0133, 0.007, 0.0109, 0.0011, 0.0213, 0.0042...</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0062, 0.0123, 0.0333, 0.0066, 0.0115, 0.001...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.0653, 0.0106, 0.0093, 0.2177, 0.0475, 0.011...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0007, 0.0121, 0.0164, 0.024, 0.0209, 0.0171...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0054, 0.0059, 0.0107, 0.0234, 0.016, 0.0388...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0102, 0.1258, 0.004, 0.0056, 0.0506, 0.055,...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.005, 0.1327, 0.0025, 0.0054, 0.0365, 0.0983...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.4268, 0.0044, 0.0031, 0.0077, 0.004, 0.0022...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0053, 0.0087, 0.0088, 0.0222, 0.2047, 0.002...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.4182, 0.0047, 0.0036, 0.0095, 0.0017, 0.006...               0   \n",
       "1   [0.4079, 0.0064, 0.004, 0.0085, 0.0042, 0.0038...               0   \n",
       "2   [0.6211, 0.0378, 0.0034, 0.0166, 0.0036, 0.148...               0   \n",
       "3   [0.1091, 0.3111, 0.0039, 0.0048, 0.026, 0.0472...               1   \n",
       "4   [0.0163, 0.358, 0.0206, 0.0023, 0.0332, 0.0491...               1   \n",
       "5   [0.0014, 0.0185, 0.6593, 0.0017, 0.0153, 0.016...               2   \n",
       "6   [0.0083, 0.0045, 0.0047, 0.4932, 0.0505, 0.008...               3   \n",
       "7   [0.0035, 0.0023, 0.0095, 0.5996, 0.0175, 0.004...               3   \n",
       "8   [0.0222, 0.0033, 0.0092, 0.6629, 0.0054, 0.004...               3   \n",
       "9   [0.0222, 0.0637, 0.0009, 0.0176, 0.1599, 0.166...               4   \n",
       "10  [0.0263, 0.2899, 0.0136, 0.0047, 0.3024, 0.221...               4   \n",
       "11  [0.0209, 0.044, 0.0019, 0.0022, 0.0283, 0.4023...               5   \n",
       "12  [0.012, 0.0304, 0.0484, 0.001, 0.0017, 0.0317,...               6   \n",
       "13  [0.0814, 0.0194, 0.0363, 0.0047, 0.007, 0.0336...               7   \n",
       "14  [0.0168, 0.1536, 0.0012, 0.0022, 0.0755, 0.020...               8   \n",
       "15  [0.0197, 0.0062, 0.0004, 0.0227, 0.0307, 0.004...               8   \n",
       "16  [0.0141, 0.0069, 0.0645, 0.0382, 0.004, 0.0013...               9   \n",
       "17  [0.0058, 0.0102, 0.0841, 0.005, 0.0073, 0.0107...               9   \n",
       "18  [0.0079, 0.0085, 0.0532, 0.0012, 0.0513, 0.009...              10   \n",
       "19  [0.0088, 0.0123, 0.0348, 0.0012, 0.0474, 0.016...              10   \n",
       "20  [0.0189, 0.0121, 0.0085, 0.0031, 0.0053, 0.003...              11   \n",
       "21  [0.0086, 0.0163, 0.0158, 0.0225, 0.0729, 0.006...              11   \n",
       "22  [0.0061, 0.0336, 0.0072, 0.008, 0.01, 0.0062, ...              12   \n",
       "23  [0.0017, 0.0045, 0.0147, 0.0273, 0.0484, 0.036...              13   \n",
       "24  [0.0007, 0.0037, 0.0416, 0.0207, 0.0351, 0.030...              13   \n",
       "25  [0.0041, 0.004, 0.012, 0.0613, 0.0532, 0.0027,...              14   \n",
       "26  [0.0021, 0.0018, 0.0104, 0.0358, 0.0218, 0.001...              14   \n",
       "27  [0.0009, 0.0408, 0.0067, 0.0025, 0.0378, 0.025...              15   \n",
       "28  [0.0003, 0.113, 0.0414, 0.0213, 0.1465, 0.0512...              15   \n",
       "29  [0.0012, 0.035, 0.0038, 0.007, 0.0882, 0.0122,...              15   \n",
       "30  [0.3928, 0.0268, 0.0075, 0.01, 0.0307, 0.0416,...              16   \n",
       "31  [0.017, 0.0203, 0.0241, 0.058, 0.0119, 0.0095,...              17   \n",
       "32  [0.018, 0.0073, 0.1076, 0.1276, 0.0284, 0.0066...              17   \n",
       "33  [0.0111, 0.0033, 0.0149, 0.0035, 0.0219, 0.001...              18   \n",
       "34  [0.0043, 0.0239, 0.0033, 0.0206, 0.0464, 0.021...              19   \n",
       "35  [0.013, 0.0069, 0.056, 0.0021, 0.0039, 0.0058,...              20   \n",
       "36  [0.0169, 0.0274, 0.0038, 0.0054, 0.0021, 0.021...              21   \n",
       "37  [0.0219, 0.0082, 0.0038, 0.0176, 0.0028, 0.003...              21   \n",
       "38  [0.004, 0.01, 0.0427, 0.0085, 0.0019, 0.0357, ...              22   \n",
       "39  [0.0071, 0.0156, 0.0098, 0.0088, 0.0021, 0.009...              22   \n",
       "40  [0.0051, 0.0073, 0.0114, 0.0373, 0.0014, 0.011...              22   \n",
       "41  [0.0038, 0.0078, 0.0137, 0.0167, 0.0024, 0.006...              22   \n",
       "42  [0.0038, 0.0052, 0.007, 0.0077, 0.0026, 0.0017...              23   \n",
       "43  [0.0133, 0.007, 0.0109, 0.0011, 0.0213, 0.0042...              23   \n",
       "44  [0.0062, 0.0123, 0.0333, 0.0066, 0.0115, 0.001...              23   \n",
       "45  [0.0653, 0.0106, 0.0093, 0.2177, 0.0475, 0.011...              23   \n",
       "46  [0.0007, 0.0121, 0.0164, 0.024, 0.0209, 0.0171...              24   \n",
       "47  [0.0054, 0.0059, 0.0107, 0.0234, 0.016, 0.0388...              24   \n",
       "48  [0.0102, 0.1258, 0.004, 0.0056, 0.0506, 0.055,...              25   \n",
       "49  [0.005, 0.1327, 0.0025, 0.0054, 0.0365, 0.0983...              25   \n",
       "50  [0.4268, 0.0044, 0.0031, 0.0077, 0.004, 0.0022...              26   \n",
       "51  [0.0053, 0.0087, 0.0088, 0.0222, 0.2047, 0.002...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.903846  0.058638  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                  1       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                  2       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                 25       NaN       NaN  \n",
       "10                 4       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                11       NaN       NaN  \n",
       "21                 8       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                16       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                20       NaN       NaN  \n",
       "36                21       NaN       NaN  \n",
       "37                21       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                18       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701 : Training: loss:  0.051901504\n",
      "2702 : Training: loss:  0.04568468\n",
      "2703 : Training: loss:  0.03506205\n",
      "2704 : Training: loss:  0.06128243\n",
      "2705 : Training: loss:  0.05077961\n",
      "2706 : Training: loss:  0.04268474\n",
      "2707 : Training: loss:  0.04347982\n",
      "2708 : Training: loss:  0.04985218\n",
      "2709 : Training: loss:  0.04382102\n",
      "2710 : Training: loss:  0.048372116\n",
      "2711 : Training: loss:  0.032875925\n",
      "2712 : Training: loss:  0.03489418\n",
      "2713 : Training: loss:  0.03884712\n",
      "2714 : Training: loss:  0.027826674\n",
      "2715 : Training: loss:  0.041446686\n",
      "2716 : Training: loss:  0.03389428\n",
      "2717 : Training: loss:  0.036185138\n",
      "2718 : Training: loss:  0.03473938\n",
      "2719 : Training: loss:  0.03695641\n",
      "2720 : Training: loss:  0.042941123\n",
      "Validation: Loss:  0.058165256  Accuracy:  0.90384614\n",
      "2721 : Training: loss:  0.044700895\n",
      "2722 : Training: loss:  0.033807974\n",
      "2723 : Training: loss:  0.0445966\n",
      "2724 : Training: loss:  0.049543403\n",
      "2725 : Training: loss:  0.0400971\n",
      "2726 : Training: loss:  0.030855624\n",
      "2727 : Training: loss:  0.033936586\n",
      "2728 : Training: loss:  0.025288723\n",
      "2729 : Training: loss:  0.0630226\n",
      "2730 : Training: loss:  0.048336044\n",
      "2731 : Training: loss:  0.042944685\n",
      "2732 : Training: loss:  0.04116057\n",
      "2733 : Training: loss:  0.047683056\n",
      "2734 : Training: loss:  0.04090183\n",
      "2735 : Training: loss:  0.03342865\n",
      "2736 : Training: loss:  0.040221594\n",
      "2737 : Training: loss:  0.048556622\n",
      "2738 : Training: loss:  0.036357388\n",
      "2739 : Training: loss:  0.033344\n",
      "2740 : Training: loss:  0.06888078\n",
      "Validation: Loss:  0.057558283  Accuracy:  0.90384614\n",
      "2741 : Training: loss:  0.032427583\n",
      "2742 : Training: loss:  0.036235888\n",
      "2743 : Training: loss:  0.035212364\n",
      "2744 : Training: loss:  0.046247292\n",
      "2745 : Training: loss:  0.042298697\n",
      "2746 : Training: loss:  0.05196278\n",
      "2747 : Training: loss:  0.04696048\n",
      "2748 : Training: loss:  0.035379868\n",
      "2749 : Training: loss:  0.0398962\n",
      "2750 : Training: loss:  0.03642096\n",
      "2751 : Training: loss:  0.033031926\n",
      "2752 : Training: loss:  0.040166106\n",
      "2753 : Training: loss:  0.05292713\n",
      "2754 : Training: loss:  0.050935324\n",
      "2755 : Training: loss:  0.050519925\n",
      "2756 : Training: loss:  0.03749235\n",
      "2757 : Training: loss:  0.05129022\n",
      "2758 : Training: loss:  0.05102282\n",
      "2759 : Training: loss:  0.038959417\n",
      "2760 : Training: loss:  0.050351687\n",
      "Validation: Loss:  0.057303365  Accuracy:  0.88461536\n",
      "2761 : Training: loss:  0.044408474\n",
      "2762 : Training: loss:  0.04768594\n",
      "2763 : Training: loss:  0.042934656\n",
      "2764 : Training: loss:  0.052006796\n",
      "2765 : Training: loss:  0.058188766\n",
      "2766 : Training: loss:  0.049406286\n",
      "2767 : Training: loss:  0.03487638\n",
      "2768 : Training: loss:  0.04565579\n",
      "2769 : Training: loss:  0.034819774\n",
      "2770 : Training: loss:  0.05115828\n",
      "2771 : Training: loss:  0.04968688\n",
      "2772 : Training: loss:  0.04193781\n",
      "2773 : Training: loss:  0.04238079\n",
      "2774 : Training: loss:  0.042852063\n",
      "2775 : Training: loss:  0.040520873\n",
      "2776 : Training: loss:  0.049636763\n",
      "2777 : Training: loss:  0.038465276\n",
      "2778 : Training: loss:  0.042338416\n",
      "2779 : Training: loss:  0.03910143\n",
      "2780 : Training: loss:  0.047026165\n",
      "Validation: Loss:  0.05688607  Accuracy:  0.88461536\n",
      "2781 : Training: loss:  0.041314382\n",
      "2782 : Training: loss:  0.03757824\n",
      "2783 : Training: loss:  0.03677262\n",
      "2784 : Training: loss:  0.050250087\n",
      "2785 : Training: loss:  0.039012875\n",
      "2786 : Training: loss:  0.04147078\n",
      "2787 : Training: loss:  0.030353608\n",
      "2788 : Training: loss:  0.06637979\n",
      "2789 : Training: loss:  0.03756089\n",
      "2790 : Training: loss:  0.049815863\n",
      "2791 : Training: loss:  0.034445375\n",
      "2792 : Training: loss:  0.0686803\n",
      "2793 : Training: loss:  0.036538262\n",
      "2794 : Training: loss:  0.040076837\n",
      "2795 : Training: loss:  0.032680854\n",
      "2796 : Training: loss:  0.035047695\n",
      "2797 : Training: loss:  0.04326927\n",
      "2798 : Training: loss:  0.03227518\n",
      "2799 : Training: loss:  0.047442958\n",
      "2800 : Training: loss:  0.03994337\n",
      "Validation: Loss:  0.056427237  Accuracy:  0.88461536\n",
      "2801 : Training: loss:  0.04397951\n",
      "2802 : Training: loss:  0.035329234\n",
      "2803 : Training: loss:  0.03953236\n",
      "2804 : Training: loss:  0.066439375\n",
      "2805 : Training: loss:  0.04932785\n",
      "2806 : Training: loss:  0.032521527\n",
      "2807 : Training: loss:  0.04109536\n",
      "2808 : Training: loss:  0.04877491\n",
      "2809 : Training: loss:  0.05455387\n",
      "2810 : Training: loss:  0.04402433\n",
      "2811 : Training: loss:  0.028906854\n",
      "2812 : Training: loss:  0.029227316\n",
      "2813 : Training: loss:  0.043044142\n",
      "2814 : Training: loss:  0.03328114\n",
      "2815 : Training: loss:  0.035473034\n",
      "2816 : Training: loss:  0.03550903\n",
      "2817 : Training: loss:  0.037501693\n",
      "2818 : Training: loss:  0.050201327\n",
      "2819 : Training: loss:  0.027577939\n",
      "2820 : Training: loss:  0.031970818\n",
      "Validation: Loss:  0.055735614  Accuracy:  0.88461536\n",
      "2821 : Training: loss:  0.03604539\n",
      "2822 : Training: loss:  0.033768196\n",
      "2823 : Training: loss:  0.049932905\n",
      "2824 : Training: loss:  0.031828914\n",
      "2825 : Training: loss:  0.049155537\n",
      "2826 : Training: loss:  0.04843499\n",
      "2827 : Training: loss:  0.03945529\n",
      "2828 : Training: loss:  0.029717516\n",
      "2829 : Training: loss:  0.037437417\n",
      "2830 : Training: loss:  0.036784366\n",
      "2831 : Training: loss:  0.0402467\n",
      "2832 : Training: loss:  0.035799302\n",
      "2833 : Training: loss:  0.054024823\n",
      "2834 : Training: loss:  0.0716381\n",
      "2835 : Training: loss:  0.026753502\n",
      "2836 : Training: loss:  0.042715788\n",
      "2837 : Training: loss:  0.050371975\n",
      "2838 : Training: loss:  0.044355903\n",
      "2839 : Training: loss:  0.04194073\n",
      "2840 : Training: loss:  0.034079414\n",
      "Validation: Loss:  0.05511949  Accuracy:  0.88461536\n",
      "2841 : Training: loss:  0.03260467\n",
      "2842 : Training: loss:  0.04011367\n",
      "2843 : Training: loss:  0.042996887\n",
      "2844 : Training: loss:  0.03227978\n",
      "2845 : Training: loss:  0.03815634\n",
      "2846 : Training: loss:  0.038191445\n",
      "2847 : Training: loss:  0.06574765\n",
      "2848 : Training: loss:  0.02688996\n",
      "2849 : Training: loss:  0.036613185\n",
      "2850 : Training: loss:  0.03528541\n",
      "2851 : Training: loss:  0.042875938\n",
      "2852 : Training: loss:  0.03687739\n",
      "2853 : Training: loss:  0.036019\n",
      "2854 : Training: loss:  0.05762959\n",
      "2855 : Training: loss:  0.04405658\n",
      "2856 : Training: loss:  0.03763507\n",
      "2857 : Training: loss:  0.04217903\n",
      "2858 : Training: loss:  0.03227399\n",
      "2859 : Training: loss:  0.03319639\n",
      "2860 : Training: loss:  0.042830672\n",
      "Validation: Loss:  0.05455587  Accuracy:  0.90384614\n",
      "2861 : Training: loss:  0.030105053\n",
      "2862 : Training: loss:  0.030329887\n",
      "2863 : Training: loss:  0.029400026\n",
      "2864 : Training: loss:  0.05956344\n",
      "2865 : Training: loss:  0.04049684\n",
      "2866 : Training: loss:  0.039812278\n",
      "2867 : Training: loss:  0.038303517\n",
      "2868 : Training: loss:  0.043649822\n",
      "2869 : Training: loss:  0.021369627\n",
      "2870 : Training: loss:  0.04865544\n",
      "2871 : Training: loss:  0.047767285\n",
      "2872 : Training: loss:  0.04299565\n",
      "2873 : Training: loss:  0.044865776\n",
      "2874 : Training: loss:  0.039016243\n",
      "2875 : Training: loss:  0.035139784\n",
      "2876 : Training: loss:  0.05975042\n",
      "2877 : Training: loss:  0.04429469\n",
      "2878 : Training: loss:  0.04142867\n",
      "2879 : Training: loss:  0.050175317\n",
      "2880 : Training: loss:  0.04473631\n",
      "Validation: Loss:  0.054182068  Accuracy:  0.86538464\n",
      "2881 : Training: loss:  0.031043418\n",
      "2882 : Training: loss:  0.03606097\n",
      "2883 : Training: loss:  0.031009432\n",
      "2884 : Training: loss:  0.043856338\n",
      "2885 : Training: loss:  0.039470162\n",
      "2886 : Training: loss:  0.055048183\n",
      "2887 : Training: loss:  0.02484802\n",
      "2888 : Training: loss:  0.035761315\n",
      "2889 : Training: loss:  0.04051632\n",
      "2890 : Training: loss:  0.028183412\n",
      "2891 : Training: loss:  0.027632914\n",
      "2892 : Training: loss:  0.030134885\n",
      "2893 : Training: loss:  0.047796816\n",
      "2894 : Training: loss:  0.042749483\n",
      "2895 : Training: loss:  0.06426359\n",
      "2896 : Training: loss:  0.038297098\n",
      "2897 : Training: loss:  0.04106874\n",
      "2898 : Training: loss:  0.040184397\n",
      "2899 : Training: loss:  0.03930016\n",
      "2900 : Training: loss:  0.032706548\n",
      "Validation: Loss:  0.05392115  Accuracy:  0.88461536\n",
      "2901 : Training: loss:  0.042149834\n",
      "2902 : Training: loss:  0.03568131\n",
      "2903 : Training: loss:  0.04534082\n",
      "2904 : Training: loss:  0.0461075\n",
      "2905 : Training: loss:  0.035180848\n",
      "2906 : Training: loss:  0.025554068\n",
      "2907 : Training: loss:  0.034257047\n",
      "2908 : Training: loss:  0.050246086\n",
      "2909 : Training: loss:  0.032129105\n",
      "2910 : Training: loss:  0.045502417\n",
      "2911 : Training: loss:  0.03285439\n",
      "2912 : Training: loss:  0.035388365\n",
      "2913 : Training: loss:  0.048280947\n",
      "2914 : Training: loss:  0.0264661\n",
      "2915 : Training: loss:  0.046097074\n",
      "2916 : Training: loss:  0.043434408\n",
      "2917 : Training: loss:  0.03837599\n",
      "2918 : Training: loss:  0.035020508\n",
      "2919 : Training: loss:  0.044322595\n",
      "2920 : Training: loss:  0.038629524\n",
      "Validation: Loss:  0.05372107  Accuracy:  0.86538464\n",
      "2921 : Training: loss:  0.078640275\n",
      "2922 : Training: loss:  0.038755257\n",
      "2923 : Training: loss:  0.045480493\n",
      "2924 : Training: loss:  0.039138697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2925 : Training: loss:  0.028556895\n",
      "2926 : Training: loss:  0.04477318\n",
      "2927 : Training: loss:  0.04084014\n",
      "2928 : Training: loss:  0.031681817\n",
      "2929 : Training: loss:  0.059275355\n",
      "2930 : Training: loss:  0.029746158\n",
      "2931 : Training: loss:  0.050007723\n",
      "2932 : Training: loss:  0.049058065\n",
      "2933 : Training: loss:  0.03559186\n",
      "2934 : Training: loss:  0.042944603\n",
      "2935 : Training: loss:  0.06457916\n",
      "2936 : Training: loss:  0.033350453\n",
      "2937 : Training: loss:  0.053672284\n",
      "2938 : Training: loss:  0.05169104\n",
      "2939 : Training: loss:  0.027034702\n",
      "2940 : Training: loss:  0.031078931\n",
      "Validation: Loss:  0.053519715  Accuracy:  0.86538464\n",
      "2941 : Training: loss:  0.034547612\n",
      "2942 : Training: loss:  0.0409069\n",
      "2943 : Training: loss:  0.026589379\n",
      "2944 : Training: loss:  0.04109868\n",
      "2945 : Training: loss:  0.032488022\n",
      "2946 : Training: loss:  0.04339158\n",
      "2947 : Training: loss:  0.039060645\n",
      "2948 : Training: loss:  0.041535206\n",
      "2949 : Training: loss:  0.02553085\n",
      "2950 : Training: loss:  0.038763165\n",
      "2951 : Training: loss:  0.061633684\n",
      "2952 : Training: loss:  0.034964256\n",
      "2953 : Training: loss:  0.032549456\n",
      "2954 : Training: loss:  0.03956247\n",
      "2955 : Training: loss:  0.030922795\n",
      "2956 : Training: loss:  0.055244144\n",
      "2957 : Training: loss:  0.034260403\n",
      "2958 : Training: loss:  0.04930639\n",
      "2959 : Training: loss:  0.058252234\n",
      "2960 : Training: loss:  0.022683144\n",
      "Validation: Loss:  0.05307347  Accuracy:  0.88461536\n",
      "2961 : Training: loss:  0.023165345\n",
      "2962 : Training: loss:  0.043045726\n",
      "2963 : Training: loss:  0.038376298\n",
      "2964 : Training: loss:  0.043279976\n",
      "2965 : Training: loss:  0.027346103\n",
      "2966 : Training: loss:  0.039489526\n",
      "2967 : Training: loss:  0.034205426\n",
      "2968 : Training: loss:  0.046875644\n",
      "2969 : Training: loss:  0.035458922\n",
      "2970 : Training: loss:  0.038530283\n",
      "2971 : Training: loss:  0.027314255\n",
      "2972 : Training: loss:  0.048330337\n",
      "2973 : Training: loss:  0.024039796\n",
      "2974 : Training: loss:  0.026991328\n",
      "2975 : Training: loss:  0.050118614\n",
      "2976 : Training: loss:  0.027454983\n",
      "2977 : Training: loss:  0.030047914\n",
      "2978 : Training: loss:  0.040009182\n",
      "2979 : Training: loss:  0.03370956\n",
      "2980 : Training: loss:  0.024485532\n",
      "Validation: Loss:  0.052598175  Accuracy:  0.90384614\n",
      "2981 : Training: loss:  0.028799852\n",
      "2982 : Training: loss:  0.028190898\n",
      "2983 : Training: loss:  0.046782557\n",
      "2984 : Training: loss:  0.037986312\n",
      "2985 : Training: loss:  0.03882489\n",
      "2986 : Training: loss:  0.0397445\n",
      "2987 : Training: loss:  0.033920158\n",
      "2988 : Training: loss:  0.026488831\n",
      "2989 : Training: loss:  0.055285685\n",
      "2990 : Training: loss:  0.022842668\n",
      "2991 : Training: loss:  0.041130226\n",
      "2992 : Training: loss:  0.033469643\n",
      "2993 : Training: loss:  0.036485627\n",
      "2994 : Training: loss:  0.028582994\n",
      "2995 : Training: loss:  0.037917823\n",
      "2996 : Training: loss:  0.03779067\n",
      "2997 : Training: loss:  0.04246783\n",
      "2998 : Training: loss:  0.03986365\n",
      "2999 : Training: loss:  0.036246587\n",
      "3000 : Training: loss:  0.037927143\n",
      "Validation: Loss:  0.052233227  Accuracy:  0.90384614\n",
      "3001 : Training: loss:  0.032785773\n",
      "3002 : Training: loss:  0.05685223\n",
      "3003 : Training: loss:  0.037107434\n",
      "3004 : Training: loss:  0.047799967\n",
      "3005 : Training: loss:  0.035949666\n",
      "3006 : Training: loss:  0.046335522\n",
      "3007 : Training: loss:  0.05217347\n",
      "3008 : Training: loss:  0.05345772\n",
      "3009 : Training: loss:  0.033101767\n",
      "3010 : Training: loss:  0.030159326\n",
      "3011 : Training: loss:  0.036177844\n",
      "3012 : Training: loss:  0.03235553\n",
      "3013 : Training: loss:  0.04030958\n",
      "3014 : Training: loss:  0.049069382\n",
      "3015 : Training: loss:  0.02877249\n",
      "3016 : Training: loss:  0.032430377\n",
      "3017 : Training: loss:  0.03257461\n",
      "3018 : Training: loss:  0.037829567\n",
      "3019 : Training: loss:  0.044589844\n",
      "3020 : Training: loss:  0.032577645\n",
      "Validation: Loss:  0.051934227  Accuracy:  0.88461536\n",
      "3021 : Training: loss:  0.040151622\n",
      "3022 : Training: loss:  0.03303606\n",
      "3023 : Training: loss:  0.03623795\n",
      "3024 : Training: loss:  0.029623397\n",
      "3025 : Training: loss:  0.054933935\n",
      "3026 : Training: loss:  0.046764746\n",
      "3027 : Training: loss:  0.03670108\n",
      "3028 : Training: loss:  0.040673647\n",
      "3029 : Training: loss:  0.0490979\n",
      "3030 : Training: loss:  0.03030564\n",
      "3031 : Training: loss:  0.038992215\n",
      "3032 : Training: loss:  0.07368895\n",
      "3033 : Training: loss:  0.033173617\n",
      "3034 : Training: loss:  0.056767914\n",
      "3035 : Training: loss:  0.03611415\n",
      "3036 : Training: loss:  0.03259592\n",
      "3037 : Training: loss:  0.049671713\n",
      "3038 : Training: loss:  0.034768973\n",
      "3039 : Training: loss:  0.041906312\n",
      "3040 : Training: loss:  0.031164398\n",
      "Validation: Loss:  0.051426392  Accuracy:  0.90384614\n",
      "3041 : Training: loss:  0.026585186\n",
      "3042 : Training: loss:  0.034451947\n",
      "3043 : Training: loss:  0.034311738\n",
      "3044 : Training: loss:  0.030040229\n",
      "3045 : Training: loss:  0.03023394\n",
      "3046 : Training: loss:  0.023656039\n",
      "3047 : Training: loss:  0.02204036\n",
      "3048 : Training: loss:  0.06440219\n",
      "3049 : Training: loss:  0.050463416\n",
      "3050 : Training: loss:  0.021491395\n",
      "3051 : Training: loss:  0.041453034\n",
      "3052 : Training: loss:  0.029101236\n",
      "3053 : Training: loss:  0.051189676\n",
      "3054 : Training: loss:  0.037248988\n",
      "3055 : Training: loss:  0.029117992\n",
      "3056 : Training: loss:  0.032689508\n",
      "3057 : Training: loss:  0.048067976\n",
      "3058 : Training: loss:  0.039683007\n",
      "3059 : Training: loss:  0.029470412\n",
      "3060 : Training: loss:  0.052965768\n",
      "Validation: Loss:  0.0510316  Accuracy:  0.90384614\n",
      "3061 : Training: loss:  0.035128232\n",
      "3062 : Training: loss:  0.029992236\n",
      "3063 : Training: loss:  0.046668928\n",
      "3064 : Training: loss:  0.021535734\n",
      "3065 : Training: loss:  0.030002078\n",
      "3066 : Training: loss:  0.034512136\n",
      "3067 : Training: loss:  0.04165073\n",
      "3068 : Training: loss:  0.03758431\n",
      "3069 : Training: loss:  0.03168427\n",
      "3070 : Training: loss:  0.041999746\n",
      "3071 : Training: loss:  0.03841596\n",
      "3072 : Training: loss:  0.04575415\n",
      "3073 : Training: loss:  0.030175908\n",
      "3074 : Training: loss:  0.03254309\n",
      "3075 : Training: loss:  0.03762284\n",
      "3076 : Training: loss:  0.020114778\n",
      "3077 : Training: loss:  0.020843534\n",
      "3078 : Training: loss:  0.034292016\n",
      "3079 : Training: loss:  0.037954334\n",
      "3080 : Training: loss:  0.027349062\n",
      "Validation: Loss:  0.05060387  Accuracy:  0.90384614\n",
      "3081 : Training: loss:  0.037390705\n",
      "3082 : Training: loss:  0.03427996\n",
      "3083 : Training: loss:  0.039946828\n",
      "3084 : Training: loss:  0.035124388\n",
      "3085 : Training: loss:  0.048614327\n",
      "3086 : Training: loss:  0.03148456\n",
      "3087 : Training: loss:  0.045939956\n",
      "3088 : Training: loss:  0.03431812\n",
      "3089 : Training: loss:  0.043918986\n",
      "3090 : Training: loss:  0.04332402\n",
      "3091 : Training: loss:  0.027070932\n",
      "3092 : Training: loss:  0.044996947\n",
      "3093 : Training: loss:  0.039699465\n",
      "3094 : Training: loss:  0.032056753\n",
      "3095 : Training: loss:  0.050717037\n",
      "3096 : Training: loss:  0.030837893\n",
      "3097 : Training: loss:  0.03153178\n",
      "3098 : Training: loss:  0.041120723\n",
      "3099 : Training: loss:  0.033920918\n",
      "3100 : Training: loss:  0.052339204\n",
      "Validation: Loss:  0.050147805  Accuracy:  0.90384614\n",
      "3101 : Training: loss:  0.03456516\n",
      "3102 : Training: loss:  0.038563654\n",
      "3103 : Training: loss:  0.042417314\n",
      "3104 : Training: loss:  0.056069043\n",
      "3105 : Training: loss:  0.03699995\n",
      "3106 : Training: loss:  0.029901076\n",
      "3107 : Training: loss:  0.041991744\n",
      "3108 : Training: loss:  0.032961965\n",
      "3109 : Training: loss:  0.032596227\n",
      "3110 : Training: loss:  0.06948854\n",
      "3111 : Training: loss:  0.03359024\n",
      "3112 : Training: loss:  0.033193666\n",
      "3113 : Training: loss:  0.03059925\n",
      "3114 : Training: loss:  0.0433044\n",
      "3115 : Training: loss:  0.04598062\n",
      "3116 : Training: loss:  0.038572047\n",
      "3117 : Training: loss:  0.04015167\n",
      "3118 : Training: loss:  0.039531842\n",
      "3119 : Training: loss:  0.038467128\n",
      "3120 : Training: loss:  0.029224515\n",
      "Validation: Loss:  0.049941592  Accuracy:  0.90384614\n",
      "3121 : Training: loss:  0.03141944\n",
      "3122 : Training: loss:  0.027076185\n",
      "3123 : Training: loss:  0.03781182\n",
      "3124 : Training: loss:  0.056434575\n",
      "3125 : Training: loss:  0.035685778\n",
      "3126 : Training: loss:  0.048707105\n",
      "3127 : Training: loss:  0.029804377\n",
      "3128 : Training: loss:  0.031380188\n",
      "3129 : Training: loss:  0.03232075\n",
      "3130 : Training: loss:  0.047690887\n",
      "3131 : Training: loss:  0.023398172\n",
      "3132 : Training: loss:  0.036652066\n",
      "3133 : Training: loss:  0.049219247\n",
      "3134 : Training: loss:  0.02709017\n",
      "3135 : Training: loss:  0.0500499\n",
      "3136 : Training: loss:  0.022031523\n",
      "3137 : Training: loss:  0.03454667\n",
      "3138 : Training: loss:  0.03008561\n",
      "3139 : Training: loss:  0.027474761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3140 : Training: loss:  0.031149054\n",
      "Validation: Loss:  0.049725827  Accuracy:  0.88461536\n",
      "3141 : Training: loss:  0.041983455\n",
      "3142 : Training: loss:  0.027029525\n",
      "3143 : Training: loss:  0.053011745\n",
      "3144 : Training: loss:  0.021694617\n",
      "3145 : Training: loss:  0.03825121\n",
      "3146 : Training: loss:  0.033793636\n",
      "3147 : Training: loss:  0.024713414\n",
      "3148 : Training: loss:  0.028037013\n",
      "3149 : Training: loss:  0.026618699\n",
      "3150 : Training: loss:  0.026438866\n",
      "3151 : Training: loss:  0.034817617\n",
      "3152 : Training: loss:  0.036121376\n",
      "3153 : Training: loss:  0.043017484\n",
      "3154 : Training: loss:  0.035635874\n",
      "3155 : Training: loss:  0.04142039\n",
      "3156 : Training: loss:  0.036409434\n",
      "3157 : Training: loss:  0.024769219\n",
      "3158 : Training: loss:  0.041340474\n",
      "3159 : Training: loss:  0.026658645\n",
      "3160 : Training: loss:  0.034837183\n",
      "Validation: Loss:  0.049333442  Accuracy:  0.90384614\n",
      "3161 : Training: loss:  0.030562079\n",
      "3162 : Training: loss:  0.041916996\n",
      "3163 : Training: loss:  0.02534277\n",
      "3164 : Training: loss:  0.046654698\n",
      "3165 : Training: loss:  0.03965321\n",
      "3166 : Training: loss:  0.027716493\n",
      "3167 : Training: loss:  0.02950168\n",
      "3168 : Training: loss:  0.023440717\n",
      "3169 : Training: loss:  0.02603674\n",
      "3170 : Training: loss:  0.041029118\n",
      "3171 : Training: loss:  0.02354792\n",
      "3172 : Training: loss:  0.037686802\n",
      "3173 : Training: loss:  0.03193241\n",
      "3174 : Training: loss:  0.03417476\n",
      "3175 : Training: loss:  0.025738861\n",
      "3176 : Training: loss:  0.041663572\n",
      "3177 : Training: loss:  0.035549905\n",
      "3178 : Training: loss:  0.024662158\n",
      "3179 : Training: loss:  0.024783902\n",
      "3180 : Training: loss:  0.027607115\n",
      "Validation: Loss:  0.049043786  Accuracy:  0.90384614\n",
      "3181 : Training: loss:  0.043994144\n",
      "3182 : Training: loss:  0.027646579\n",
      "3183 : Training: loss:  0.04585166\n",
      "3184 : Training: loss:  0.030869082\n",
      "3185 : Training: loss:  0.029932704\n",
      "3186 : Training: loss:  0.03717566\n",
      "3187 : Training: loss:  0.031879205\n",
      "3188 : Training: loss:  0.0376583\n",
      "3189 : Training: loss:  0.036022022\n",
      "3190 : Training: loss:  0.054498125\n",
      "3191 : Training: loss:  0.032142624\n",
      "3192 : Training: loss:  0.044087615\n",
      "3193 : Training: loss:  0.040848345\n",
      "3194 : Training: loss:  0.032490406\n",
      "3195 : Training: loss:  0.04913281\n",
      "3196 : Training: loss:  0.02934138\n",
      "3197 : Training: loss:  0.028185783\n",
      "3198 : Training: loss:  0.041027937\n",
      "3199 : Training: loss:  0.027366877\n",
      "3200 : Training: loss:  0.028616311\n",
      "Validation: Loss:  0.048645437  Accuracy:  0.90384614\n",
      "3201 : Training: loss:  0.032573566\n",
      "3202 : Training: loss:  0.042200066\n",
      "3203 : Training: loss:  0.04559806\n",
      "3204 : Training: loss:  0.03221073\n",
      "3205 : Training: loss:  0.034914613\n",
      "3206 : Training: loss:  0.027368417\n",
      "3207 : Training: loss:  0.033167668\n",
      "3208 : Training: loss:  0.028017389\n",
      "3209 : Training: loss:  0.021526823\n",
      "3210 : Training: loss:  0.038059957\n",
      "3211 : Training: loss:  0.03545585\n",
      "3212 : Training: loss:  0.042834464\n",
      "3213 : Training: loss:  0.026576135\n",
      "3214 : Training: loss:  0.024574926\n",
      "3215 : Training: loss:  0.03627717\n",
      "3216 : Training: loss:  0.030323414\n",
      "3217 : Training: loss:  0.029925644\n",
      "3218 : Training: loss:  0.027690733\n",
      "3219 : Training: loss:  0.033770483\n",
      "3220 : Training: loss:  0.030122561\n",
      "Validation: Loss:  0.04832404  Accuracy:  0.9230769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.4521, 0.003, 0.0014, 0.0052, 0.0006, 0.0033...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.048324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.4798, 0.0056, 0.0018, 0.0053, 0.0022, 0.002...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.7398, 0.0337, 0.0014, 0.0091, 0.0017, 0.175...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1101, 0.4506, 0.0022, 0.0029, 0.0164, 0.041...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.012, 0.4352, 0.0107, 0.001, 0.0233, 0.0389,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0006, 0.0094, 0.6729, 0.0006, 0.0079, 0.008...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0057, 0.0028, 0.0018, 0.5529, 0.051, 0.0062...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0017, 0.001, 0.0039, 0.6342, 0.0143, 0.0019...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0144, 0.0017, 0.0034, 0.6985, 0.0034, 0.002...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.016, 0.0601, 0.0003, 0.01, 0.1378, 0.1928, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0251, 0.3531, 0.0077, 0.0024, 0.3636, 0.288...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0161, 0.0378, 0.0007, 0.001, 0.0228, 0.5702...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0069, 0.017, 0.0364, 0.0003, 0.0005, 0.0187...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0657, 0.0132, 0.0234, 0.0023, 0.0037, 0.024...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0106, 0.1479, 0.0004, 0.0011, 0.0545, 0.013...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0107, 0.0036, 1e-04, 0.0123, 0.0201, 0.0026...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0082, 0.0043, 0.0377, 0.0244, 0.0021, 0.000...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0027, 0.0057, 0.0647, 0.0019, 0.005, 0.0067...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0034, 0.0044, 0.0338, 0.0005, 0.0397, 0.003...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0039, 0.0074, 0.0222, 0.0005, 0.0356, 0.007...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0109, 0.006, 0.0036, 0.0014, 0.0016, 0.0011...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0038, 0.0091, 0.0078, 0.0146, 0.0531, 0.003...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0036, 0.0208, 0.0025, 0.0036, 0.0039, 0.003...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0008, 0.0021, 0.0082, 0.0152, 0.0444, 0.033...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0003, 0.0015, 0.0279, 0.0124, 0.0272, 0.023...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0014, 0.0016, 0.0058, 0.0361, 0.0374, 0.001...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0008, 0.0008, 0.0045, 0.0237, 0.012, 0.0004...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0004, 0.0313, 0.0033, 0.0011, 0.0236, 0.019...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[1e-04, 0.0914, 0.026, 0.0104, 0.1286, 0.0409,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0005, 0.0242, 0.0016, 0.0029, 0.0722, 0.009...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.3501, 0.0221, 0.0045, 0.0057, 0.0199, 0.027...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0149, 0.0123, 0.0102, 0.0407, 0.0044, 0.004...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0135, 0.0035, 0.0561, 0.0948, 0.0136, 0.002...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0054, 0.0013, 0.0084, 0.0015, 0.0101, 0.000...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0016, 0.0163, 0.0017, 0.0163, 0.0366, 0.011...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0078, 0.0034, 0.0431, 0.001, 0.0017, 0.0025...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0179, 0.0242, 0.0018, 0.0033, 0.001, 0.0222...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0251, 0.0061, 0.0019, 0.0119, 0.0013, 0.002...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0025, 0.0058, 0.0303, 0.0043, 0.0009, 0.031...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0049, 0.0127, 0.0053, 0.0066, 0.0012, 0.007...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0034, 0.0054, 0.0073, 0.0269, 0.0009, 0.008...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0021, 0.0053, 0.0079, 0.0104, 0.0013, 0.004...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0019, 0.0036, 0.0044, 0.0053, 0.0015, 0.000...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0081, 0.0036, 0.0076, 0.0006, 0.0138, 0.002...</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0031, 0.0069, 0.0167, 0.0036, 0.0065, 0.000...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.0576, 0.0083, 0.0045, 0.2279, 0.0415, 0.007...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0003, 0.0056, 0.0084, 0.017, 0.0142, 0.0108...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0033, 0.0028, 0.0045, 0.0168, 0.011, 0.0331...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0055, 0.1067, 0.0015, 0.0025, 0.0274, 0.036...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0024, 0.11, 0.001, 0.0026, 0.0224, 0.0781, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.4431, 0.0026, 0.0014, 0.0049, 0.0022, 0.000...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0028, 0.0053, 0.0041, 0.0211, 0.2243, 0.000...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.4521, 0.003, 0.0014, 0.0052, 0.0006, 0.0033...               0   \n",
       "1   [0.4798, 0.0056, 0.0018, 0.0053, 0.0022, 0.002...               0   \n",
       "2   [0.7398, 0.0337, 0.0014, 0.0091, 0.0017, 0.175...               0   \n",
       "3   [0.1101, 0.4506, 0.0022, 0.0029, 0.0164, 0.041...               1   \n",
       "4   [0.012, 0.4352, 0.0107, 0.001, 0.0233, 0.0389,...               1   \n",
       "5   [0.0006, 0.0094, 0.6729, 0.0006, 0.0079, 0.008...               2   \n",
       "6   [0.0057, 0.0028, 0.0018, 0.5529, 0.051, 0.0062...               3   \n",
       "7   [0.0017, 0.001, 0.0039, 0.6342, 0.0143, 0.0019...               3   \n",
       "8   [0.0144, 0.0017, 0.0034, 0.6985, 0.0034, 0.002...               3   \n",
       "9   [0.016, 0.0601, 0.0003, 0.01, 0.1378, 0.1928, ...               4   \n",
       "10  [0.0251, 0.3531, 0.0077, 0.0024, 0.3636, 0.288...               4   \n",
       "11  [0.0161, 0.0378, 0.0007, 0.001, 0.0228, 0.5702...               5   \n",
       "12  [0.0069, 0.017, 0.0364, 0.0003, 0.0005, 0.0187...               6   \n",
       "13  [0.0657, 0.0132, 0.0234, 0.0023, 0.0037, 0.024...               7   \n",
       "14  [0.0106, 0.1479, 0.0004, 0.0011, 0.0545, 0.013...               8   \n",
       "15  [0.0107, 0.0036, 1e-04, 0.0123, 0.0201, 0.0026...               8   \n",
       "16  [0.0082, 0.0043, 0.0377, 0.0244, 0.0021, 0.000...               9   \n",
       "17  [0.0027, 0.0057, 0.0647, 0.0019, 0.005, 0.0067...               9   \n",
       "18  [0.0034, 0.0044, 0.0338, 0.0005, 0.0397, 0.003...              10   \n",
       "19  [0.0039, 0.0074, 0.0222, 0.0005, 0.0356, 0.007...              10   \n",
       "20  [0.0109, 0.006, 0.0036, 0.0014, 0.0016, 0.0011...              11   \n",
       "21  [0.0038, 0.0091, 0.0078, 0.0146, 0.0531, 0.003...              11   \n",
       "22  [0.0036, 0.0208, 0.0025, 0.0036, 0.0039, 0.003...              12   \n",
       "23  [0.0008, 0.0021, 0.0082, 0.0152, 0.0444, 0.033...              13   \n",
       "24  [0.0003, 0.0015, 0.0279, 0.0124, 0.0272, 0.023...              13   \n",
       "25  [0.0014, 0.0016, 0.0058, 0.0361, 0.0374, 0.001...              14   \n",
       "26  [0.0008, 0.0008, 0.0045, 0.0237, 0.012, 0.0004...              14   \n",
       "27  [0.0004, 0.0313, 0.0033, 0.0011, 0.0236, 0.019...              15   \n",
       "28  [1e-04, 0.0914, 0.026, 0.0104, 0.1286, 0.0409,...              15   \n",
       "29  [0.0005, 0.0242, 0.0016, 0.0029, 0.0722, 0.009...              15   \n",
       "30  [0.3501, 0.0221, 0.0045, 0.0057, 0.0199, 0.027...              16   \n",
       "31  [0.0149, 0.0123, 0.0102, 0.0407, 0.0044, 0.004...              17   \n",
       "32  [0.0135, 0.0035, 0.0561, 0.0948, 0.0136, 0.002...              17   \n",
       "33  [0.0054, 0.0013, 0.0084, 0.0015, 0.0101, 0.000...              18   \n",
       "34  [0.0016, 0.0163, 0.0017, 0.0163, 0.0366, 0.011...              19   \n",
       "35  [0.0078, 0.0034, 0.0431, 0.001, 0.0017, 0.0025...              20   \n",
       "36  [0.0179, 0.0242, 0.0018, 0.0033, 0.001, 0.0222...              21   \n",
       "37  [0.0251, 0.0061, 0.0019, 0.0119, 0.0013, 0.002...              21   \n",
       "38  [0.0025, 0.0058, 0.0303, 0.0043, 0.0009, 0.031...              22   \n",
       "39  [0.0049, 0.0127, 0.0053, 0.0066, 0.0012, 0.007...              22   \n",
       "40  [0.0034, 0.0054, 0.0073, 0.0269, 0.0009, 0.008...              22   \n",
       "41  [0.0021, 0.0053, 0.0079, 0.0104, 0.0013, 0.004...              22   \n",
       "42  [0.0019, 0.0036, 0.0044, 0.0053, 0.0015, 0.000...              23   \n",
       "43  [0.0081, 0.0036, 0.0076, 0.0006, 0.0138, 0.002...              23   \n",
       "44  [0.0031, 0.0069, 0.0167, 0.0036, 0.0065, 0.000...              23   \n",
       "45  [0.0576, 0.0083, 0.0045, 0.2279, 0.0415, 0.007...              23   \n",
       "46  [0.0003, 0.0056, 0.0084, 0.017, 0.0142, 0.0108...              24   \n",
       "47  [0.0033, 0.0028, 0.0045, 0.0168, 0.011, 0.0331...              24   \n",
       "48  [0.0055, 0.1067, 0.0015, 0.0025, 0.0274, 0.036...              25   \n",
       "49  [0.0024, 0.11, 0.001, 0.0026, 0.0224, 0.0781, ...              25   \n",
       "50  [0.4431, 0.0026, 0.0014, 0.0049, 0.0022, 0.000...              26   \n",
       "51  [0.0028, 0.0053, 0.0041, 0.0211, 0.2243, 0.000...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.923077  0.048324  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                  1       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                  2       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                 25       NaN       NaN  \n",
       "10                 4       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                11       NaN       NaN  \n",
       "21                11       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                16       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                20       NaN       NaN  \n",
       "36                21       NaN       NaN  \n",
       "37                21       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                 8       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3221 : Training: loss:  0.043670945\n",
      "3222 : Training: loss:  0.018350486\n",
      "3223 : Training: loss:  0.045157477\n",
      "3224 : Training: loss:  0.03332185\n",
      "3225 : Training: loss:  0.034724977\n",
      "3226 : Training: loss:  0.02982752\n",
      "3227 : Training: loss:  0.04967487\n",
      "3228 : Training: loss:  0.03566352\n",
      "3229 : Training: loss:  0.024007307\n",
      "3230 : Training: loss:  0.040504124\n",
      "3231 : Training: loss:  0.028270887\n",
      "3232 : Training: loss:  0.020467404\n",
      "3233 : Training: loss:  0.03979856\n",
      "3234 : Training: loss:  0.048622295\n",
      "3235 : Training: loss:  0.032695957\n",
      "3236 : Training: loss:  0.03964483\n",
      "3237 : Training: loss:  0.02224169\n",
      "3238 : Training: loss:  0.041883565\n",
      "3239 : Training: loss:  0.038357444\n",
      "3240 : Training: loss:  0.041758265\n",
      "Validation: Loss:  0.047999557  Accuracy:  0.90384614\n",
      "3241 : Training: loss:  0.021779202\n",
      "3242 : Training: loss:  0.032667466\n",
      "3243 : Training: loss:  0.03287253\n",
      "3244 : Training: loss:  0.047281798\n",
      "3245 : Training: loss:  0.029347125\n",
      "3246 : Training: loss:  0.028820276\n",
      "3247 : Training: loss:  0.038489122\n",
      "3248 : Training: loss:  0.03612502\n",
      "3249 : Training: loss:  0.045897275\n",
      "3250 : Training: loss:  0.04387184\n",
      "3251 : Training: loss:  0.02698704\n",
      "3252 : Training: loss:  0.03748546\n",
      "3253 : Training: loss:  0.045777816\n",
      "3254 : Training: loss:  0.023459729\n",
      "3255 : Training: loss:  0.043374985\n",
      "3256 : Training: loss:  0.02831086\n",
      "3257 : Training: loss:  0.05525684\n",
      "3258 : Training: loss:  0.037271302\n",
      "3259 : Training: loss:  0.028733058\n",
      "3260 : Training: loss:  0.04424796\n",
      "Validation: Loss:  0.04767328  Accuracy:  0.90384614\n",
      "3261 : Training: loss:  0.034481887\n",
      "3262 : Training: loss:  0.032554172\n",
      "3263 : Training: loss:  0.030041037\n",
      "3264 : Training: loss:  0.03402171\n",
      "3265 : Training: loss:  0.053402666\n",
      "3266 : Training: loss:  0.03763969\n",
      "3267 : Training: loss:  0.017893786\n",
      "3268 : Training: loss:  0.033156388\n",
      "3269 : Training: loss:  0.03441376\n",
      "3270 : Training: loss:  0.03925915\n",
      "3271 : Training: loss:  0.03126684\n",
      "3272 : Training: loss:  0.04290808\n",
      "3273 : Training: loss:  0.035766944\n",
      "3274 : Training: loss:  0.030770821\n",
      "3275 : Training: loss:  0.028477049\n",
      "3276 : Training: loss:  0.0674094\n",
      "3277 : Training: loss:  0.04756728\n",
      "3278 : Training: loss:  0.046674542\n",
      "3279 : Training: loss:  0.027121687\n",
      "3280 : Training: loss:  0.050787956\n",
      "Validation: Loss:  0.047373746  Accuracy:  0.90384614\n",
      "3281 : Training: loss:  0.03230988\n",
      "3282 : Training: loss:  0.0523739\n",
      "3283 : Training: loss:  0.025674919\n",
      "3284 : Training: loss:  0.042480614\n",
      "3285 : Training: loss:  0.026200112\n",
      "3286 : Training: loss:  0.034539755\n",
      "3287 : Training: loss:  0.040528577\n",
      "3288 : Training: loss:  0.033477847\n",
      "3289 : Training: loss:  0.03186499\n",
      "3290 : Training: loss:  0.026590029\n",
      "3291 : Training: loss:  0.0321432\n",
      "3292 : Training: loss:  0.026952071\n",
      "3293 : Training: loss:  0.031737134\n",
      "3294 : Training: loss:  0.033928808\n",
      "3295 : Training: loss:  0.029635234\n",
      "3296 : Training: loss:  0.035610363\n",
      "3297 : Training: loss:  0.04861261\n",
      "3298 : Training: loss:  0.034081895\n",
      "3299 : Training: loss:  0.04679572\n",
      "3300 : Training: loss:  0.043259986\n",
      "Validation: Loss:  0.046928924  Accuracy:  0.90384614\n",
      "3301 : Training: loss:  0.030806351\n",
      "3302 : Training: loss:  0.031623997\n",
      "3303 : Training: loss:  0.034033056\n",
      "3304 : Training: loss:  0.034952708\n",
      "3305 : Training: loss:  0.023846226\n",
      "3306 : Training: loss:  0.032724973\n",
      "3307 : Training: loss:  0.031459067\n",
      "3308 : Training: loss:  0.024423419\n",
      "3309 : Training: loss:  0.020138444\n",
      "3310 : Training: loss:  0.022872053\n",
      "3311 : Training: loss:  0.030326936\n",
      "3312 : Training: loss:  0.03354425\n",
      "3313 : Training: loss:  0.02851639\n",
      "3314 : Training: loss:  0.04672978\n",
      "3315 : Training: loss:  0.036651667\n",
      "3316 : Training: loss:  0.032752663\n",
      "3317 : Training: loss:  0.044621754\n",
      "3318 : Training: loss:  0.03818991\n",
      "3319 : Training: loss:  0.026711026\n",
      "3320 : Training: loss:  0.021144403\n",
      "Validation: Loss:  0.046517737  Accuracy:  0.90384614\n",
      "3321 : Training: loss:  0.027100185\n",
      "3322 : Training: loss:  0.04295581\n",
      "3323 : Training: loss:  0.020109858\n",
      "3324 : Training: loss:  0.027841842\n",
      "3325 : Training: loss:  0.025390634\n",
      "3326 : Training: loss:  0.027190724\n",
      "3327 : Training: loss:  0.0300284\n",
      "3328 : Training: loss:  0.024194824\n",
      "3329 : Training: loss:  0.027953155\n",
      "3330 : Training: loss:  0.032343157\n",
      "3331 : Training: loss:  0.028101323\n",
      "3332 : Training: loss:  0.032328717\n",
      "3333 : Training: loss:  0.027080832\n",
      "3334 : Training: loss:  0.039483953\n",
      "3335 : Training: loss:  0.032913394\n",
      "3336 : Training: loss:  0.026261883\n",
      "3337 : Training: loss:  0.04794235\n",
      "3338 : Training: loss:  0.02021886\n",
      "3339 : Training: loss:  0.03489608\n",
      "3340 : Training: loss:  0.017178131\n",
      "Validation: Loss:  0.046241313  Accuracy:  0.90384614\n",
      "3341 : Training: loss:  0.030382536\n",
      "3342 : Training: loss:  0.026351348\n",
      "3343 : Training: loss:  0.033560447\n",
      "3344 : Training: loss:  0.028968701\n",
      "3345 : Training: loss:  0.03999196\n",
      "3346 : Training: loss:  0.038608685\n",
      "3347 : Training: loss:  0.0255964\n",
      "3348 : Training: loss:  0.026348028\n",
      "3349 : Training: loss:  0.03655806\n",
      "3350 : Training: loss:  0.046189155\n",
      "3351 : Training: loss:  0.038666993\n",
      "3352 : Training: loss:  0.052226357\n",
      "3353 : Training: loss:  0.02981236\n",
      "3354 : Training: loss:  0.032626323\n",
      "3355 : Training: loss:  0.043606862\n",
      "3356 : Training: loss:  0.02032874\n",
      "3357 : Training: loss:  0.020800665\n",
      "3358 : Training: loss:  0.036080886\n",
      "3359 : Training: loss:  0.03187284\n",
      "3360 : Training: loss:  0.031360976\n",
      "Validation: Loss:  0.04578933  Accuracy:  0.9230769\n",
      "3361 : Training: loss:  0.027248302\n",
      "3362 : Training: loss:  0.02870454\n",
      "3363 : Training: loss:  0.03494851\n",
      "3364 : Training: loss:  0.023920659\n",
      "3365 : Training: loss:  0.03622505\n",
      "3366 : Training: loss:  0.036963064\n",
      "3367 : Training: loss:  0.02848362\n",
      "3368 : Training: loss:  0.02560636\n",
      "3369 : Training: loss:  0.02609652\n",
      "3370 : Training: loss:  0.038982436\n",
      "3371 : Training: loss:  0.030763099\n",
      "3372 : Training: loss:  0.025570719\n",
      "3373 : Training: loss:  0.026681073\n",
      "3374 : Training: loss:  0.03565766\n",
      "3375 : Training: loss:  0.0367677\n",
      "3376 : Training: loss:  0.023201508\n",
      "3377 : Training: loss:  0.03081463\n",
      "3378 : Training: loss:  0.037989665\n",
      "3379 : Training: loss:  0.027551055\n",
      "3380 : Training: loss:  0.025299171\n",
      "Validation: Loss:  0.04550075  Accuracy:  0.9230769\n",
      "3381 : Training: loss:  0.033136312\n",
      "3382 : Training: loss:  0.030841077\n",
      "3383 : Training: loss:  0.03204965\n",
      "3384 : Training: loss:  0.028956952\n",
      "3385 : Training: loss:  0.027898498\n",
      "3386 : Training: loss:  0.0493326\n",
      "3387 : Training: loss:  0.04306319\n",
      "3388 : Training: loss:  0.042747002\n",
      "3389 : Training: loss:  0.036124367\n",
      "3390 : Training: loss:  0.034775965\n",
      "3391 : Training: loss:  0.024950335\n",
      "3392 : Training: loss:  0.028986529\n",
      "3393 : Training: loss:  0.03297576\n",
      "3394 : Training: loss:  0.028467616\n",
      "3395 : Training: loss:  0.03461667\n",
      "3396 : Training: loss:  0.026491579\n",
      "3397 : Training: loss:  0.03193963\n",
      "3398 : Training: loss:  0.021885373\n",
      "3399 : Training: loss:  0.035103224\n",
      "3400 : Training: loss:  0.020374833\n",
      "Validation: Loss:  0.045366883  Accuracy:  0.9230769\n",
      "3401 : Training: loss:  0.033710834\n",
      "3402 : Training: loss:  0.03132083\n",
      "3403 : Training: loss:  0.016160822\n",
      "3404 : Training: loss:  0.023868384\n",
      "3405 : Training: loss:  0.0259693\n",
      "3406 : Training: loss:  0.044780858\n",
      "3407 : Training: loss:  0.024435496\n",
      "3408 : Training: loss:  0.027748875\n",
      "3409 : Training: loss:  0.0271023\n",
      "3410 : Training: loss:  0.03618894\n",
      "3411 : Training: loss:  0.030058825\n",
      "3412 : Training: loss:  0.02925153\n",
      "3413 : Training: loss:  0.03533412\n",
      "3414 : Training: loss:  0.02826911\n",
      "3415 : Training: loss:  0.038567327\n",
      "3416 : Training: loss:  0.025910534\n",
      "3417 : Training: loss:  0.034629647\n",
      "3418 : Training: loss:  0.02363732\n",
      "3419 : Training: loss:  0.0377589\n",
      "3420 : Training: loss:  0.025478099\n",
      "Validation: Loss:  0.045256145  Accuracy:  0.90384614\n",
      "3421 : Training: loss:  0.03318018\n",
      "3422 : Training: loss:  0.030989978\n",
      "3423 : Training: loss:  0.03103142\n",
      "3424 : Training: loss:  0.028567923\n",
      "3425 : Training: loss:  0.03314639\n",
      "3426 : Training: loss:  0.037813324\n",
      "3427 : Training: loss:  0.023662189\n",
      "3428 : Training: loss:  0.030552331\n",
      "3429 : Training: loss:  0.049787555\n",
      "3430 : Training: loss:  0.036219582\n",
      "3431 : Training: loss:  0.02597967\n",
      "3432 : Training: loss:  0.022373574\n",
      "3433 : Training: loss:  0.026270555\n",
      "3434 : Training: loss:  0.025901094\n",
      "3435 : Training: loss:  0.04975819\n",
      "3436 : Training: loss:  0.018691313\n",
      "3437 : Training: loss:  0.04017019\n",
      "3438 : Training: loss:  0.033528592\n",
      "3439 : Training: loss:  0.029351547\n",
      "3440 : Training: loss:  0.024047362\n",
      "Validation: Loss:  0.04513208  Accuracy:  0.90384614\n",
      "3441 : Training: loss:  0.02941709\n",
      "3442 : Training: loss:  0.027771976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3443 : Training: loss:  0.03427587\n",
      "3444 : Training: loss:  0.021818934\n",
      "3445 : Training: loss:  0.035814285\n",
      "3446 : Training: loss:  0.01899778\n",
      "3447 : Training: loss:  0.025093481\n",
      "3448 : Training: loss:  0.019208847\n",
      "3449 : Training: loss:  0.025260316\n",
      "3450 : Training: loss:  0.031972025\n",
      "3451 : Training: loss:  0.032276765\n",
      "3452 : Training: loss:  0.021760667\n",
      "3453 : Training: loss:  0.028966187\n",
      "3454 : Training: loss:  0.045067064\n",
      "3455 : Training: loss:  0.030794334\n",
      "3456 : Training: loss:  0.03146086\n",
      "3457 : Training: loss:  0.022170063\n",
      "3458 : Training: loss:  0.032464024\n",
      "3459 : Training: loss:  0.027800785\n",
      "3460 : Training: loss:  0.023797857\n",
      "Validation: Loss:  0.04492507  Accuracy:  0.90384614\n",
      "3461 : Training: loss:  0.021384332\n",
      "3462 : Training: loss:  0.038462225\n",
      "3463 : Training: loss:  0.025707928\n",
      "3464 : Training: loss:  0.025834503\n",
      "3465 : Training: loss:  0.030437192\n",
      "3466 : Training: loss:  0.029435078\n",
      "3467 : Training: loss:  0.026645735\n",
      "3468 : Training: loss:  0.031978697\n",
      "3469 : Training: loss:  0.024661854\n",
      "3470 : Training: loss:  0.024582734\n",
      "3471 : Training: loss:  0.024672711\n",
      "3472 : Training: loss:  0.03257442\n",
      "3473 : Training: loss:  0.029303132\n",
      "3474 : Training: loss:  0.040430322\n",
      "3475 : Training: loss:  0.032165356\n",
      "3476 : Training: loss:  0.03283399\n",
      "3477 : Training: loss:  0.029789766\n",
      "3478 : Training: loss:  0.03373058\n",
      "3479 : Training: loss:  0.031851884\n",
      "3480 : Training: loss:  0.027773485\n",
      "Validation: Loss:  0.044629604  Accuracy:  0.90384614\n",
      "3481 : Training: loss:  0.031991456\n",
      "3482 : Training: loss:  0.021801004\n",
      "3483 : Training: loss:  0.0358305\n",
      "3484 : Training: loss:  0.021107651\n",
      "3485 : Training: loss:  0.030600287\n",
      "3486 : Training: loss:  0.02439634\n",
      "3487 : Training: loss:  0.040246725\n",
      "3488 : Training: loss:  0.03135535\n",
      "3489 : Training: loss:  0.026460193\n",
      "3490 : Training: loss:  0.029826477\n",
      "3491 : Training: loss:  0.022366079\n",
      "3492 : Training: loss:  0.025187135\n",
      "3493 : Training: loss:  0.022265596\n",
      "3494 : Training: loss:  0.036231544\n",
      "3495 : Training: loss:  0.022208082\n",
      "3496 : Training: loss:  0.027517676\n",
      "3497 : Training: loss:  0.02548627\n",
      "3498 : Training: loss:  0.03138736\n",
      "3499 : Training: loss:  0.028663024\n",
      "3500 : Training: loss:  0.032143738\n",
      "Validation: Loss:  0.04430829  Accuracy:  0.9230769\n",
      "3501 : Training: loss:  0.024460517\n",
      "3502 : Training: loss:  0.029741824\n",
      "3503 : Training: loss:  0.03338849\n",
      "3504 : Training: loss:  0.02267541\n",
      "3505 : Training: loss:  0.03425037\n",
      "3506 : Training: loss:  0.029769693\n",
      "3507 : Training: loss:  0.02246749\n",
      "3508 : Training: loss:  0.03447303\n",
      "3509 : Training: loss:  0.029376421\n",
      "3510 : Training: loss:  0.021956047\n",
      "3511 : Training: loss:  0.019586869\n",
      "3512 : Training: loss:  0.03191858\n",
      "3513 : Training: loss:  0.03170398\n",
      "3514 : Training: loss:  0.023965342\n",
      "3515 : Training: loss:  0.025624542\n",
      "3516 : Training: loss:  0.033707857\n",
      "3517 : Training: loss:  0.027798763\n",
      "3518 : Training: loss:  0.01674982\n",
      "3519 : Training: loss:  0.027127799\n",
      "3520 : Training: loss:  0.017919676\n",
      "Validation: Loss:  0.044059113  Accuracy:  0.90384614\n",
      "3521 : Training: loss:  0.027501145\n",
      "3522 : Training: loss:  0.026021777\n",
      "3523 : Training: loss:  0.019284438\n",
      "3524 : Training: loss:  0.028540595\n",
      "3525 : Training: loss:  0.029654471\n",
      "3526 : Training: loss:  0.052179642\n",
      "3527 : Training: loss:  0.018195458\n",
      "3528 : Training: loss:  0.024696968\n",
      "3529 : Training: loss:  0.026656838\n",
      "3530 : Training: loss:  0.037418555\n",
      "3531 : Training: loss:  0.022268092\n",
      "3532 : Training: loss:  0.028908517\n",
      "3533 : Training: loss:  0.020997219\n",
      "3534 : Training: loss:  0.03851173\n",
      "3535 : Training: loss:  0.02371489\n",
      "3536 : Training: loss:  0.028642157\n",
      "3537 : Training: loss:  0.031815294\n",
      "3538 : Training: loss:  0.02086778\n",
      "3539 : Training: loss:  0.043817382\n",
      "3540 : Training: loss:  0.022607172\n",
      "Validation: Loss:  0.043804515  Accuracy:  0.90384614\n",
      "3541 : Training: loss:  0.0232765\n",
      "3542 : Training: loss:  0.031080123\n",
      "3543 : Training: loss:  0.027254744\n",
      "3544 : Training: loss:  0.019380163\n",
      "3545 : Training: loss:  0.021438075\n",
      "3546 : Training: loss:  0.03858269\n",
      "3547 : Training: loss:  0.023383768\n",
      "3548 : Training: loss:  0.027039329\n",
      "3549 : Training: loss:  0.033640116\n",
      "3550 : Training: loss:  0.037484027\n",
      "3551 : Training: loss:  0.037662484\n",
      "3552 : Training: loss:  0.023119751\n",
      "3553 : Training: loss:  0.01849638\n",
      "3554 : Training: loss:  0.025147833\n",
      "3555 : Training: loss:  0.033439565\n",
      "3556 : Training: loss:  0.027753396\n",
      "3557 : Training: loss:  0.038282804\n",
      "3558 : Training: loss:  0.03763563\n",
      "3559 : Training: loss:  0.02179899\n",
      "3560 : Training: loss:  0.027275857\n",
      "Validation: Loss:  0.0434919  Accuracy:  0.90384614\n",
      "3561 : Training: loss:  0.037859574\n",
      "3562 : Training: loss:  0.019828595\n",
      "3563 : Training: loss:  0.021406459\n",
      "3564 : Training: loss:  0.025330467\n",
      "3565 : Training: loss:  0.019996433\n",
      "3566 : Training: loss:  0.024246756\n",
      "3567 : Training: loss:  0.037319165\n",
      "3568 : Training: loss:  0.027797744\n",
      "3569 : Training: loss:  0.027474845\n",
      "3570 : Training: loss:  0.020370971\n",
      "3571 : Training: loss:  0.026130881\n",
      "3572 : Training: loss:  0.029485855\n",
      "3573 : Training: loss:  0.023915283\n",
      "3574 : Training: loss:  0.033759963\n",
      "3575 : Training: loss:  0.025016151\n",
      "3576 : Training: loss:  0.029644659\n",
      "3577 : Training: loss:  0.019089928\n",
      "3578 : Training: loss:  0.023245065\n",
      "3579 : Training: loss:  0.029702809\n",
      "3580 : Training: loss:  0.036594935\n",
      "Validation: Loss:  0.04323559  Accuracy:  0.90384614\n",
      "3581 : Training: loss:  0.026376538\n",
      "3582 : Training: loss:  0.039327197\n",
      "3583 : Training: loss:  0.028880974\n",
      "3584 : Training: loss:  0.042002633\n",
      "3585 : Training: loss:  0.02808079\n",
      "3586 : Training: loss:  0.02964679\n",
      "3587 : Training: loss:  0.034075644\n",
      "3588 : Training: loss:  0.039492823\n",
      "3589 : Training: loss:  0.025282321\n",
      "3590 : Training: loss:  0.022546493\n",
      "3591 : Training: loss:  0.024150074\n",
      "3592 : Training: loss:  0.020138826\n",
      "3593 : Training: loss:  0.038825963\n",
      "3594 : Training: loss:  0.018452026\n",
      "3595 : Training: loss:  0.022125555\n",
      "3596 : Training: loss:  0.028057495\n",
      "3597 : Training: loss:  0.032673318\n",
      "3598 : Training: loss:  0.0277491\n",
      "3599 : Training: loss:  0.029740788\n",
      "3600 : Training: loss:  0.025549157\n",
      "Validation: Loss:  0.042906366  Accuracy:  0.90384614\n",
      "3601 : Training: loss:  0.046593126\n",
      "3602 : Training: loss:  0.030034048\n",
      "3603 : Training: loss:  0.027561745\n",
      "3604 : Training: loss:  0.0349761\n",
      "3605 : Training: loss:  0.026880823\n",
      "3606 : Training: loss:  0.030778492\n",
      "3607 : Training: loss:  0.018176401\n",
      "3608 : Training: loss:  0.029785832\n",
      "3609 : Training: loss:  0.024990043\n",
      "3610 : Training: loss:  0.021977175\n",
      "3611 : Training: loss:  0.030890994\n",
      "3612 : Training: loss:  0.02905886\n",
      "3613 : Training: loss:  0.026709953\n",
      "3614 : Training: loss:  0.029528225\n",
      "3615 : Training: loss:  0.030550757\n",
      "3616 : Training: loss:  0.024500225\n",
      "3617 : Training: loss:  0.020958532\n",
      "3618 : Training: loss:  0.016068479\n",
      "3619 : Training: loss:  0.020065442\n",
      "3620 : Training: loss:  0.037289884\n",
      "Validation: Loss:  0.042468887  Accuracy:  0.9423077\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class scores</th>\n",
       "      <th>Correct labels</th>\n",
       "      <th>Predicted labels</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5332, 0.0028, 0.0008, 0.0049, 0.0003, 0.002...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.608, 0.0057, 0.0012, 0.0048, 0.0016, 0.0022...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.8153, 0.0267, 0.0007, 0.0072, 0.001, 0.1736...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1337, 0.587, 0.0016, 0.0023, 0.0112, 0.0323...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0096, 0.4694, 0.0074, 0.0006, 0.016, 0.0256...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.0004, 0.0063, 0.7714, 0.0003, 0.0049, 0.005...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0049, 0.0026, 0.0011, 0.7028, 0.0603, 0.004...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.0009, 0.0007, 0.0024, 0.713, 0.0144, 0.0011...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0093, 0.0012, 0.0018, 0.7556, 0.0024, 0.001...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.0155, 0.0623, 1e-04, 0.0086, 0.1135, 0.2043...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0235, 0.3173, 0.0049, 0.0015, 0.3265, 0.243...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0127, 0.0286, 0.0003, 0.0006, 0.019, 0.6678...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0049, 0.0108, 0.0374, 0.0002, 0.0003, 0.012...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0558, 0.0098, 0.02, 0.0017, 0.0026, 0.0209,...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0076, 0.1244, 0.0002, 0.0006, 0.043, 0.0083...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0.0076, 0.0026, 1e-04, 0.0101, 0.0173, 0.002,...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0052, 0.0038, 0.0377, 0.0233, 0.0016, 0.000...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0017, 0.0044, 0.0825, 0.0012, 0.0049, 0.005...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.0018, 0.0027, 0.0305, 0.0003, 0.0339, 0.001...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.0021, 0.0052, 0.0193, 0.0003, 0.0295, 0.004...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.0079, 0.0045, 0.0024, 0.0011, 0.001, 0.0005...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.0027, 0.0078, 0.0066, 0.014, 0.0464, 0.002,...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.0026, 0.0159, 0.0015, 0.0026, 0.0024, 0.002...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0005, 0.0013, 0.0063, 0.0148, 0.0438, 0.033...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0002, 0.0007, 0.0251, 0.0109, 0.0242, 0.017...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0007, 0.0011, 0.0044, 0.0309, 0.0343, 0.000...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0004, 0.0006, 0.0031, 0.0234, 0.0106, 0.000...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0002, 0.0279, 0.0023, 0.0008, 0.0194, 0.014...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[1e-04, 0.0806, 0.0228, 0.0076, 0.116, 0.03, 0...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0003, 0.0211, 0.001, 0.002, 0.0667, 0.0074,...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.3838, 0.0216, 0.0037, 0.0054, 0.0141, 0.021...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0149, 0.0101, 0.0067, 0.045, 0.0031, 0.0025...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0119, 0.0025, 0.0476, 0.1123, 0.0087, 0.001...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0035, 0.0008, 0.0064, 0.0011, 0.0075, 0.000...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0009, 0.0151, 0.0013, 0.0157, 0.0359, 0.007...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0049, 0.0019, 0.0391, 0.0006, 0.0009, 0.001...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0158, 0.0155, 0.001, 0.0021, 0.0006, 0.0177...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0259, 0.0041, 0.0011, 0.0109, 0.0008, 0.002...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0017, 0.0035, 0.0266, 0.0032, 0.0005, 0.028...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0034, 0.0097, 0.0036, 0.0049, 0.0008, 0.005...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0028, 0.0043, 0.006, 0.0221, 0.0006, 0.0071...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0014, 0.0035, 0.0057, 0.0085, 0.0008, 0.002...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0011, 0.0024, 0.0032, 0.0045, 0.001, 0.0005...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0053, 0.0017, 0.0062, 0.0003, 0.0096, 0.001...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.002, 0.0053, 0.0147, 0.0029, 0.0045, 0.0003...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.059, 0.0076, 0.0031, 0.3142, 0.0377, 0.0056...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0002, 0.004, 0.0068, 0.0196, 0.0108, 0.008,...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0025, 0.0019, 0.0028, 0.0148, 0.0082, 0.033...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0041, 0.121, 0.0009, 0.002, 0.025, 0.0267, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0016, 0.1118, 0.0006, 0.0021, 0.0207, 0.068...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.486, 0.0016, 0.0008, 0.004, 0.0014, 0.0004,...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.0019, 0.0043, 0.0029, 0.0246, 0.2605, 0.000...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Class scores  Correct labels  \\\n",
       "0   [0.5332, 0.0028, 0.0008, 0.0049, 0.0003, 0.002...               0   \n",
       "1   [0.608, 0.0057, 0.0012, 0.0048, 0.0016, 0.0022...               0   \n",
       "2   [0.8153, 0.0267, 0.0007, 0.0072, 0.001, 0.1736...               0   \n",
       "3   [0.1337, 0.587, 0.0016, 0.0023, 0.0112, 0.0323...               1   \n",
       "4   [0.0096, 0.4694, 0.0074, 0.0006, 0.016, 0.0256...               1   \n",
       "5   [0.0004, 0.0063, 0.7714, 0.0003, 0.0049, 0.005...               2   \n",
       "6   [0.0049, 0.0026, 0.0011, 0.7028, 0.0603, 0.004...               3   \n",
       "7   [0.0009, 0.0007, 0.0024, 0.713, 0.0144, 0.0011...               3   \n",
       "8   [0.0093, 0.0012, 0.0018, 0.7556, 0.0024, 0.001...               3   \n",
       "9   [0.0155, 0.0623, 1e-04, 0.0086, 0.1135, 0.2043...               4   \n",
       "10  [0.0235, 0.3173, 0.0049, 0.0015, 0.3265, 0.243...               4   \n",
       "11  [0.0127, 0.0286, 0.0003, 0.0006, 0.019, 0.6678...               5   \n",
       "12  [0.0049, 0.0108, 0.0374, 0.0002, 0.0003, 0.012...               6   \n",
       "13  [0.0558, 0.0098, 0.02, 0.0017, 0.0026, 0.0209,...               7   \n",
       "14  [0.0076, 0.1244, 0.0002, 0.0006, 0.043, 0.0083...               8   \n",
       "15  [0.0076, 0.0026, 1e-04, 0.0101, 0.0173, 0.002,...               8   \n",
       "16  [0.0052, 0.0038, 0.0377, 0.0233, 0.0016, 0.000...               9   \n",
       "17  [0.0017, 0.0044, 0.0825, 0.0012, 0.0049, 0.005...               9   \n",
       "18  [0.0018, 0.0027, 0.0305, 0.0003, 0.0339, 0.001...              10   \n",
       "19  [0.0021, 0.0052, 0.0193, 0.0003, 0.0295, 0.004...              10   \n",
       "20  [0.0079, 0.0045, 0.0024, 0.0011, 0.001, 0.0005...              11   \n",
       "21  [0.0027, 0.0078, 0.0066, 0.014, 0.0464, 0.002,...              11   \n",
       "22  [0.0026, 0.0159, 0.0015, 0.0026, 0.0024, 0.002...              12   \n",
       "23  [0.0005, 0.0013, 0.0063, 0.0148, 0.0438, 0.033...              13   \n",
       "24  [0.0002, 0.0007, 0.0251, 0.0109, 0.0242, 0.017...              13   \n",
       "25  [0.0007, 0.0011, 0.0044, 0.0309, 0.0343, 0.000...              14   \n",
       "26  [0.0004, 0.0006, 0.0031, 0.0234, 0.0106, 0.000...              14   \n",
       "27  [0.0002, 0.0279, 0.0023, 0.0008, 0.0194, 0.014...              15   \n",
       "28  [1e-04, 0.0806, 0.0228, 0.0076, 0.116, 0.03, 0...              15   \n",
       "29  [0.0003, 0.0211, 0.001, 0.002, 0.0667, 0.0074,...              15   \n",
       "30  [0.3838, 0.0216, 0.0037, 0.0054, 0.0141, 0.021...              16   \n",
       "31  [0.0149, 0.0101, 0.0067, 0.045, 0.0031, 0.0025...              17   \n",
       "32  [0.0119, 0.0025, 0.0476, 0.1123, 0.0087, 0.001...              17   \n",
       "33  [0.0035, 0.0008, 0.0064, 0.0011, 0.0075, 0.000...              18   \n",
       "34  [0.0009, 0.0151, 0.0013, 0.0157, 0.0359, 0.007...              19   \n",
       "35  [0.0049, 0.0019, 0.0391, 0.0006, 0.0009, 0.001...              20   \n",
       "36  [0.0158, 0.0155, 0.001, 0.0021, 0.0006, 0.0177...              21   \n",
       "37  [0.0259, 0.0041, 0.0011, 0.0109, 0.0008, 0.002...              21   \n",
       "38  [0.0017, 0.0035, 0.0266, 0.0032, 0.0005, 0.028...              22   \n",
       "39  [0.0034, 0.0097, 0.0036, 0.0049, 0.0008, 0.005...              22   \n",
       "40  [0.0028, 0.0043, 0.006, 0.0221, 0.0006, 0.0071...              22   \n",
       "41  [0.0014, 0.0035, 0.0057, 0.0085, 0.0008, 0.002...              22   \n",
       "42  [0.0011, 0.0024, 0.0032, 0.0045, 0.001, 0.0005...              23   \n",
       "43  [0.0053, 0.0017, 0.0062, 0.0003, 0.0096, 0.001...              23   \n",
       "44  [0.002, 0.0053, 0.0147, 0.0029, 0.0045, 0.0003...              23   \n",
       "45  [0.059, 0.0076, 0.0031, 0.3142, 0.0377, 0.0056...              23   \n",
       "46  [0.0002, 0.004, 0.0068, 0.0196, 0.0108, 0.008,...              24   \n",
       "47  [0.0025, 0.0019, 0.0028, 0.0148, 0.0082, 0.033...              24   \n",
       "48  [0.0041, 0.121, 0.0009, 0.002, 0.025, 0.0267, ...              25   \n",
       "49  [0.0016, 0.1118, 0.0006, 0.0021, 0.0207, 0.068...              25   \n",
       "50  [0.486, 0.0016, 0.0008, 0.004, 0.0014, 0.0004,...              26   \n",
       "51  [0.0019, 0.0043, 0.0029, 0.0246, 0.2605, 0.000...              26   \n",
       "\n",
       "    Predicted labels  Accuracy      Loss  \n",
       "0                  0  0.942308  0.042469  \n",
       "1                  0       NaN       NaN  \n",
       "2                  0       NaN       NaN  \n",
       "3                  1       NaN       NaN  \n",
       "4                  1       NaN       NaN  \n",
       "5                  2       NaN       NaN  \n",
       "6                  3       NaN       NaN  \n",
       "7                  3       NaN       NaN  \n",
       "8                  3       NaN       NaN  \n",
       "9                  5       NaN       NaN  \n",
       "10                 4       NaN       NaN  \n",
       "11                 5       NaN       NaN  \n",
       "12                 6       NaN       NaN  \n",
       "13                 9       NaN       NaN  \n",
       "14                 8       NaN       NaN  \n",
       "15                 8       NaN       NaN  \n",
       "16                 9       NaN       NaN  \n",
       "17                 9       NaN       NaN  \n",
       "18                10       NaN       NaN  \n",
       "19                10       NaN       NaN  \n",
       "20                11       NaN       NaN  \n",
       "21                11       NaN       NaN  \n",
       "22                12       NaN       NaN  \n",
       "23                13       NaN       NaN  \n",
       "24                13       NaN       NaN  \n",
       "25                14       NaN       NaN  \n",
       "26                14       NaN       NaN  \n",
       "27                15       NaN       NaN  \n",
       "28                15       NaN       NaN  \n",
       "29                15       NaN       NaN  \n",
       "30                16       NaN       NaN  \n",
       "31                17       NaN       NaN  \n",
       "32                17       NaN       NaN  \n",
       "33                18       NaN       NaN  \n",
       "34                19       NaN       NaN  \n",
       "35                20       NaN       NaN  \n",
       "36                21       NaN       NaN  \n",
       "37                21       NaN       NaN  \n",
       "38                22       NaN       NaN  \n",
       "39                22       NaN       NaN  \n",
       "40                22       NaN       NaN  \n",
       "41                22       NaN       NaN  \n",
       "42                23       NaN       NaN  \n",
       "43                23       NaN       NaN  \n",
       "44                23       NaN       NaN  \n",
       "45                23       NaN       NaN  \n",
       "46                24       NaN       NaN  \n",
       "47                24       NaN       NaN  \n",
       "48                25       NaN       NaN  \n",
       "49                25       NaN       NaN  \n",
       "50                 0       NaN       NaN  \n",
       "51                26       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3621 : Training: loss:  0.024870353\n",
      "3622 : Training: loss:  0.025018059\n",
      "3623 : Training: loss:  0.030942442\n",
      "3624 : Training: loss:  0.01840659\n",
      "3625 : Training: loss:  0.03824196\n",
      "3626 : Training: loss:  0.03771239\n",
      "3627 : Training: loss:  0.022408826\n",
      "3628 : Training: loss:  0.019786635\n",
      "3629 : Training: loss:  0.024355253\n",
      "3630 : Training: loss:  0.024381446\n",
      "3631 : Training: loss:  0.028907238\n",
      "3632 : Training: loss:  0.021015264\n",
      "3633 : Training: loss:  0.02492762\n",
      "3634 : Training: loss:  0.02314841\n",
      "3635 : Training: loss:  0.027004467\n",
      "3636 : Training: loss:  0.019958062\n",
      "3637 : Training: loss:  0.029764695\n",
      "3638 : Training: loss:  0.022015316\n",
      "3639 : Training: loss:  0.021966537\n",
      "3640 : Training: loss:  0.037309475\n",
      "Validation: Loss:  0.04225885  Accuracy:  0.9423077\n",
      "3641 : Training: loss:  0.021652887\n",
      "3642 : Training: loss:  0.025107088\n",
      "3643 : Training: loss:  0.023995928\n",
      "3644 : Training: loss:  0.029728735\n",
      "3645 : Training: loss:  0.026403792\n",
      "3646 : Training: loss:  0.019409288\n",
      "3647 : Training: loss:  0.01606134\n",
      "3648 : Training: loss:  0.023279695\n",
      "3649 : Training: loss:  0.023274446\n",
      "3650 : Training: loss:  0.04553637\n",
      "3651 : Training: loss:  0.026907012\n",
      "3652 : Training: loss:  0.028408458\n",
      "3653 : Training: loss:  0.026258197\n",
      "3654 : Training: loss:  0.028377412\n",
      "3655 : Training: loss:  0.028463183\n",
      "3656 : Training: loss:  0.022983862\n",
      "3657 : Training: loss:  0.02758997\n",
      "3658 : Training: loss:  0.023400888\n",
      "3659 : Training: loss:  0.028429987\n",
      "3660 : Training: loss:  0.021790972\n",
      "Validation: Loss:  0.042104565  Accuracy:  0.9423077\n",
      "3661 : Training: loss:  0.026984263\n",
      "3662 : Training: loss:  0.021447763\n",
      "3663 : Training: loss:  0.037042018\n",
      "3664 : Training: loss:  0.022156639\n",
      "3665 : Training: loss:  0.03497856\n",
      "3666 : Training: loss:  0.03527014\n",
      "3667 : Training: loss:  0.039802976\n",
      "3668 : Training: loss:  0.01635689\n",
      "3669 : Training: loss:  0.01778257\n",
      "3670 : Training: loss:  0.03258849\n",
      "3671 : Training: loss:  0.01612051\n",
      "3672 : Training: loss:  0.025159033\n",
      "3673 : Training: loss:  0.027587047\n",
      "3674 : Training: loss:  0.038898967\n",
      "3675 : Training: loss:  0.026635457\n",
      "3676 : Training: loss:  0.019289888\n",
      "3677 : Training: loss:  0.023359003\n",
      "3678 : Training: loss:  0.031408627\n",
      "3679 : Training: loss:  0.022337625\n",
      "3680 : Training: loss:  0.02286116\n",
      "Validation: Loss:  0.041752383  Accuracy:  0.9423077\n",
      "3681 : Training: loss:  0.03368029\n",
      "3682 : Training: loss:  0.026262786\n",
      "3683 : Training: loss:  0.020377193\n",
      "3684 : Training: loss:  0.019586094\n",
      "3685 : Training: loss:  0.01813035\n",
      "3686 : Training: loss:  0.032757957\n",
      "3687 : Training: loss:  0.05358019\n",
      "3688 : Training: loss:  0.021966085\n",
      "3689 : Training: loss:  0.027814772\n",
      "3690 : Training: loss:  0.02603045\n",
      "3691 : Training: loss:  0.016979372\n",
      "3692 : Training: loss:  0.037967935\n",
      "3693 : Training: loss:  0.018368479\n",
      "3694 : Training: loss:  0.03708989\n",
      "3695 : Training: loss:  0.027445512\n",
      "3696 : Training: loss:  0.028983006\n",
      "3697 : Training: loss:  0.025621464\n",
      "3698 : Training: loss:  0.028519642\n",
      "3699 : Training: loss:  0.026757948\n",
      "3700 : Training: loss:  0.022098647\n",
      "Validation: Loss:  0.04149104  Accuracy:  0.9423077\n",
      "3701 : Training: loss:  0.027814584\n",
      "3702 : Training: loss:  0.02179574\n",
      "3703 : Training: loss:  0.01738343\n",
      "3704 : Training: loss:  0.028898647\n",
      "3705 : Training: loss:  0.031752583\n",
      "3706 : Training: loss:  0.020955734\n",
      "3707 : Training: loss:  0.025648149\n",
      "3708 : Training: loss:  0.027413407\n",
      "3709 : Training: loss:  0.022210645\n",
      "3710 : Training: loss:  0.022223428\n",
      "3711 : Training: loss:  0.03184507\n",
      "3712 : Training: loss:  0.027211605\n",
      "3713 : Training: loss:  0.024911694\n",
      "3714 : Training: loss:  0.03015451\n",
      "3715 : Training: loss:  0.019872664\n",
      "3716 : Training: loss:  0.022535184\n",
      "3717 : Training: loss:  0.034518115\n",
      "3718 : Training: loss:  0.035483245\n",
      "3719 : Training: loss:  0.01471686\n",
      "3720 : Training: loss:  0.028545473\n",
      "Validation: Loss:  0.04135986  Accuracy:  0.9423077\n",
      "3721 : Training: loss:  0.016985016\n",
      "3722 : Training: loss:  0.024597017\n",
      "3723 : Training: loss:  0.022153445\n",
      "3724 : Training: loss:  0.041693266\n",
      "3725 : Training: loss:  0.020785106\n",
      "3726 : Training: loss:  0.025568541\n",
      "3727 : Training: loss:  0.021797892\n",
      "3728 : Training: loss:  0.03570401\n",
      "3729 : Training: loss:  0.039892726\n",
      "3730 : Training: loss:  0.029182838\n",
      "3731 : Training: loss:  0.034804627\n",
      "3732 : Training: loss:  0.023453716\n",
      "3733 : Training: loss:  0.020041808\n",
      "3734 : Training: loss:  0.03054408\n",
      "3735 : Training: loss:  0.028460564\n",
      "3736 : Training: loss:  0.022564514\n",
      "3737 : Training: loss:  0.018201664\n",
      "3738 : Training: loss:  0.018230407\n",
      "3739 : Training: loss:  0.017531665\n",
      "3740 : Training: loss:  0.024206027\n",
      "Validation: Loss:  0.041273393  Accuracy:  0.9423077\n",
      "3741 : Training: loss:  0.022601437\n",
      "3742 : Training: loss:  0.025667107\n",
      "3743 : Training: loss:  0.023779396\n",
      "3744 : Training: loss:  0.019676244\n",
      "3745 : Training: loss:  0.027466722\n",
      "3746 : Training: loss:  0.02109532\n",
      "3747 : Training: loss:  0.028913192\n",
      "3748 : Training: loss:  0.020637767\n",
      "3749 : Training: loss:  0.030989138\n",
      "3750 : Training: loss:  0.019435702\n",
      "3751 : Training: loss:  0.03522145\n",
      "3752 : Training: loss:  0.024871835\n",
      "3753 : Training: loss:  0.018166458\n",
      "3754 : Training: loss:  0.018729959\n",
      "3755 : Training: loss:  0.023446037\n",
      "3756 : Training: loss:  0.01869108\n",
      "3757 : Training: loss:  0.015115405\n",
      "3758 : Training: loss:  0.01964917\n",
      "3759 : Training: loss:  0.017875893\n",
      "3760 : Training: loss:  0.023677612\n",
      "Validation: Loss:  0.041201487  Accuracy:  0.9423077\n",
      "3761 : Training: loss:  0.028933885\n",
      "3762 : Training: loss:  0.030909702\n",
      "3763 : Training: loss:  0.02640151\n",
      "3764 : Training: loss:  0.018212808\n",
      "3765 : Training: loss:  0.030189693\n",
      "3766 : Training: loss:  0.029506573\n",
      "3767 : Training: loss:  0.03173021\n",
      "3768 : Training: loss:  0.02131438\n",
      "3769 : Training: loss:  0.018759623\n",
      "3770 : Training: loss:  0.022862181\n",
      "3771 : Training: loss:  0.017029783\n",
      "3772 : Training: loss:  0.021750534\n",
      "3773 : Training: loss:  0.031178951\n",
      "3774 : Training: loss:  0.018101392\n",
      "3775 : Training: loss:  0.024777927\n",
      "3776 : Training: loss:  0.020037914\n",
      "3777 : Training: loss:  0.04956084\n",
      "3778 : Training: loss:  0.028854035\n",
      "3779 : Training: loss:  0.030482471\n",
      "3780 : Training: loss:  0.022902146\n",
      "Validation: Loss:  0.041011304  Accuracy:  0.9423077\n",
      "3781 : Training: loss:  0.03153157\n",
      "3782 : Training: loss:  0.021449348\n",
      "3783 : Training: loss:  0.018723223\n",
      "3784 : Training: loss:  0.024029532\n",
      "3785 : Training: loss:  0.02019538\n",
      "3786 : Training: loss:  0.03483785\n",
      "3787 : Training: loss:  0.019967088\n",
      "3788 : Training: loss:  0.019560417\n",
      "3789 : Training: loss:  0.032924935\n",
      "3790 : Training: loss:  0.02971159\n",
      "3791 : Training: loss:  0.02190881\n",
      "3792 : Training: loss:  0.022804953\n",
      "3793 : Training: loss:  0.019487252\n",
      "3794 : Training: loss:  0.018263208\n",
      "3795 : Training: loss:  0.040477242\n",
      "3796 : Training: loss:  0.042487312\n",
      "3797 : Training: loss:  0.018830845\n",
      "3798 : Training: loss:  0.014539796\n",
      "3799 : Training: loss:  0.024176963\n",
      "3800 : Training: loss:  0.022036374\n",
      "Validation: Loss:  0.040844873  Accuracy:  0.9230769\n",
      "3801 : Training: loss:  0.03126412\n",
      "3802 : Training: loss:  0.026836805\n",
      "3803 : Training: loss:  0.021714875\n",
      "3804 : Training: loss:  0.02185216\n",
      "3805 : Training: loss:  0.020031616\n",
      "3806 : Training: loss:  0.025200376\n",
      "3807 : Training: loss:  0.02746065\n",
      "3808 : Training: loss:  0.03544872\n",
      "3809 : Training: loss:  0.018222395\n",
      "3810 : Training: loss:  0.01999134\n",
      "3811 : Training: loss:  0.026883723\n",
      "3812 : Training: loss:  0.020975903\n",
      "3813 : Training: loss:  0.03505455\n",
      "3814 : Training: loss:  0.017807897\n",
      "3815 : Training: loss:  0.022691848\n",
      "3816 : Training: loss:  0.03606724\n",
      "3817 : Training: loss:  0.018126683\n",
      "3818 : Training: loss:  0.020629318\n",
      "3819 : Training: loss:  0.019735929\n",
      "3820 : Training: loss:  0.013682591\n",
      "Validation: Loss:  0.04048587  Accuracy:  0.9423077\n",
      "3821 : Training: loss:  0.021891473\n",
      "3822 : Training: loss:  0.025698883\n",
      "3823 : Training: loss:  0.025902407\n",
      "3824 : Training: loss:  0.023977237\n",
      "3825 : Training: loss:  0.036898974\n",
      "3826 : Training: loss:  0.014481777\n",
      "3827 : Training: loss:  0.024676267\n",
      "3828 : Training: loss:  0.012178452\n",
      "3829 : Training: loss:  0.03210639\n",
      "3830 : Training: loss:  0.020869207\n",
      "3831 : Training: loss:  0.0214168\n",
      "3832 : Training: loss:  0.014558892\n",
      "3833 : Training: loss:  0.03936034\n",
      "3834 : Training: loss:  0.03126996\n",
      "3835 : Training: loss:  0.03391643\n",
      "3836 : Training: loss:  0.026980983\n",
      "3837 : Training: loss:  0.017799515\n",
      "3838 : Training: loss:  0.026182555\n",
      "3839 : Training: loss:  0.02964349\n",
      "3840 : Training: loss:  0.016832205\n",
      "Validation: Loss:  0.040182017  Accuracy:  0.9423077\n",
      "3841 : Training: loss:  0.021593098\n",
      "3842 : Training: loss:  0.022029232\n",
      "3843 : Training: loss:  0.028014382\n",
      "3844 : Training: loss:  0.023517234\n",
      "3845 : Training: loss:  0.02185271\n",
      "3846 : Training: loss:  0.032210976\n",
      "3847 : Training: loss:  0.02562541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3848 : Training: loss:  0.027940428\n",
      "3849 : Training: loss:  0.028105268\n",
      "3850 : Training: loss:  0.015400352\n",
      "3851 : Training: loss:  0.017745117\n",
      "3852 : Training: loss:  0.025602737\n",
      "3853 : Training: loss:  0.021275124\n",
      "3854 : Training: loss:  0.025833096\n",
      "3855 : Training: loss:  0.015663903\n",
      "3856 : Training: loss:  0.020095842\n",
      "3857 : Training: loss:  0.023225753\n",
      "3858 : Training: loss:  0.024384711\n",
      "3859 : Training: loss:  0.024516212\n",
      "3860 : Training: loss:  0.02099963\n",
      "Validation: Loss:  0.03975076  Accuracy:  0.9423077\n",
      "3861 : Training: loss:  0.02733771\n",
      "3862 : Training: loss:  0.017328007\n",
      "3863 : Training: loss:  0.029313052\n",
      "3864 : Training: loss:  0.025074204\n",
      "3865 : Training: loss:  0.019725535\n",
      "3866 : Training: loss:  0.030693749\n",
      "3867 : Training: loss:  0.017548814\n",
      "3868 : Training: loss:  0.026882347\n",
      "3869 : Training: loss:  0.028256668\n",
      "3870 : Training: loss:  0.015702596\n",
      "3871 : Training: loss:  0.023476698\n",
      "3872 : Training: loss:  0.020109119\n",
      "3873 : Training: loss:  0.030788122\n",
      "3874 : Training: loss:  0.032379184\n",
      "3875 : Training: loss:  0.02836412\n",
      "3876 : Training: loss:  0.019643495\n",
      "3877 : Training: loss:  0.027727278\n",
      "3878 : Training: loss:  0.017667599\n",
      "3879 : Training: loss:  0.022809453\n",
      "3880 : Training: loss:  0.019375382\n",
      "Validation: Loss:  0.0396325  Accuracy:  0.9423077\n",
      "3881 : Training: loss:  0.015913997\n",
      "3882 : Training: loss:  0.014145157\n",
      "3883 : Training: loss:  0.020011758\n",
      "3884 : Training: loss:  0.017702084\n",
      "3885 : Training: loss:  0.016003748\n",
      "3886 : Training: loss:  0.019692922\n",
      "3887 : Training: loss:  0.015858795\n",
      "3888 : Training: loss:  0.020489924\n",
      "3889 : Training: loss:  0.04030533\n",
      "3890 : Training: loss:  0.025608446\n",
      "3891 : Training: loss:  0.01790106\n",
      "3892 : Training: loss:  0.019733954\n",
      "3893 : Training: loss:  0.018171184\n",
      "3894 : Training: loss:  0.015048972\n",
      "3895 : Training: loss:  0.023296276\n",
      "3896 : Training: loss:  0.027894208\n",
      "3897 : Training: loss:  0.025848707\n",
      "3898 : Training: loss:  0.020141805\n",
      "3899 : Training: loss:  0.017892303\n",
      "3900 : Training: loss:  0.031686515\n",
      "Validation: Loss:  0.039431024  Accuracy:  0.9423077\n",
      "3901 : Training: loss:  0.031027181\n",
      "3902 : Training: loss:  0.021376202\n",
      "3903 : Training: loss:  0.023698738\n",
      "3904 : Training: loss:  0.018303037\n",
      "3905 : Training: loss:  0.019784745\n",
      "3906 : Training: loss:  0.019537594\n",
      "3907 : Training: loss:  0.029447857\n",
      "3908 : Training: loss:  0.026229238\n",
      "3909 : Training: loss:  0.02844591\n",
      "3910 : Training: loss:  0.03473294\n",
      "3911 : Training: loss:  0.024457645\n",
      "3912 : Training: loss:  0.01866606\n",
      "3913 : Training: loss:  0.031390958\n",
      "3914 : Training: loss:  0.017793657\n",
      "3915 : Training: loss:  0.021729663\n",
      "3916 : Training: loss:  0.024863794\n",
      "3917 : Training: loss:  0.029109223\n",
      "3918 : Training: loss:  0.021803811\n",
      "3919 : Training: loss:  0.03695617\n",
      "3920 : Training: loss:  0.0120786205\n",
      "Validation: Loss:  0.03919177  Accuracy:  0.9230769\n",
      "3921 : Training: loss:  0.022400526\n",
      "3922 : Training: loss:  0.018550841\n",
      "3923 : Training: loss:  0.026891\n",
      "3924 : Training: loss:  0.02283562\n",
      "3925 : Training: loss:  0.015501136\n",
      "3926 : Training: loss:  0.03670965\n",
      "3927 : Training: loss:  0.017423447\n",
      "3928 : Training: loss:  0.029539432\n",
      "3929 : Training: loss:  0.017966254\n",
      "3930 : Training: loss:  0.036450576\n",
      "3931 : Training: loss:  0.025586214\n",
      "3932 : Training: loss:  0.022780363\n",
      "3933 : Training: loss:  0.016632518\n",
      "3934 : Training: loss:  0.014389331\n",
      "3935 : Training: loss:  0.020533275\n",
      "3936 : Training: loss:  0.029862752\n",
      "3937 : Training: loss:  0.024723338\n",
      "3938 : Training: loss:  0.02544974\n",
      "3939 : Training: loss:  0.014992929\n",
      "3940 : Training: loss:  0.014923737\n",
      "Validation: Loss:  0.038980458  Accuracy:  0.9230769\n",
      "3941 : Training: loss:  0.028393434\n",
      "3942 : Training: loss:  0.030481132\n",
      "3943 : Training: loss:  0.019410066\n",
      "3944 : Training: loss:  0.021191137\n",
      "3945 : Training: loss:  0.014053001\n",
      "3946 : Training: loss:  0.017643869\n",
      "3947 : Training: loss:  0.025480164\n",
      "3948 : Training: loss:  0.026831686\n",
      "3949 : Training: loss:  0.014513129\n",
      "3950 : Training: loss:  0.01868804\n",
      "3951 : Training: loss:  0.020700717\n",
      "3952 : Training: loss:  0.0131794475\n",
      "3953 : Training: loss:  0.03442121\n",
      "3954 : Training: loss:  0.032885585\n",
      "3955 : Training: loss:  0.018444711\n",
      "3956 : Training: loss:  0.01925374\n",
      "3957 : Training: loss:  0.016248057\n",
      "3958 : Training: loss:  0.033538863\n",
      "3959 : Training: loss:  0.023231778\n",
      "3960 : Training: loss:  0.030006884\n",
      "Validation: Loss:  0.038875315  Accuracy:  0.9230769\n",
      "3961 : Training: loss:  0.0153076425\n",
      "3962 : Training: loss:  0.02404615\n",
      "3963 : Training: loss:  0.016996272\n",
      "3964 : Training: loss:  0.022988023\n",
      "3965 : Training: loss:  0.033919048\n",
      "3966 : Training: loss:  0.018217947\n",
      "3967 : Training: loss:  0.016121343\n",
      "3968 : Training: loss:  0.0157638\n",
      "3969 : Training: loss:  0.029550299\n",
      "3970 : Training: loss:  0.01806561\n",
      "3971 : Training: loss:  0.021505926\n",
      "3972 : Training: loss:  0.03516147\n",
      "3973 : Training: loss:  0.02694591\n",
      "3974 : Training: loss:  0.033078082\n",
      "3975 : Training: loss:  0.031171873\n",
      "3976 : Training: loss:  0.018783009\n",
      "3977 : Training: loss:  0.02049806\n",
      "3978 : Training: loss:  0.020492544\n",
      "3979 : Training: loss:  0.021169407\n",
      "3980 : Training: loss:  0.014687479\n",
      "Validation: Loss:  0.038751677  Accuracy:  0.9230769\n",
      "3981 : Training: loss:  0.03226548\n",
      "3982 : Training: loss:  0.031367656\n",
      "3983 : Training: loss:  0.030192845\n",
      "3984 : Training: loss:  0.021332575\n",
      "3985 : Training: loss:  0.024133505\n",
      "3986 : Training: loss:  0.023964921\n",
      "3987 : Training: loss:  0.025316834\n",
      "3988 : Training: loss:  0.025074279\n",
      "3989 : Training: loss:  0.025522407\n",
      "3990 : Training: loss:  0.021119688\n",
      "3991 : Training: loss:  0.021665499\n",
      "3992 : Training: loss:  0.034012742\n",
      "3993 : Training: loss:  0.016159208\n",
      "3994 : Training: loss:  0.021235023\n",
      "3995 : Training: loss:  0.019408755\n",
      "3996 : Training: loss:  0.018273834\n",
      "3997 : Training: loss:  0.02317092\n",
      "3998 : Training: loss:  0.016474381\n",
      "3999 : Training: loss:  0.016664388\n",
      "4000 : Training: loss:  0.02989645\n",
      "Validation: Loss:  0.038696114  Accuracy:  0.9230769\n",
      "4001 : Training: loss:  0.015287399\n",
      "4002 : Training: loss:  0.015915193\n",
      "4003 : Training: loss:  0.015666725\n",
      "4004 : Training: loss:  0.030190205\n",
      "4005 : Training: loss:  0.03355896\n",
      "4006 : Training: loss:  0.032289278\n",
      "4007 : Training: loss:  0.043746028\n",
      "4008 : Training: loss:  0.021736221\n",
      "4009 : Training: loss:  0.018961761\n",
      "4010 : Training: loss:  0.027417185\n",
      "4011 : Training: loss:  0.03279532\n",
      "4012 : Training: loss:  0.022952689\n",
      "4013 : Training: loss:  0.029631604\n",
      "4014 : Training: loss:  0.018268988\n",
      "4015 : Training: loss:  0.017650025\n",
      "4016 : Training: loss:  0.01482888\n",
      "4017 : Training: loss:  0.033299744\n",
      "4018 : Training: loss:  0.01863176\n",
      "4019 : Training: loss:  0.025602702\n",
      "4020 : Training: loss:  0.02082261\n",
      "Validation: Loss:  0.038521852  Accuracy:  0.9230769\n",
      "4021 : Training: loss:  0.034377236\n",
      "4022 : Training: loss:  0.02753813\n",
      "4023 : Training: loss:  0.043112025\n",
      "4024 : Training: loss:  0.027029319\n",
      "4025 : Training: loss:  0.015705587\n",
      "4026 : Training: loss:  0.028143348\n",
      "4027 : Training: loss:  0.026984172\n",
      "4028 : Training: loss:  0.042207174\n",
      "4029 : Training: loss:  0.021012472\n",
      "4030 : Training: loss:  0.019285824\n",
      "4031 : Training: loss:  0.013157747\n",
      "4032 : Training: loss:  0.026638018\n",
      "4033 : Training: loss:  0.026228275\n",
      "4034 : Training: loss:  0.014585427\n",
      "4035 : Training: loss:  0.027961567\n",
      "4036 : Training: loss:  0.020390125\n",
      "4037 : Training: loss:  0.020760039\n",
      "4038 : Training: loss:  0.01583846\n",
      "4039 : Training: loss:  0.030586185\n",
      "4040 : Training: loss:  0.03197765\n",
      "Validation: Loss:  0.038189  Accuracy:  0.9230769\n",
      "4041 : Training: loss:  0.024878873\n",
      "4042 : Training: loss:  0.02615792\n",
      "4043 : Training: loss:  0.028428612\n",
      "4044 : Training: loss:  0.02147796\n",
      "4045 : Training: loss:  0.01759332\n",
      "4046 : Training: loss:  0.015341063\n",
      "4047 : Training: loss:  0.022058742\n",
      "4048 : Training: loss:  0.039368838\n",
      "4049 : Training: loss:  0.02567\n",
      "4050 : Training: loss:  0.018730683\n",
      "4051 : Training: loss:  0.025418136\n",
      "4052 : Training: loss:  0.026960287\n",
      "4053 : Training: loss:  0.025322655\n",
      "4054 : Training: loss:  0.02151875\n",
      "4055 : Training: loss:  0.024063086\n",
      "4056 : Training: loss:  0.016767211\n",
      "4057 : Training: loss:  0.022170302\n",
      "4058 : Training: loss:  0.018171905\n",
      "4059 : Training: loss:  0.020713184\n",
      "4060 : Training: loss:  0.019448305\n",
      "Validation: Loss:  0.037810802  Accuracy:  0.9230769\n",
      "4061 : Training: loss:  0.016920961\n",
      "4062 : Training: loss:  0.023684671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4063 : Training: loss:  0.023272768\n",
      "4064 : Training: loss:  0.02891054\n",
      "4065 : Training: loss:  0.028132014\n",
      "4066 : Training: loss:  0.019350328\n",
      "4067 : Training: loss:  0.019008875\n",
      "4068 : Training: loss:  0.018163877\n",
      "4069 : Training: loss:  0.021832105\n",
      "4070 : Training: loss:  0.01869959\n",
      "4071 : Training: loss:  0.025373137\n",
      "4072 : Training: loss:  0.017407201\n",
      "4073 : Training: loss:  0.025251832\n",
      "4074 : Training: loss:  0.01978623\n",
      "4075 : Training: loss:  0.016393006\n",
      "4076 : Training: loss:  0.016699482\n",
      "4077 : Training: loss:  0.028901665\n",
      "4078 : Training: loss:  0.019590689\n",
      "4079 : Training: loss:  0.02002771\n",
      "4080 : Training: loss:  0.032458533\n",
      "Validation: Loss:  0.0374778  Accuracy:  0.9230769\n",
      "4081 : Training: loss:  0.020373352\n",
      "4082 : Training: loss:  0.022937946\n",
      "4083 : Training: loss:  0.027270121\n",
      "4084 : Training: loss:  0.030460551\n",
      "4085 : Training: loss:  0.012089812\n",
      "4086 : Training: loss:  0.01543542\n",
      "4087 : Training: loss:  0.026228653\n",
      "4088 : Training: loss:  0.024178954\n",
      "4089 : Training: loss:  0.018431768\n",
      "4090 : Training: loss:  0.032978516\n",
      "4091 : Training: loss:  0.017165253\n",
      "4092 : Training: loss:  0.020205678\n",
      "4093 : Training: loss:  0.027294377\n",
      "4094 : Training: loss:  0.022196237\n",
      "4095 : Training: loss:  0.019114371\n",
      "4096 : Training: loss:  0.023221921\n",
      "4097 : Training: loss:  0.024179861\n",
      "4098 : Training: loss:  0.017344914\n",
      "4099 : Training: loss:  0.01637288\n",
      "4100 : Training: loss:  0.02927532\n",
      "Validation: Loss:  0.03739076  Accuracy:  0.9230769\n",
      "4101 : Training: loss:  0.020418288\n",
      "4102 : Training: loss:  0.023765333\n",
      "4103 : Training: loss:  0.016923307\n",
      "4104 : Training: loss:  0.016566984\n",
      "4105 : Training: loss:  0.021260187\n",
      "4106 : Training: loss:  0.01601758\n",
      "4107 : Training: loss:  0.021466048\n",
      "4108 : Training: loss:  0.025738705\n",
      "4109 : Training: loss:  0.016398814\n",
      "4110 : Training: loss:  0.011356104\n",
      "4111 : Training: loss:  0.01887779\n",
      "4112 : Training: loss:  0.04539801\n",
      "4113 : Training: loss:  0.027222184\n",
      "4114 : Training: loss:  0.022012185\n",
      "4115 : Training: loss:  0.016005287\n",
      "4116 : Training: loss:  0.025689634\n",
      "4117 : Training: loss:  0.018831596\n",
      "4118 : Training: loss:  0.034297008\n",
      "4119 : Training: loss:  0.017906584\n",
      "4120 : Training: loss:  0.02097216\n",
      "Validation: Loss:  0.037194278  Accuracy:  0.9230769\n",
      "4121 : Training: loss:  0.025138544\n",
      "4122 : Training: loss:  0.024325803\n",
      "4123 : Training: loss:  0.018000683\n",
      "4124 : Training: loss:  0.017840274\n",
      "4125 : Training: loss:  0.021502588\n",
      "4126 : Training: loss:  0.014284951\n",
      "4127 : Training: loss:  0.015341473\n",
      "4128 : Training: loss:  0.016006127\n",
      "4129 : Training: loss:  0.02172422\n",
      "4130 : Training: loss:  0.023722343\n",
      "4131 : Training: loss:  0.04054103\n",
      "4132 : Training: loss:  0.029388437\n",
      "4133 : Training: loss:  0.016309334\n",
      "4134 : Training: loss:  0.0196306\n",
      "4135 : Training: loss:  0.019204484\n",
      "4136 : Training: loss:  0.020035625\n",
      "4137 : Training: loss:  0.018695308\n",
      "4138 : Training: loss:  0.016595853\n",
      "4139 : Training: loss:  0.02228868\n",
      "4140 : Training: loss:  0.014990835\n",
      "Validation: Loss:  0.037015107  Accuracy:  0.9230769\n",
      "4141 : Training: loss:  0.019990332\n",
      "4142 : Training: loss:  0.023550143\n",
      "4143 : Training: loss:  0.022460934\n",
      "4144 : Training: loss:  0.011245686\n",
      "4145 : Training: loss:  0.016270528\n",
      "4146 : Training: loss:  0.02023658\n",
      "4147 : Training: loss:  0.01583986\n",
      "4148 : Training: loss:  0.018313397\n",
      "4149 : Training: loss:  0.03277373\n",
      "4150 : Training: loss:  0.024369411\n",
      "4151 : Training: loss:  0.013594506\n",
      "4152 : Training: loss:  0.013905851\n",
      "4153 : Training: loss:  0.01638007\n",
      "4154 : Training: loss:  0.020105653\n",
      "4155 : Training: loss:  0.01755803\n",
      "4156 : Training: loss:  0.019744622\n",
      "4157 : Training: loss:  0.018415852\n",
      "4158 : Training: loss:  0.021432813\n",
      "4159 : Training: loss:  0.018377677\n",
      "4160 : Training: loss:  0.020640412\n",
      "Validation: Loss:  0.036705494  Accuracy:  0.9423077\n",
      "4161 : Training: loss:  0.014484764\n",
      "4162 : Training: loss:  0.0150681315\n",
      "4163 : Training: loss:  0.038013514\n",
      "4164 : Training: loss:  0.02399172\n",
      "4165 : Training: loss:  0.018045608\n",
      "4166 : Training: loss:  0.023378821\n",
      "4167 : Training: loss:  0.020554507\n",
      "4168 : Training: loss:  0.024287727\n",
      "4169 : Training: loss:  0.020676184\n",
      "4170 : Training: loss:  0.016029917\n",
      "4171 : Training: loss:  0.016188929\n",
      "4172 : Training: loss:  0.03125292\n",
      "4173 : Training: loss:  0.01828528\n",
      "4174 : Training: loss:  0.017443862\n",
      "4175 : Training: loss:  0.014012643\n",
      "4176 : Training: loss:  0.021320356\n",
      "4177 : Training: loss:  0.019363053\n",
      "4178 : Training: loss:  0.015865384\n",
      "4179 : Training: loss:  0.02488873\n",
      "4180 : Training: loss:  0.020692376\n",
      "Validation: Loss:  0.036525562  Accuracy:  0.9423077\n",
      "4181 : Training: loss:  0.018898247\n",
      "4182 : Training: loss:  0.01938577\n",
      "4183 : Training: loss:  0.029179098\n",
      "4184 : Training: loss:  0.0183461\n",
      "4185 : Training: loss:  0.026289873\n",
      "4186 : Training: loss:  0.012783579\n",
      "4187 : Training: loss:  0.024998272\n",
      "4188 : Training: loss:  0.018682202\n",
      "4189 : Training: loss:  0.012622825\n",
      "4190 : Training: loss:  0.020439498\n",
      "4191 : Training: loss:  0.02408021\n",
      "4192 : Training: loss:  0.025866874\n",
      "4193 : Training: loss:  0.013160658\n",
      "4194 : Training: loss:  0.011610291\n",
      "4195 : Training: loss:  0.019948998\n",
      "4196 : Training: loss:  0.012942407\n",
      "4197 : Training: loss:  0.02444234\n",
      "4198 : Training: loss:  0.012478686\n",
      "4199 : Training: loss:  0.024926731\n",
      "4200 : Training: loss:  0.012610479\n",
      "Validation: Loss:  0.036513835  Accuracy:  0.9230769\n",
      "4201 : Training: loss:  0.054222886\n",
      "4202 : Training: loss:  0.015140728\n",
      "4203 : Training: loss:  0.029513419\n",
      "4204 : Training: loss:  0.0129785715\n",
      "4205 : Training: loss:  0.012721465\n",
      "4206 : Training: loss:  0.017956264\n",
      "4207 : Training: loss:  0.019335438\n",
      "4208 : Training: loss:  0.012551091\n",
      "4209 : Training: loss:  0.017976178\n",
      "4210 : Training: loss:  0.02785473\n",
      "4211 : Training: loss:  0.024242338\n",
      "4212 : Training: loss:  0.015759\n",
      "4213 : Training: loss:  0.02110109\n",
      "4214 : Training: loss:  0.018437138\n",
      "4215 : Training: loss:  0.016855467\n",
      "4216 : Training: loss:  0.015341938\n",
      "4217 : Training: loss:  0.02316899\n",
      "4218 : Training: loss:  0.03975287\n",
      "4219 : Training: loss:  0.013599992\n",
      "4220 : Training: loss:  0.02341774\n",
      "Validation: Loss:  0.03651974  Accuracy:  0.9230769\n",
      "4221 : Training: loss:  0.01649696\n",
      "4222 : Training: loss:  0.021603052\n",
      "4223 : Training: loss:  0.018163184\n",
      "4224 : Training: loss:  0.023101814\n",
      "4225 : Training: loss:  0.022096468\n",
      "4226 : Training: loss:  0.015707342\n",
      "4227 : Training: loss:  0.025015593\n",
      "4228 : Training: loss:  0.03487439\n",
      "4229 : Training: loss:  0.025342774\n",
      "4230 : Training: loss:  0.022136958\n",
      "4231 : Training: loss:  0.019248871\n",
      "4232 : Training: loss:  0.01698252\n",
      "4233 : Training: loss:  0.026981078\n",
      "4234 : Training: loss:  0.020959197\n",
      "4235 : Training: loss:  0.023540441\n",
      "4236 : Training: loss:  0.016486917\n",
      "4237 : Training: loss:  0.025729371\n",
      "4238 : Training: loss:  0.036486045\n",
      "4239 : Training: loss:  0.017051164\n",
      "4240 : Training: loss:  0.019976728\n",
      "Validation: Loss:  0.03633596  Accuracy:  0.9230769\n",
      "4241 : Training: loss:  0.025116827\n",
      "4242 : Training: loss:  0.0145492\n",
      "4243 : Training: loss:  0.012644374\n",
      "4244 : Training: loss:  0.0213506\n",
      "4245 : Training: loss:  0.017214272\n",
      "4246 : Training: loss:  0.030708686\n",
      "4247 : Training: loss:  0.018114414\n",
      "4248 : Training: loss:  0.03272181\n",
      "4249 : Training: loss:  0.015713077\n",
      "4250 : Training: loss:  0.028840367\n",
      "4251 : Training: loss:  0.018501086\n",
      "4252 : Training: loss:  0.017811503\n",
      "4253 : Training: loss:  0.020268742\n",
      "4254 : Training: loss:  0.02481713\n",
      "4255 : Training: loss:  0.018905155\n",
      "4256 : Training: loss:  0.02642512\n",
      "4257 : Training: loss:  0.021548102\n",
      "4258 : Training: loss:  0.012970834\n",
      "4259 : Training: loss:  0.02169497\n",
      "4260 : Training: loss:  0.017163357\n",
      "Validation: Loss:  0.036142506  Accuracy:  0.9230769\n",
      "4261 : Training: loss:  0.014440026\n",
      "4262 : Training: loss:  0.023524912\n",
      "4263 : Training: loss:  0.025102576\n",
      "4264 : Training: loss:  0.02659394\n",
      "4265 : Training: loss:  0.021419886\n",
      "4266 : Training: loss:  0.02162115\n",
      "4267 : Training: loss:  0.025627982\n",
      "4268 : Training: loss:  0.02017362\n",
      "4269 : Training: loss:  0.015724735\n",
      "4270 : Training: loss:  0.016402349\n",
      "4271 : Training: loss:  0.030551033\n",
      "4272 : Training: loss:  0.018291537\n",
      "4273 : Training: loss:  0.018619632\n",
      "4274 : Training: loss:  0.012946902\n",
      "4275 : Training: loss:  0.015080794\n",
      "4276 : Training: loss:  0.023709966\n",
      "4277 : Training: loss:  0.014420432\n",
      "4278 : Training: loss:  0.015637193\n",
      "4279 : Training: loss:  0.015530401\n",
      "4280 : Training: loss:  0.017394649\n",
      "Validation: Loss:  0.03603972  Accuracy:  0.9230769\n",
      "4281 : Training: loss:  0.01300245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4282 : Training: loss:  0.040006973\n",
      "4283 : Training: loss:  0.022238828\n",
      "4284 : Training: loss:  0.03637572\n",
      "4285 : Training: loss:  0.015797248\n",
      "4286 : Training: loss:  0.019449027\n",
      "4287 : Training: loss:  0.016601725\n",
      "4288 : Training: loss:  0.018393446\n",
      "4289 : Training: loss:  0.019942882\n",
      "4290 : Training: loss:  0.0135175055\n",
      "4291 : Training: loss:  0.02000258\n",
      "4292 : Training: loss:  0.032054376\n",
      "4293 : Training: loss:  0.029999088\n",
      "4294 : Training: loss:  0.0241841\n",
      "4295 : Training: loss:  0.028037168\n",
      "4296 : Training: loss:  0.0155497175\n",
      "4297 : Training: loss:  0.03153431\n",
      "4298 : Training: loss:  0.015687997\n",
      "4299 : Training: loss:  0.01937735\n",
      "4300 : Training: loss:  0.012476804\n",
      "Validation: Loss:  0.035707578  Accuracy:  0.9230769\n",
      "4301 : Training: loss:  0.012492628\n",
      "4302 : Training: loss:  0.016505416\n",
      "4303 : Training: loss:  0.023118315\n",
      "4304 : Training: loss:  0.01738112\n",
      "4305 : Training: loss:  0.01699498\n",
      "4306 : Training: loss:  0.027505903\n",
      "4307 : Training: loss:  0.016474368\n",
      "4308 : Training: loss:  0.02173258\n",
      "4309 : Training: loss:  0.016797615\n",
      "4310 : Training: loss:  0.02242084\n",
      "4311 : Training: loss:  0.027755914\n",
      "4312 : Training: loss:  0.019310309\n",
      "4313 : Training: loss:  0.014810941\n",
      "4314 : Training: loss:  0.0139152715\n",
      "4315 : Training: loss:  0.017943813\n",
      "4316 : Training: loss:  0.026055455\n",
      "4317 : Training: loss:  0.030737214\n",
      "4318 : Training: loss:  0.027403677\n",
      "4319 : Training: loss:  0.013547752\n",
      "4320 : Training: loss:  0.016373696\n",
      "Validation: Loss:  0.035375945  Accuracy:  0.9230769\n",
      "4321 : Training: loss:  0.021984532\n",
      "4322 : Training: loss:  0.02344049\n",
      "4323 : Training: loss:  0.019134156\n",
      "4324 : Training: loss:  0.024835411\n",
      "4325 : Training: loss:  0.019910982\n",
      "4326 : Training: loss:  0.018055286\n",
      "4327 : Training: loss:  0.019216545\n",
      "4328 : Training: loss:  0.02618467\n",
      "4329 : Training: loss:  0.020473901\n",
      "4330 : Training: loss:  0.015803704\n",
      "4331 : Training: loss:  0.015585448\n",
      "4332 : Training: loss:  0.022641443\n",
      "4333 : Training: loss:  0.022182805\n",
      "4334 : Training: loss:  0.016654758\n",
      "4335 : Training: loss:  0.039446916\n",
      "4336 : Training: loss:  0.014530747\n",
      "4337 : Training: loss:  0.014655066\n",
      "4338 : Training: loss:  0.04157641\n",
      "4339 : Training: loss:  0.01410445\n",
      "4340 : Training: loss:  0.012135316\n",
      "Validation: Loss:  0.03519644  Accuracy:  0.9230769\n",
      "4341 : Training: loss:  0.034079015\n",
      "4342 : Training: loss:  0.028060468\n",
      "4343 : Training: loss:  0.018402614\n",
      "4344 : Training: loss:  0.035287764\n",
      "4345 : Training: loss:  0.022603055\n",
      "4346 : Training: loss:  0.0150024295\n",
      "4347 : Training: loss:  0.013066028\n",
      "4348 : Training: loss:  0.01644558\n",
      "4349 : Training: loss:  0.02117407\n",
      "4350 : Training: loss:  0.0142027065\n",
      "4351 : Training: loss:  0.015122963\n",
      "4352 : Training: loss:  0.01928647\n",
      "4353 : Training: loss:  0.018263178\n",
      "4354 : Training: loss:  0.022965873\n",
      "4355 : Training: loss:  0.021658182\n",
      "4356 : Training: loss:  0.024186091\n",
      "4357 : Training: loss:  0.026597297\n",
      "4358 : Training: loss:  0.016202947\n",
      "4359 : Training: loss:  0.031947866\n",
      "4360 : Training: loss:  0.024200037\n",
      "Validation: Loss:  0.03521499  Accuracy:  0.9230769\n",
      "4361 : Training: loss:  0.029047957\n",
      "4362 : Training: loss:  0.019844221\n",
      "4363 : Training: loss:  0.023046374\n",
      "4364 : Training: loss:  0.020120833\n",
      "4365 : Training: loss:  0.014463042\n",
      "4366 : Training: loss:  0.014381232\n",
      "4367 : Training: loss:  0.017680194\n",
      "4368 : Training: loss:  0.023834743\n",
      "4369 : Training: loss:  0.05295012\n",
      "4370 : Training: loss:  0.013009917\n",
      "4371 : Training: loss:  0.025564821\n",
      "4372 : Training: loss:  0.019689288\n",
      "4373 : Training: loss:  0.011404481\n",
      "4374 : Training: loss:  0.017727928\n",
      "4375 : Training: loss:  0.020615803\n",
      "4376 : Training: loss:  0.019930584\n",
      "4377 : Training: loss:  0.024605056\n",
      "4378 : Training: loss:  0.015914682\n",
      "4379 : Training: loss:  0.015636316\n",
      "4380 : Training: loss:  0.022043098\n",
      "Validation: Loss:  0.035114348  Accuracy:  0.9230769\n",
      "4381 : Training: loss:  0.017721206\n",
      "4382 : Training: loss:  0.014879154\n",
      "4383 : Training: loss:  0.018940069\n",
      "4384 : Training: loss:  0.012949772\n",
      "4385 : Training: loss:  0.013214751\n",
      "4386 : Training: loss:  0.028166918\n",
      "4387 : Training: loss:  0.024105884\n",
      "4388 : Training: loss:  0.020440007\n",
      "4389 : Training: loss:  0.013793598\n",
      "4390 : Training: loss:  0.02203631\n",
      "4391 : Training: loss:  0.012109531\n",
      "4392 : Training: loss:  0.023703314\n",
      "4393 : Training: loss:  0.018106293\n",
      "4394 : Training: loss:  0.018364705\n",
      "4395 : Training: loss:  0.015159544\n",
      "4396 : Training: loss:  0.02596711\n",
      "4397 : Training: loss:  0.015057127\n",
      "4398 : Training: loss:  0.0352694\n",
      "4399 : Training: loss:  0.017991355\n",
      "4400 : Training: loss:  0.023084842\n",
      "Validation: Loss:  0.03493038  Accuracy:  0.9230769\n",
      "4401 : Training: loss:  0.028120495\n",
      "4402 : Training: loss:  0.02827829\n",
      "4403 : Training: loss:  0.014237707\n",
      "4404 : Training: loss:  0.016575027\n",
      "4405 : Training: loss:  0.011024855\n",
      "4406 : Training: loss:  0.020678917\n",
      "4407 : Training: loss:  0.019424109\n",
      "4408 : Training: loss:  0.014409638\n",
      "4409 : Training: loss:  0.010580752\n",
      "4410 : Training: loss:  0.017349813\n",
      "4411 : Training: loss:  0.018886628\n",
      "4412 : Training: loss:  0.018990563\n",
      "4413 : Training: loss:  0.01972982\n",
      "4414 : Training: loss:  0.013506855\n",
      "4415 : Training: loss:  0.014851351\n",
      "4416 : Training: loss:  0.018871045\n",
      "4417 : Training: loss:  0.017618604\n",
      "4418 : Training: loss:  0.024147823\n",
      "4419 : Training: loss:  0.014764072\n",
      "4420 : Training: loss:  0.017070446\n",
      "Validation: Loss:  0.03473095  Accuracy:  0.9230769\n",
      "4421 : Training: loss:  0.01900268\n",
      "4422 : Training: loss:  0.016920159\n",
      "4423 : Training: loss:  0.021676583\n",
      "4424 : Training: loss:  0.021991715\n",
      "4425 : Training: loss:  0.01510299\n",
      "4426 : Training: loss:  0.015561647\n",
      "4427 : Training: loss:  0.014838135\n",
      "4428 : Training: loss:  0.024287568\n",
      "4429 : Training: loss:  0.014861532\n",
      "4430 : Training: loss:  0.015900234\n",
      "4431 : Training: loss:  0.018871617\n",
      "4432 : Training: loss:  0.015476173\n",
      "4433 : Training: loss:  0.0135195665\n",
      "4434 : Training: loss:  0.017713174\n",
      "4435 : Training: loss:  0.016782219\n",
      "4436 : Training: loss:  0.027724577\n",
      "4437 : Training: loss:  0.02432145\n",
      "4438 : Training: loss:  0.011733019\n",
      "4439 : Training: loss:  0.018746007\n",
      "4440 : Training: loss:  0.02245865\n",
      "Validation: Loss:  0.034572475  Accuracy:  0.9423077\n",
      "4441 : Training: loss:  0.025045667\n",
      "4442 : Training: loss:  0.020419411\n",
      "4443 : Training: loss:  0.015277356\n",
      "4444 : Training: loss:  0.013966335\n",
      "4445 : Training: loss:  0.01897384\n",
      "4446 : Training: loss:  0.019695839\n",
      "4447 : Training: loss:  0.015625544\n",
      "4448 : Training: loss:  0.019663118\n",
      "4449 : Training: loss:  0.029147409\n",
      "4450 : Training: loss:  0.020379892\n",
      "4451 : Training: loss:  0.01930526\n",
      "4452 : Training: loss:  0.025306689\n",
      "4453 : Training: loss:  0.01458842\n",
      "4454 : Training: loss:  0.017900307\n",
      "4455 : Training: loss:  0.02037933\n",
      "4456 : Training: loss:  0.016928742\n",
      "4457 : Training: loss:  0.022983992\n",
      "4458 : Training: loss:  0.014439515\n",
      "4459 : Training: loss:  0.02308815\n",
      "4460 : Training: loss:  0.017384183\n",
      "Validation: Loss:  0.03465738  Accuracy:  0.9423077\n",
      "4461 : Training: loss:  0.012960092\n",
      "4462 : Training: loss:  0.01983679\n",
      "4463 : Training: loss:  0.020601247\n",
      "4464 : Training: loss:  0.017967232\n",
      "4465 : Training: loss:  0.018710267\n",
      "4466 : Training: loss:  0.0232128\n",
      "4467 : Training: loss:  0.019997194\n",
      "4468 : Training: loss:  0.021915123\n",
      "4469 : Training: loss:  0.015946837\n",
      "4470 : Training: loss:  0.029896975\n",
      "4471 : Training: loss:  0.014911163\n",
      "4472 : Training: loss:  0.028819595\n",
      "4473 : Training: loss:  0.0145691\n",
      "4474 : Training: loss:  0.021061294\n",
      "4475 : Training: loss:  0.028715173\n",
      "4476 : Training: loss:  0.02566946\n",
      "4477 : Training: loss:  0.015697377\n",
      "4478 : Training: loss:  0.012134911\n",
      "4479 : Training: loss:  0.020534327\n",
      "4480 : Training: loss:  0.020325737\n",
      "Validation: Loss:  0.03465636  Accuracy:  0.9423077\n",
      "4481 : Training: loss:  0.015913645\n",
      "4482 : Training: loss:  0.018648898\n",
      "4483 : Training: loss:  0.018667147\n",
      "4484 : Training: loss:  0.028471448\n",
      "4485 : Training: loss:  0.012364746\n",
      "4486 : Training: loss:  0.01595881\n",
      "4487 : Training: loss:  0.01524259\n",
      "4488 : Training: loss:  0.023489464\n",
      "4489 : Training: loss:  0.017222183\n",
      "4490 : Training: loss:  0.020985652\n",
      "4491 : Training: loss:  0.021329867\n",
      "4492 : Training: loss:  0.017746158\n",
      "4493 : Training: loss:  0.016107257\n",
      "4494 : Training: loss:  0.012795751\n",
      "4495 : Training: loss:  0.015229523\n",
      "4496 : Training: loss:  0.013693534\n",
      "4497 : Training: loss:  0.014493745\n",
      "4498 : Training: loss:  0.011989155\n",
      "4499 : Training: loss:  0.011200675\n",
      "4500 : Training: loss:  0.020981848\n",
      "Validation: Loss:  0.03439806  Accuracy:  0.9423077\n",
      "4501 : Training: loss:  0.0147180185\n",
      "4502 : Training: loss:  0.016201707\n",
      "4503 : Training: loss:  0.011761116\n",
      "4504 : Training: loss:  0.0236293\n",
      "4505 : Training: loss:  0.022296214\n",
      "4506 : Training: loss:  0.015788993\n",
      "4507 : Training: loss:  0.0121837715\n",
      "4508 : Training: loss:  0.018348841\n",
      "4509 : Training: loss:  0.017817544\n",
      "4510 : Training: loss:  0.01244144\n",
      "4511 : Training: loss:  0.018287273\n",
      "4512 : Training: loss:  0.02248075\n",
      "4513 : Training: loss:  0.015714824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4514 : Training: loss:  0.017291984\n",
      "4515 : Training: loss:  0.015394275\n",
      "4516 : Training: loss:  0.028609581\n",
      "4517 : Training: loss:  0.01632942\n",
      "4518 : Training: loss:  0.015233531\n",
      "4519 : Training: loss:  0.017164495\n",
      "4520 : Training: loss:  0.011963902\n",
      "Validation: Loss:  0.034182508  Accuracy:  0.9423077\n",
      "4521 : Training: loss:  0.01983238\n",
      "4522 : Training: loss:  0.014615302\n",
      "4523 : Training: loss:  0.012154963\n",
      "4524 : Training: loss:  0.033844642\n",
      "4525 : Training: loss:  0.01489918\n",
      "4526 : Training: loss:  0.017359864\n",
      "4527 : Training: loss:  0.017718403\n",
      "4528 : Training: loss:  0.016848795\n",
      "4529 : Training: loss:  0.012242258\n",
      "4530 : Training: loss:  0.019297384\n",
      "4531 : Training: loss:  0.020906445\n",
      "4532 : Training: loss:  0.016550602\n",
      "4533 : Training: loss:  0.020196632\n",
      "4534 : Training: loss:  0.024461217\n",
      "4535 : Training: loss:  0.021924876\n",
      "4536 : Training: loss:  0.021379974\n",
      "4537 : Training: loss:  0.022440676\n",
      "4538 : Training: loss:  0.009550242\n",
      "4539 : Training: loss:  0.024084358\n",
      "4540 : Training: loss:  0.01973226\n",
      "Validation: Loss:  0.034024656  Accuracy:  0.9423077\n",
      "4541 : Training: loss:  0.014795826\n",
      "4542 : Training: loss:  0.031165622\n",
      "4543 : Training: loss:  0.015405281\n",
      "4544 : Training: loss:  0.011274594\n",
      "4545 : Training: loss:  0.018841911\n",
      "4546 : Training: loss:  0.01893621\n",
      "4547 : Training: loss:  0.017164133\n",
      "4548 : Training: loss:  0.017100414\n",
      "4549 : Training: loss:  0.012909073\n",
      "4550 : Training: loss:  0.021460287\n",
      "4551 : Training: loss:  0.014132053\n",
      "4552 : Training: loss:  0.017369369\n",
      "4553 : Training: loss:  0.016888533\n",
      "4554 : Training: loss:  0.016165178\n",
      "4555 : Training: loss:  0.015261155\n",
      "4556 : Training: loss:  0.028877504\n",
      "4557 : Training: loss:  0.010647435\n",
      "4558 : Training: loss:  0.020462012\n",
      "4559 : Training: loss:  0.014490209\n",
      "4560 : Training: loss:  0.011505009\n",
      "Validation: Loss:  0.033931144  Accuracy:  0.9423077\n",
      "4561 : Training: loss:  0.022876278\n",
      "4562 : Training: loss:  0.022440793\n",
      "4563 : Training: loss:  0.023225216\n",
      "4564 : Training: loss:  0.017851867\n",
      "4565 : Training: loss:  0.01984523\n",
      "4566 : Training: loss:  0.018084107\n",
      "4567 : Training: loss:  0.014210738\n",
      "4568 : Training: loss:  0.012284315\n",
      "4569 : Training: loss:  0.016917756\n",
      "4570 : Training: loss:  0.013498775\n",
      "4571 : Training: loss:  0.01008617\n",
      "4572 : Training: loss:  0.010981207\n",
      "4573 : Training: loss:  0.015781827\n",
      "4574 : Training: loss:  0.018745251\n",
      "4575 : Training: loss:  0.013946776\n",
      "4576 : Training: loss:  0.011839312\n",
      "4577 : Training: loss:  0.014084236\n",
      "4578 : Training: loss:  0.016068188\n",
      "4579 : Training: loss:  0.014306484\n",
      "4580 : Training: loss:  0.0155493235\n",
      "Validation: Loss:  0.033911057  Accuracy:  0.9423077\n",
      "4581 : Training: loss:  0.011407549\n",
      "4582 : Training: loss:  0.013697092\n",
      "4583 : Training: loss:  0.025886359\n",
      "4584 : Training: loss:  0.014555978\n",
      "4585 : Training: loss:  0.020330487\n",
      "4586 : Training: loss:  0.015054752\n",
      "4587 : Training: loss:  0.012536674\n",
      "4588 : Training: loss:  0.0130102765\n",
      "4589 : Training: loss:  0.027223937\n",
      "4590 : Training: loss:  0.018212903\n",
      "4591 : Training: loss:  0.02409295\n",
      "4592 : Training: loss:  0.016311033\n",
      "4593 : Training: loss:  0.01553582\n",
      "4594 : Training: loss:  0.018221056\n",
      "4595 : Training: loss:  0.015996387\n",
      "4596 : Training: loss:  0.010675823\n",
      "4597 : Training: loss:  0.015103286\n",
      "4598 : Training: loss:  0.012035357\n",
      "4599 : Training: loss:  0.017580487\n",
      "4600 : Training: loss:  0.018586978\n",
      "Validation: Loss:  0.033864327  Accuracy:  0.9423077\n",
      "4601 : Training: loss:  0.027179118\n",
      "4602 : Training: loss:  0.018161599\n",
      "4603 : Training: loss:  0.012427349\n",
      "4604 : Training: loss:  0.019385109\n",
      "4605 : Training: loss:  0.023817917\n",
      "4606 : Training: loss:  0.01616675\n",
      "4607 : Training: loss:  0.022541832\n",
      "4608 : Training: loss:  0.019962454\n",
      "4609 : Training: loss:  0.010097657\n",
      "4610 : Training: loss:  0.019695379\n",
      "4611 : Training: loss:  0.024306497\n",
      "4612 : Training: loss:  0.017833747\n",
      "4613 : Training: loss:  0.023345945\n",
      "4614 : Training: loss:  0.010600821\n",
      "4615 : Training: loss:  0.017477572\n",
      "4616 : Training: loss:  0.020623574\n",
      "4617 : Training: loss:  0.03269668\n",
      "4618 : Training: loss:  0.01689545\n",
      "4619 : Training: loss:  0.015268573\n",
      "4620 : Training: loss:  0.008174615\n",
      "Validation: Loss:  0.033903472  Accuracy:  0.9423077\n",
      "4621 : Training: loss:  0.016699431\n",
      "4622 : Training: loss:  0.01834341\n",
      "4623 : Training: loss:  0.011944036\n",
      "4624 : Training: loss:  0.036576767\n",
      "4625 : Training: loss:  0.0148429405\n",
      "4626 : Training: loss:  0.034959555\n",
      "4627 : Training: loss:  0.021805001\n",
      "4628 : Training: loss:  0.02552347\n",
      "4629 : Training: loss:  0.024001345\n",
      "4630 : Training: loss:  0.02441505\n",
      "4631 : Training: loss:  0.017485725\n",
      "4632 : Training: loss:  0.0165363\n",
      "4633 : Training: loss:  0.013673549\n",
      "4634 : Training: loss:  0.03452697\n",
      "4635 : Training: loss:  0.013370205\n",
      "4636 : Training: loss:  0.012050843\n",
      "4637 : Training: loss:  0.016174974\n",
      "4638 : Training: loss:  0.018223263\n",
      "4639 : Training: loss:  0.02572858\n",
      "4640 : Training: loss:  0.013844468\n",
      "Validation: Loss:  0.03371468  Accuracy:  0.9230769\n",
      "4641 : Training: loss:  0.016998265\n",
      "4642 : Training: loss:  0.024331156\n",
      "4643 : Training: loss:  0.011327802\n",
      "4644 : Training: loss:  0.012946246\n",
      "4645 : Training: loss:  0.024778755\n",
      "4646 : Training: loss:  0.016254462\n",
      "4647 : Training: loss:  0.016165547\n",
      "4648 : Training: loss:  0.02119275\n",
      "4649 : Training: loss:  0.0202615\n",
      "4650 : Training: loss:  0.0119754495\n",
      "4651 : Training: loss:  0.011192684\n",
      "4652 : Training: loss:  0.022531096\n",
      "4653 : Training: loss:  0.00866464\n",
      "4654 : Training: loss:  0.017850677\n",
      "4655 : Training: loss:  0.016270248\n",
      "4656 : Training: loss:  0.01127463\n",
      "4657 : Training: loss:  0.014665548\n",
      "4658 : Training: loss:  0.012267994\n",
      "4659 : Training: loss:  0.015457386\n",
      "4660 : Training: loss:  0.017701384\n",
      "Validation: Loss:  0.03371488  Accuracy:  0.9230769\n",
      "4661 : Training: loss:  0.024814878\n",
      "4662 : Training: loss:  0.010076572\n",
      "4663 : Training: loss:  0.00862683\n",
      "4664 : Training: loss:  0.015369255\n",
      "4665 : Training: loss:  0.013619774\n",
      "4666 : Training: loss:  0.022571592\n",
      "4667 : Training: loss:  0.016786609\n",
      "4668 : Training: loss:  0.017901605\n",
      "4669 : Training: loss:  0.023101168\n",
      "4670 : Training: loss:  0.021012576\n",
      "4671 : Training: loss:  0.011005716\n",
      "4672 : Training: loss:  0.015276231\n",
      "4673 : Training: loss:  0.011233354\n",
      "4674 : Training: loss:  0.011535978\n",
      "4675 : Training: loss:  0.015240361\n",
      "4676 : Training: loss:  0.014285805\n",
      "4677 : Training: loss:  0.01699506\n",
      "4678 : Training: loss:  0.012745212\n",
      "4679 : Training: loss:  0.0149882715\n",
      "4680 : Training: loss:  0.012694625\n",
      "Validation: Loss:  0.033655625  Accuracy:  0.9230769\n",
      "4681 : Training: loss:  0.013221072\n",
      "4682 : Training: loss:  0.018190004\n",
      "4683 : Training: loss:  0.020787355\n",
      "4684 : Training: loss:  0.009940219\n",
      "4685 : Training: loss:  0.014478986\n",
      "4686 : Training: loss:  0.018635033\n",
      "4687 : Training: loss:  0.016608715\n",
      "4688 : Training: loss:  0.017224954\n",
      "4689 : Training: loss:  0.014174944\n",
      "4690 : Training: loss:  0.025705634\n",
      "4691 : Training: loss:  0.021943143\n",
      "4692 : Training: loss:  0.017973468\n",
      "4693 : Training: loss:  0.017624404\n",
      "4694 : Training: loss:  0.012054622\n",
      "4695 : Training: loss:  0.017817108\n",
      "4696 : Training: loss:  0.027092282\n",
      "4697 : Training: loss:  0.015274883\n",
      "4698 : Training: loss:  0.0102724945\n",
      "4699 : Training: loss:  0.03299636\n",
      "4700 : Training: loss:  0.016829357\n",
      "Validation: Loss:  0.033450585  Accuracy:  0.9230769\n",
      "4701 : Training: loss:  0.014029197\n",
      "4702 : Training: loss:  0.023534834\n",
      "4703 : Training: loss:  0.014105477\n",
      "4704 : Training: loss:  0.014602596\n",
      "4705 : Training: loss:  0.0103597855\n",
      "4706 : Training: loss:  0.0116704125\n",
      "4707 : Training: loss:  0.015857032\n",
      "4708 : Training: loss:  0.016821109\n",
      "4709 : Training: loss:  0.013937927\n",
      "4710 : Training: loss:  0.013648723\n",
      "4711 : Training: loss:  0.017515294\n",
      "4712 : Training: loss:  0.04056198\n",
      "4713 : Training: loss:  0.014216327\n",
      "4714 : Training: loss:  0.019043628\n",
      "4715 : Training: loss:  0.018077143\n",
      "4716 : Training: loss:  0.014963245\n",
      "4717 : Training: loss:  0.020687262\n",
      "4718 : Training: loss:  0.011582468\n",
      "4719 : Training: loss:  0.020057626\n",
      "4720 : Training: loss:  0.016131828\n",
      "Validation: Loss:  0.03338384  Accuracy:  0.90384614\n",
      "4721 : Training: loss:  0.02973486\n",
      "4722 : Training: loss:  0.0139834\n",
      "4723 : Training: loss:  0.014194187\n",
      "4724 : Training: loss:  0.0114487475\n",
      "4725 : Training: loss:  0.018716386\n",
      "4726 : Training: loss:  0.019463822\n",
      "4727 : Training: loss:  0.014306583\n",
      "4728 : Training: loss:  0.021178778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4729 : Training: loss:  0.02319815\n",
      "4730 : Training: loss:  0.011734706\n",
      "4731 : Training: loss:  0.01044295\n",
      "4732 : Training: loss:  0.023882238\n",
      "4733 : Training: loss:  0.011827918\n",
      "4734 : Training: loss:  0.025699696\n",
      "4735 : Training: loss:  0.014816135\n",
      "4736 : Training: loss:  0.020043803\n",
      "4737 : Training: loss:  0.0141677335\n",
      "4738 : Training: loss:  0.013350153\n",
      "4739 : Training: loss:  0.023755394\n",
      "4740 : Training: loss:  0.014031025\n",
      "Validation: Loss:  0.033128697  Accuracy:  0.90384614\n",
      "4741 : Training: loss:  0.011269114\n",
      "4742 : Training: loss:  0.018458232\n",
      "4743 : Training: loss:  0.01700378\n",
      "4744 : Training: loss:  0.02311618\n",
      "4745 : Training: loss:  0.017157929\n",
      "4746 : Training: loss:  0.0144562\n",
      "4747 : Training: loss:  0.022384275\n",
      "4748 : Training: loss:  0.014732595\n",
      "4749 : Training: loss:  0.013269359\n",
      "4750 : Training: loss:  0.01694579\n",
      "4751 : Training: loss:  0.019831002\n",
      "4752 : Training: loss:  0.017509434\n",
      "4753 : Training: loss:  0.0114271045\n",
      "4754 : Training: loss:  0.012258769\n",
      "4755 : Training: loss:  0.015804809\n",
      "4756 : Training: loss:  0.011390563\n",
      "4757 : Training: loss:  0.015014595\n",
      "4758 : Training: loss:  0.011281152\n",
      "4759 : Training: loss:  0.014575737\n",
      "4760 : Training: loss:  0.015032853\n",
      "Validation: Loss:  0.03296847  Accuracy:  0.9230769\n",
      "4761 : Training: loss:  0.016879201\n",
      "4762 : Training: loss:  0.012084021\n",
      "4763 : Training: loss:  0.018303972\n",
      "4764 : Training: loss:  0.027904995\n",
      "4765 : Training: loss:  0.013827435\n",
      "4766 : Training: loss:  0.01790642\n",
      "4767 : Training: loss:  0.013046821\n",
      "4768 : Training: loss:  0.01075637\n",
      "4769 : Training: loss:  0.016114509\n",
      "4770 : Training: loss:  0.014806076\n",
      "4771 : Training: loss:  0.024513526\n",
      "4772 : Training: loss:  0.020313075\n",
      "4773 : Training: loss:  0.017549537\n",
      "4774 : Training: loss:  0.014193956\n",
      "4775 : Training: loss:  0.014888765\n",
      "4776 : Training: loss:  0.010049401\n",
      "4777 : Training: loss:  0.023812775\n",
      "4778 : Training: loss:  0.009319623\n",
      "4779 : Training: loss:  0.01000737\n",
      "4780 : Training: loss:  0.012749712\n",
      "Validation: Loss:  0.03273663  Accuracy:  0.9230769\n",
      "4781 : Training: loss:  0.013530845\n",
      "4782 : Training: loss:  0.016458463\n",
      "4783 : Training: loss:  0.019180309\n",
      "4784 : Training: loss:  0.02309995\n",
      "4785 : Training: loss:  0.012836348\n",
      "4786 : Training: loss:  0.014632164\n",
      "4787 : Training: loss:  0.012588729\n",
      "4788 : Training: loss:  0.012197535\n",
      "4789 : Training: loss:  0.010879762\n",
      "4790 : Training: loss:  0.044007227\n",
      "4791 : Training: loss:  0.022476723\n",
      "4792 : Training: loss:  0.016514344\n",
      "4793 : Training: loss:  0.021010129\n",
      "4794 : Training: loss:  0.0125476\n",
      "4795 : Training: loss:  0.021440387\n",
      "4796 : Training: loss:  0.011000714\n",
      "4797 : Training: loss:  0.020124665\n",
      "4798 : Training: loss:  0.019190667\n",
      "4799 : Training: loss:  0.023436196\n",
      "4800 : Training: loss:  0.010775498\n",
      "Validation: Loss:  0.032515198  Accuracy:  0.9230769\n",
      "4801 : Training: loss:  0.013439907\n",
      "4802 : Training: loss:  0.00993469\n",
      "4803 : Training: loss:  0.012201437\n",
      "4804 : Training: loss:  0.012839186\n",
      "4805 : Training: loss:  0.010720102\n",
      "4806 : Training: loss:  0.019662522\n",
      "4807 : Training: loss:  0.020720683\n",
      "4808 : Training: loss:  0.010730194\n",
      "4809 : Training: loss:  0.017628739\n",
      "4810 : Training: loss:  0.019512389\n",
      "4811 : Training: loss:  0.008758645\n",
      "4812 : Training: loss:  0.011679556\n",
      "4813 : Training: loss:  0.017646255\n",
      "4814 : Training: loss:  0.01242108\n",
      "4815 : Training: loss:  0.01406865\n",
      "4816 : Training: loss:  0.014317768\n",
      "4817 : Training: loss:  0.015147449\n",
      "4818 : Training: loss:  0.021836242\n",
      "4819 : Training: loss:  0.013779158\n",
      "4820 : Training: loss:  0.018062424\n",
      "Validation: Loss:  0.032385048  Accuracy:  0.9230769\n",
      "4821 : Training: loss:  0.012546752\n",
      "4822 : Training: loss:  0.018351689\n",
      "4823 : Training: loss:  0.0144589655\n",
      "4824 : Training: loss:  0.025201188\n",
      "4825 : Training: loss:  0.03712035\n",
      "4826 : Training: loss:  0.014327093\n",
      "4827 : Training: loss:  0.009253644\n",
      "4828 : Training: loss:  0.009825586\n",
      "4829 : Training: loss:  0.01998084\n",
      "4830 : Training: loss:  0.0105175655\n",
      "4831 : Training: loss:  0.0319098\n",
      "4832 : Training: loss:  0.011974872\n",
      "4833 : Training: loss:  0.018232001\n",
      "4834 : Training: loss:  0.012417298\n",
      "4835 : Training: loss:  0.011933786\n",
      "4836 : Training: loss:  0.012978191\n",
      "4837 : Training: loss:  0.01725722\n",
      "4838 : Training: loss:  0.015902001\n",
      "4839 : Training: loss:  0.027229214\n",
      "4840 : Training: loss:  0.024877263\n",
      "Validation: Loss:  0.032344718  Accuracy:  0.90384614\n",
      "4841 : Training: loss:  0.016161917\n",
      "4842 : Training: loss:  0.020313\n",
      "4843 : Training: loss:  0.01565781\n",
      "4844 : Training: loss:  0.01363182\n",
      "4845 : Training: loss:  0.011399897\n",
      "4846 : Training: loss:  0.012340169\n",
      "4847 : Training: loss:  0.018447043\n",
      "4848 : Training: loss:  0.018629147\n",
      "4849 : Training: loss:  0.015194763\n",
      "4850 : Training: loss:  0.009751455\n",
      "4851 : Training: loss:  0.018379778\n",
      "4852 : Training: loss:  0.020620815\n",
      "4853 : Training: loss:  0.023223436\n",
      "4854 : Training: loss:  0.015184553\n",
      "4855 : Training: loss:  0.012040325\n",
      "4856 : Training: loss:  0.009419572\n",
      "4857 : Training: loss:  0.009028816\n",
      "4858 : Training: loss:  0.011873472\n",
      "4859 : Training: loss:  0.012454518\n",
      "4860 : Training: loss:  0.01409598\n",
      "Validation: Loss:  0.03236366  Accuracy:  0.90384614\n",
      "4861 : Training: loss:  0.013795455\n",
      "4862 : Training: loss:  0.0104605425\n",
      "4863 : Training: loss:  0.011115996\n",
      "4864 : Training: loss:  0.020430634\n",
      "4865 : Training: loss:  0.01694947\n",
      "4866 : Training: loss:  0.011472241\n",
      "4867 : Training: loss:  0.018582646\n",
      "4868 : Training: loss:  0.012930839\n",
      "4869 : Training: loss:  0.031428766\n",
      "4870 : Training: loss:  0.020192191\n",
      "4871 : Training: loss:  0.010760724\n",
      "4872 : Training: loss:  0.01585848\n",
      "4873 : Training: loss:  0.014066724\n",
      "4874 : Training: loss:  0.0072622183\n",
      "4875 : Training: loss:  0.012097585\n",
      "4876 : Training: loss:  0.01638964\n",
      "4877 : Training: loss:  0.009706259\n",
      "4878 : Training: loss:  0.0135318255\n",
      "4879 : Training: loss:  0.013004243\n",
      "4880 : Training: loss:  0.013438098\n",
      "Validation: Loss:  0.03215036  Accuracy:  0.90384614\n",
      "4881 : Training: loss:  0.014813025\n",
      "4882 : Training: loss:  0.016104994\n",
      "4883 : Training: loss:  0.011995158\n",
      "4884 : Training: loss:  0.015553546\n",
      "4885 : Training: loss:  0.009133173\n",
      "4886 : Training: loss:  0.022543982\n",
      "4887 : Training: loss:  0.016088966\n",
      "4888 : Training: loss:  0.012698061\n",
      "4889 : Training: loss:  0.0187916\n",
      "4890 : Training: loss:  0.01267144\n",
      "4891 : Training: loss:  0.011623405\n",
      "4892 : Training: loss:  0.013561933\n",
      "4893 : Training: loss:  0.01248586\n",
      "4894 : Training: loss:  0.024681581\n",
      "4895 : Training: loss:  0.023324693\n",
      "4896 : Training: loss:  0.013355835\n",
      "4897 : Training: loss:  0.014066518\n",
      "4898 : Training: loss:  0.014711619\n",
      "4899 : Training: loss:  0.009809115\n",
      "4900 : Training: loss:  0.01094126\n",
      "Validation: Loss:  0.03210513  Accuracy:  0.9230769\n",
      "4901 : Training: loss:  0.01566709\n",
      "4902 : Training: loss:  0.010465729\n",
      "4903 : Training: loss:  0.0129925925\n",
      "4904 : Training: loss:  0.009745723\n",
      "4905 : Training: loss:  0.013725195\n",
      "4906 : Training: loss:  0.010656477\n",
      "4907 : Training: loss:  0.011536245\n",
      "4908 : Training: loss:  0.010382224\n",
      "4909 : Training: loss:  0.014743433\n",
      "4910 : Training: loss:  0.012566139\n",
      "4911 : Training: loss:  0.015332265\n",
      "4912 : Training: loss:  0.013620419\n",
      "4913 : Training: loss:  0.017831279\n",
      "4914 : Training: loss:  0.023376564\n",
      "4915 : Training: loss:  0.0084671145\n",
      "4916 : Training: loss:  0.010032683\n",
      "4917 : Training: loss:  0.0110298265\n",
      "4918 : Training: loss:  0.013729703\n",
      "4919 : Training: loss:  0.012986385\n",
      "4920 : Training: loss:  0.02041854\n",
      "Validation: Loss:  0.031967673  Accuracy:  0.9423077\n",
      "4921 : Training: loss:  0.018910548\n",
      "4922 : Training: loss:  0.012256211\n",
      "4923 : Training: loss:  0.008827185\n",
      "4924 : Training: loss:  0.017610328\n",
      "4925 : Training: loss:  0.008264265\n",
      "4926 : Training: loss:  0.0140546905\n",
      "4927 : Training: loss:  0.013630913\n",
      "4928 : Training: loss:  0.010198495\n",
      "4929 : Training: loss:  0.017553583\n",
      "4930 : Training: loss:  0.0152145885\n",
      "4931 : Training: loss:  0.015392896\n",
      "4932 : Training: loss:  0.009824889\n",
      "4933 : Training: loss:  0.010399097\n",
      "4934 : Training: loss:  0.015848016\n",
      "4935 : Training: loss:  0.012385716\n",
      "4936 : Training: loss:  0.016249735\n",
      "4937 : Training: loss:  0.009983801\n",
      "4938 : Training: loss:  0.030844672\n",
      "4939 : Training: loss:  0.0217905\n",
      "4940 : Training: loss:  0.018291412\n",
      "Validation: Loss:  0.031791225  Accuracy:  0.9423077\n",
      "4941 : Training: loss:  0.010208523\n",
      "4942 : Training: loss:  0.013260482\n",
      "4943 : Training: loss:  0.013115317\n",
      "4944 : Training: loss:  0.010193312\n",
      "4945 : Training: loss:  0.008347341\n",
      "4946 : Training: loss:  0.0209322\n",
      "4947 : Training: loss:  0.018450882\n",
      "4948 : Training: loss:  0.011483605\n",
      "4949 : Training: loss:  0.018798409\n",
      "4950 : Training: loss:  0.01773622\n",
      "4951 : Training: loss:  0.009493982\n",
      "4952 : Training: loss:  0.014456351\n",
      "4953 : Training: loss:  0.010419861\n",
      "4954 : Training: loss:  0.011976253\n",
      "4955 : Training: loss:  0.019298501\n",
      "4956 : Training: loss:  0.020959638\n",
      "4957 : Training: loss:  0.01733522\n",
      "4958 : Training: loss:  0.011879393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4959 : Training: loss:  0.014553553\n",
      "4960 : Training: loss:  0.014014456\n",
      "Validation: Loss:  0.031651754  Accuracy:  0.9423077\n",
      "4961 : Training: loss:  0.0202997\n",
      "4962 : Training: loss:  0.010047115\n",
      "4963 : Training: loss:  0.013555407\n",
      "4964 : Training: loss:  0.010543639\n",
      "4965 : Training: loss:  0.009358325\n",
      "4966 : Training: loss:  0.017693108\n",
      "4967 : Training: loss:  0.020235958\n",
      "4968 : Training: loss:  0.019750537\n",
      "4969 : Training: loss:  0.017574323\n",
      "4970 : Training: loss:  0.016858624\n",
      "4971 : Training: loss:  0.022464732\n",
      "4972 : Training: loss:  0.01596108\n",
      "4973 : Training: loss:  0.018337846\n",
      "4974 : Training: loss:  0.009897653\n",
      "4975 : Training: loss:  0.00795775\n",
      "4976 : Training: loss:  0.012529233\n",
      "4977 : Training: loss:  0.020157853\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-eb8110e16071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mremove_directory_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries_folder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-38c12dc3bb02>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_training_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0minputs_visual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs_textual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorrect_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtextual\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs_textual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcorrect_classes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": Training: loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0msumm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mloss_ph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mdirect\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[0;32m--> 470\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5224\u001b[0m     context.context().context_switches.push(\n\u001b[0;32m-> 5225\u001b[0;31m         default.building_function, default.as_default)\n\u001b[0m\u001b[1;32m   5226\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5227\u001b[0m       with super(_DefaultGraphStack, self).get_controller(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mpush\u001b[0;34m(self, is_building_function, enter_context_fn)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     self.stack.append(\n\u001b[0m\u001b[1;32m    136\u001b[0m         ContextSwitch(is_building_function, enter_context_fn))\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "remove_directory_content(summaries_folder_name)\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
